[32m[I 2025-01-28 13:04:23,716][0m A new study created in memory with name: no-name-11c4cd18-f802-4980-9423-032d4f5cce1a[0m
[32m[I 2025-01-28 13:05:54,012][0m Trial 0 finished with value: 0.1451368561399443 and parameters: {'depth': 3, 'learning_rate': 0.11430485332959725, 'l2_leaf_reg': 25.439393102913712, 'random_strength': 0.7869219781280372, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'Bernoulli', 'subsample': 0.6858902060296476}. Best is trial 0 with value: 0.1451368561399443.[0m
[32m[I 2025-01-28 13:06:53,307][0m Trial 1 finished with value: 0.144134753020353 and parameters: {'depth': 4, 'learning_rate': 0.1463288100728504, 'l2_leaf_reg': 37.70313881300155, 'random_strength': 0.5555506613820326, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'Bernoulli', 'subsample': 0.7051632701440742}. Best is trial 0 with value: 0.1451368561399443.[0m
[32m[I 2025-01-28 13:09:03,537][0m Trial 2 finished with value: 0.14531369039506487 and parameters: {'depth': 3, 'learning_rate': 0.1072856981045499, 'l2_leaf_reg': 34.30802447438378, 'random_strength': 1.4041060821934384, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.3124081173356764}. Best is trial 2 with value: 0.14531369039506487.[0m
[32m[I 2025-01-28 13:10:01,995][0m Trial 3 finished with value: 0.14340725173454816 and parameters: {'depth': 3, 'learning_rate': 0.12452605050161442, 'l2_leaf_reg': 34.24400114225851, 'random_strength': 0.25897317477486026, 'grow_policy': 'Depthwise', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.6844834895453955, 'min_data_in_leaf': 10}. Best is trial 2 with value: 0.14531369039506487.[0m
[32m[I 2025-01-28 13:10:32,195][0m Trial 4 finished with value: 0.14156797423653583 and parameters: {'depth': 5, 'learning_rate': 0.11798656988546007, 'l2_leaf_reg': 17.45496501738341, 'random_strength': 0.1254662228751633, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'Bernoulli', 'subsample': 0.6676023097025449}. Best is trial 2 with value: 0.14531369039506487.[0m
[32m[I 2025-01-28 13:11:37,771][0m Trial 5 finished with value: 0.1437996058387343 and parameters: {'depth': 4, 'learning_rate': 0.12460200497290033, 'l2_leaf_reg': 15.963452811501764, 'random_strength': 1.1946420445884427, 'grow_policy': 'Depthwise', 'bootstrap_type': 'MVS', 'min_data_in_leaf': 10}. Best is trial 2 with value: 0.14531369039506487.[0m
[33m[W 2025-01-28 13:11:40,761][0m Trial 6 failed with parameters: {'depth': 5, 'learning_rate': 0.13490375334707067, 'l2_leaf_reg': 15.724982808708633, 'random_strength': 1.1904735403211668, 'grow_policy': 'Depthwise', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.5621123459012801, 'min_data_in_leaf': 9} because of the following error: KeyboardInterrupt('').[0m
Traceback (most recent call last):
  File "C:\Users\maorb\Classes\Classical_ML\YDATA-kaggle-assignment\venv\Lib\site-packages\optuna\study\_optimize.py", line 197, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "C:\Users\maorb\Classes\Classical_ML\YDATA-kaggle-assignment\train.py", line 87, in objective
    model.fit(
  File "C:\Users\maorb\Classes\Classical_ML\YDATA-kaggle-assignment\venv\Lib\site-packages\catboost\core.py", line 5245, in fit
    self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline, use_best_model,
  File "C:\Users\maorb\Classes\Classical_ML\YDATA-kaggle-assignment\venv\Lib\site-packages\catboost\core.py", line 2410, in _fit
    self._train(
  File "C:\Users\maorb\Classes\Classical_ML\YDATA-kaggle-assignment\venv\Lib\site-packages\catboost\core.py", line 1790, in _train
    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)
  File "_catboost.pyx", line 5017, in _catboost._CatBoost._train
  File "_catboost.pyx", line 5066, in _catboost._CatBoost._train
KeyboardInterrupt
[33m[W 2025-01-28 13:11:40,768][0m Trial 6 failed with value None.[0m
13:11:40.769 | [38;5;160mERROR[0m   | Task run 'tune_hyperparameters-a25' - Crash detected! Execution was aborted by an interrupt signal.
13:11:40.772 | [38;5;160mERROR[0m   | Task run 'tune_hyperparameters-a25' - Finished in state [91mCrashed[0m('Execution was aborted by an interrupt signal.')
13:11:40.776 | [38;5;160mERROR[0m   | Flow run[35m 'loose-centipede'[0m - Crash detected! Execution was aborted by an interrupt signal.
13:11:41.132 | [38;5;160mERROR[0m   | Flow run[35m 'loose-centipede'[0m - Finished in state [91mCrashed[0m('Execution was aborted by an interrupt signal.')
Traceback (most recent call last):
  File "C:\Users\maorb\Classes\Classical_ML\YDATA-kaggle-assignment\tasks_wandb.py", line 107, in <module>
    tune_and_train_pipeline(
  File "C:\Users\maorb\Classes\Classical_ML\YDATA-kaggle-assignment\venv\Lib\site-packages\prefect\flows.py", line 1392, in __call__
    return run_flow(
           ^^^^^^^^^
  File "C:\Users\maorb\Classes\Classical_ML\YDATA-kaggle-assignment\venv\Lib\site-packages\prefect\flow_engine.py", line 1511, in run_flow
    ret_val = run_flow_sync(**kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\maorb\Classes\Classical_ML\YDATA-kaggle-assignment\venv\Lib\site-packages\prefect\flow_engine.py", line 1354, in run_flow_sync
    engine.call_flow_fn()
  File "C:\Users\maorb\Classes\Classical_ML\YDATA-kaggle-assignment\venv\Lib\site-packages\prefect\flow_engine.py", line 766, in call_flow_fn
    result = call_with_parameters(self.flow.fn, self.parameters)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\maorb\Classes\Classical_ML\YDATA-kaggle-assignment\venv\Lib\site-packages\prefect\utilities\callables.py", line 208, in call_with_parameters
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\maorb\Classes\Classical_ML\YDATA-kaggle-assignment\tasks_wandb.py", line 92, in tune_and_train_pipeline
    best_params = tune_hyperparameters(base_trainer, folds_dir, n_trials, run_id)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\maorb\Classes\Classical_ML\YDATA-kaggle-assignment\venv\Lib\site-packages\prefect\tasks.py", line 1035, in __call__
    return run_task(
           ^^^^^^^^^
  File "C:\Users\maorb\Classes\Classical_ML\YDATA-kaggle-assignment\venv\Lib\site-packages\prefect\task_engine.py", line 1576, in run_task
    return run_task_sync(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\maorb\Classes\Classical_ML\YDATA-kaggle-assignment\venv\Lib\site-packages\prefect\task_engine.py", line 1387, in run_task_sync
    engine.call_task_fn(txn)
  File "C:\Users\maorb\Classes\Classical_ML\YDATA-kaggle-assignment\venv\Lib\site-packages\prefect\task_engine.py", line 828, in call_task_fn
    result = call_with_parameters(self.task.fn, parameters)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\maorb\Classes\Classical_ML\YDATA-kaggle-assignment\venv\Lib\site-packages\prefect\utilities\callables.py", line 208, in call_with_parameters
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\maorb\Classes\Classical_ML\YDATA-kaggle-assignment\tasks_wandb.py", line 42, in tune_hyperparameters
    return trainer.hyperparameter_tuning(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\maorb\Classes\Classical_ML\YDATA-kaggle-assignment\train.py", line 130, in hyperparameter_tuning
    study.optimize(objective, n_trials=n_trials)
  File "C:\Users\maorb\Classes\Classical_ML\YDATA-kaggle-assignment\venv\Lib\site-packages\optuna\study\study.py", line 475, in optimize
    _optimize(
  File "C:\Users\maorb\Classes\Classical_ML\YDATA-kaggle-assignment\venv\Lib\site-packages\optuna\study\_optimize.py", line 63, in _optimize
    _optimize_sequential(
  File "C:\Users\maorb\Classes\Classical_ML\YDATA-kaggle-assignment\venv\Lib\site-packages\optuna\study\_optimize.py", line 160, in _optimize_sequential
    frozen_trial = _run_trial(study, func, catch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\maorb\Classes\Classical_ML\YDATA-kaggle-assignment\venv\Lib\site-packages\optuna\study\_optimize.py", line 248, in _run_trial
    raise func_err
  File "C:\Users\maorb\Classes\Classical_ML\YDATA-kaggle-assignment\venv\Lib\site-packages\optuna\study\_optimize.py", line 197, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "C:\Users\maorb\Classes\Classical_ML\YDATA-kaggle-assignment\train.py", line 87, in objective
    model.fit(
  File "C:\Users\maorb\Classes\Classical_ML\YDATA-kaggle-assignment\venv\Lib\site-packages\catboost\core.py", line 5245, in fit
    self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline, use_best_model,
  File "C:\Users\maorb\Classes\Classical_ML\YDATA-kaggle-assignment\venv\Lib\site-packages\catboost\core.py", line 2410, in _fit
    self._train(
  File "C:\Users\maorb\Classes\Classical_ML\YDATA-kaggle-assignment\venv\Lib\site-packages\catboost\core.py", line 1790, in _train
    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)
  File "_catboost.pyx", line 5017, in _catboost._CatBoost._train
  File "_catboost.pyx", line 5066, in _catboost._CatBoost._train
KeyboardInterrupt
