{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pickled data\n",
    "import pickle\n",
    "cleaned_data = pd.read_pickle(r\"C:\\Users\\maorb\\Classes\\Classical_ML\\YDATA-kaggle-assignment\\data\\processed\\cleaned_data_Maor.pkl\")\n",
    "X_train = pd.read_pickle(r\"C:\\Users\\maorb\\Classes\\Classical_ML\\YDATA-kaggle-assignment\\data\\processed\\X_train.pkl\")\n",
    "X_test = pd.read_pickle(r\"C:\\Users\\maorb\\Classes\\Classical_ML\\YDATA-kaggle-assignment\\data\\processed\\X_test.pkl\")\n",
    "y_train = pd.read_pickle(r\"C:\\Users\\maorb\\Classes\\Classical_ML\\YDATA-kaggle-assignment\\data\\processed\\y_train.pkl\")\n",
    "y_test = pd.read_pickle(r\"C:\\Users\\maorb\\Classes\\Classical_ML\\YDATA-kaggle-assignment\\data\\processed\\y_test.pkl\")\n",
    "\n",
    "\n",
    "X_val_fold_0 = pd.read_pickle(r\"C:\\Users\\maorb\\Classes\\Classical_ML\\YDATA-kaggle-assignment\\data\\processed\\X_val_fold_0.pkl\")\n",
    "y_val_fold_0 = pd.read_pickle(r\"C:\\Users\\maorb\\Classes\\Classical_ML\\YDATA-kaggle-assignment\\data\\processed\\y_val_fold_0.pkl\")\n",
    "X_val_fold_1 = pd.read_pickle(r\"C:\\Users\\maorb\\Classes\\Classical_ML\\YDATA-kaggle-assignment\\data\\processed\\X_val_fold_1.pkl\")\n",
    "y_val_fold_1 = pd.read_pickle(r\"C:\\Users\\maorb\\Classes\\Classical_ML\\YDATA-kaggle-assignment\\data\\processed\\y_val_fold_1.pkl\")\n",
    "X_val_fold_2 = pd.read_pickle(r\"C:\\Users\\maorb\\Classes\\Classical_ML\\YDATA-kaggle-assignment\\data\\processed\\X_val_fold_2.pkl\")\n",
    "y_val_fold_2 = pd.read_pickle(r\"C:\\Users\\maorb\\Classes\\Classical_ML\\YDATA-kaggle-assignment\\data\\processed\\y_val_fold_2.pkl\")\n",
    "X_val_fold_3 = pd.read_pickle(r\"C:\\Users\\maorb\\Classes\\Classical_ML\\YDATA-kaggle-assignment\\data\\processed\\X_val_fold_3.pkl\")\n",
    "y_val_fold_3 = pd.read_pickle(r\"C:\\Users\\maorb\\Classes\\Classical_ML\\YDATA-kaggle-assignment\\data\\processed\\y_val_fold_3.pkl\")\n",
    "X_val_fold_4 = pd.read_pickle(r\"C:\\Users\\maorb\\Classes\\Classical_ML\\YDATA-kaggle-assignment\\data\\processed\\X_val_fold_4.pkl\")\n",
    "y_val_fold_4 = pd.read_pickle(r\"C:\\Users\\maorb\\Classes\\Classical_ML\\YDATA-kaggle-assignment\\data\\processed\\y_val_fold_4.pkl\")\n",
    "\n",
    "\n",
    "predictions_1st = pd.read_csv(r'C:\\Users\\maorb\\Classes\\Classical_ML\\YDATA-kaggle-assignment\\data\\Predictions\\predictionscatboost.csv',\n",
    "                                header=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = pd.concat([y_val_fold_0, y_val_fold_1, y_val_fold_2, y_val_fold_3, y_val_fold_4], axis=0)\n",
    "X_val = pd.concat([X_val_fold_0, X_val_fold_1, X_val_fold_2, X_val_fold_3, X_val_fold_4], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 365349 entries, 0 to 370631\n",
      "Data columns (total 37 columns):\n",
      " #   Column                       Non-Null Count   Dtype   \n",
      "---  ------                       --------------   -----   \n",
      " 0   product                      365349 non-null  category\n",
      " 1   campaign_id                  365349 non-null  category\n",
      " 2   webpage_id                   365349 non-null  category\n",
      " 3   user_group_id                365349 non-null  category\n",
      " 4   gender                       365349 non-null  category\n",
      " 5   age_level                    365349 non-null  float64 \n",
      " 6   user_depth                   365349 non-null  float64 \n",
      " 7   city_development_index       365349 non-null  float64 \n",
      " 8   var_1                        365349 non-null  float64 \n",
      " 9   product_category             365349 non-null  category\n",
      " 10  user_id_ctrS                 365349 non-null  float64 \n",
      " 11  product_ctrS                 365349 non-null  float64 \n",
      " 12  campaign_id_ctrS             365349 non-null  float64 \n",
      " 13  webpage_id_ctrS              365349 non-null  float64 \n",
      " 14  user_group_id_ctrS           365349 non-null  float64 \n",
      " 15  gender_ctrS                  365349 non-null  float64 \n",
      " 16  age_level_ctrS               365349 non-null  float64 \n",
      " 17  user_depth_ctrS              365349 non-null  float64 \n",
      " 18  city_development_index_ctrS  365349 non-null  float64 \n",
      " 19  var_1_ctrS                   365349 non-null  float64 \n",
      " 20  product_category_ctrS        365349 non-null  float64 \n",
      " 21  user_id_te                   365349 non-null  float64 \n",
      " 22  product_te                   365349 non-null  float64 \n",
      " 23  campaign_id_te               365349 non-null  float64 \n",
      " 24  webpage_id_te                365349 non-null  float64 \n",
      " 25  user_group_id_te             365349 non-null  float64 \n",
      " 26  gender_te                    365349 non-null  float64 \n",
      " 27  age_level_te                 365349 non-null  float64 \n",
      " 28  user_depth_te                365349 non-null  float64 \n",
      " 29  city_development_index_te    365349 non-null  float64 \n",
      " 30  var_1_te                     365349 non-null  float64 \n",
      " 31  product_category_te          365349 non-null  float64 \n",
      " 32  Day                          365349 non-null  float64 \n",
      " 33  Hour                         365349 non-null  float64 \n",
      " 34  Minute                       365349 non-null  float64 \n",
      " 35  weekday                      365349 non-null  float64 \n",
      " 36  campaign_duration_hours      364969 non-null  float64 \n",
      "dtypes: category(6), float64(31)\n",
      "memory usage: 91.3 MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_test = pd.read_csv(r\"C:\\Users\\maorb\\Classes\\Classical_ML\\YDATA-kaggle-assignment\\data\\raw\\X_test_1st.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.concat([raw_test, y_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['is_click'] = test['is_click'].to_numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv(r\"C:\\Users\\maorb\\Classes\\Classical_ML\\YDATA-kaggle-assignment\\data\\raw\\test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>campaign_id</th>\n",
       "      <th>webpage_id</th>\n",
       "      <th>user_group_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age_level</th>\n",
       "      <th>user_depth</th>\n",
       "      <th>city_development_index</th>\n",
       "      <th>var_1</th>\n",
       "      <th>product_category</th>\n",
       "      <th>...</th>\n",
       "      <th>age_level_te</th>\n",
       "      <th>user_depth_te</th>\n",
       "      <th>city_development_index_te</th>\n",
       "      <th>var_1_te</th>\n",
       "      <th>product_category_te</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "      <th>weekday</th>\n",
       "      <th>campaign_duration_hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C</td>\n",
       "      <td>405490</td>\n",
       "      <td>60305</td>\n",
       "      <td>3</td>\n",
       "      <td>Male</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065461</td>\n",
       "      <td>0.067863</td>\n",
       "      <td>0.068202</td>\n",
       "      <td>0.070970</td>\n",
       "      <td>0.083574</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>118601</td>\n",
       "      <td>28529</td>\n",
       "      <td>10</td>\n",
       "      <td>Female</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058336</td>\n",
       "      <td>0.067791</td>\n",
       "      <td>0.066689</td>\n",
       "      <td>0.070798</td>\n",
       "      <td>0.058813</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>51.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>H</td>\n",
       "      <td>359520</td>\n",
       "      <td>13787</td>\n",
       "      <td>4</td>\n",
       "      <td>Male</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058336</td>\n",
       "      <td>0.067791</td>\n",
       "      <td>0.068200</td>\n",
       "      <td>0.065399</td>\n",
       "      <td>0.058813</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>H</td>\n",
       "      <td>405490</td>\n",
       "      <td>60305</td>\n",
       "      <td>3</td>\n",
       "      <td>Male</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065097</td>\n",
       "      <td>0.067852</td>\n",
       "      <td>0.066718</td>\n",
       "      <td>0.065066</td>\n",
       "      <td>0.083392</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>87.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C</td>\n",
       "      <td>405490</td>\n",
       "      <td>60305</td>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070941</td>\n",
       "      <td>0.067863</td>\n",
       "      <td>0.068202</td>\n",
       "      <td>0.065281</td>\n",
       "      <td>0.083574</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>116.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  product campaign_id webpage_id user_group_id  gender  age_level  user_depth  \\\n",
       "0       C      405490      60305             3    Male        3.0         3.0   \n",
       "1       I      118601      28529            10  Female        4.0         3.0   \n",
       "2       H      359520      13787             4    Male        4.0         3.0   \n",
       "3       H      405490      60305             3    Male        3.0         3.0   \n",
       "4       C      405490      60305             2    Male        2.0         3.0   \n",
       "\n",
       "   city_development_index  var_1 product_category  ...  age_level_te  \\\n",
       "0                     2.0    1.0                3  ...      0.065461   \n",
       "1                     3.0    1.0                4  ...      0.058336   \n",
       "2                     2.0    0.0                4  ...      0.058336   \n",
       "3                     3.0    0.0                3  ...      0.065097   \n",
       "4                     2.0    0.0                3  ...      0.070941   \n",
       "\n",
       "   user_depth_te  city_development_index_te  var_1_te  product_category_te  \\\n",
       "0       0.067863                   0.068202  0.070970             0.083574   \n",
       "1       0.067791                   0.066689  0.070798             0.058813   \n",
       "2       0.067791                   0.068200  0.065399             0.058813   \n",
       "3       0.067852                   0.066718  0.065066             0.083392   \n",
       "4       0.067863                   0.068202  0.065281             0.083574   \n",
       "\n",
       "   Day  Hour  Minute  weekday  campaign_duration_hours  \n",
       "0  3.0  11.0     4.0      0.0                64.683333  \n",
       "1  7.0  10.0    49.0      4.0                51.583333  \n",
       "2  3.0  15.0    42.0      0.0               140.700000  \n",
       "3  5.0   7.0    24.0      2.0                87.066667  \n",
       "4  2.0   8.0    11.0      2.0               116.166667  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(test['is_click'].to_numpy()))\n",
    "print(type(y_test.to_numpy().flatten()))\n",
    "sum(test['is_click'].to_numpy() == y_test.to_numpy().flatten()) == len(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the model from the file\n",
    "with open(r\"C:\\Users\\maorb\\Classes\\Classical_ML\\YDATA-kaggle-assignment\\data\\processed\\y_test_1st.pkl\", 'wb') as file:\n",
    "    pickle.dump(y_test, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>product</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>campaign_id</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>359520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>webpage_id</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_group_id</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_level</th>\n",
       "      <td>2.791836</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_depth</th>\n",
       "      <td>2.882903</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city_development_index</th>\n",
       "      <td>2.451127</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_1</th>\n",
       "      <td>0.421193</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_category</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id_smooth</th>\n",
       "      <td>0.064283</td>\n",
       "      <td>0.311783</td>\n",
       "      <td>0.007779</td>\n",
       "      <td>0.061523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_smooth</th>\n",
       "      <td>0.067689</td>\n",
       "      <td>0.094044</td>\n",
       "      <td>0.04566</td>\n",
       "      <td>0.068735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>campaign_id_smooth</th>\n",
       "      <td>0.067667</td>\n",
       "      <td>0.090821</td>\n",
       "      <td>0.045638</td>\n",
       "      <td>0.05871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>webpage_id_smooth</th>\n",
       "      <td>0.067671</td>\n",
       "      <td>0.090821</td>\n",
       "      <td>0.054066</td>\n",
       "      <td>0.054487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_group_id_smooth</th>\n",
       "      <td>0.067693</td>\n",
       "      <td>0.087937</td>\n",
       "      <td>0.053437</td>\n",
       "      <td>0.064566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender_smooth</th>\n",
       "      <td>0.067683</td>\n",
       "      <td>0.068062</td>\n",
       "      <td>0.064794</td>\n",
       "      <td>0.068062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_level_smooth</th>\n",
       "      <td>0.067674</td>\n",
       "      <td>0.0864</td>\n",
       "      <td>0.058125</td>\n",
       "      <td>0.064876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_depth_smooth</th>\n",
       "      <td>0.067675</td>\n",
       "      <td>0.07149</td>\n",
       "      <td>0.063406</td>\n",
       "      <td>0.067875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city_development_index_smooth</th>\n",
       "      <td>0.067675</td>\n",
       "      <td>0.068114</td>\n",
       "      <td>0.066554</td>\n",
       "      <td>0.068114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_1_smooth</th>\n",
       "      <td>0.067675</td>\n",
       "      <td>0.070955</td>\n",
       "      <td>0.065288</td>\n",
       "      <td>0.065288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_category_smooth</th>\n",
       "      <td>0.067682</td>\n",
       "      <td>0.161267</td>\n",
       "      <td>0.058967</td>\n",
       "      <td>0.059263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id_te</th>\n",
       "      <td>0.054488</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_te</th>\n",
       "      <td>0.067675</td>\n",
       "      <td>0.097442</td>\n",
       "      <td>0.044625</td>\n",
       "      <td>0.068671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>campaign_id_te</th>\n",
       "      <td>0.067677</td>\n",
       "      <td>0.091618</td>\n",
       "      <td>0.044669</td>\n",
       "      <td>0.058053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>webpage_id_te</th>\n",
       "      <td>0.067677</td>\n",
       "      <td>0.091618</td>\n",
       "      <td>0.053065</td>\n",
       "      <td>0.054145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_group_id_te</th>\n",
       "      <td>0.067677</td>\n",
       "      <td>0.095613</td>\n",
       "      <td>0.052385</td>\n",
       "      <td>0.064476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender_te</th>\n",
       "      <td>0.067677</td>\n",
       "      <td>0.07021</td>\n",
       "      <td>0.064336</td>\n",
       "      <td>0.068034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_level_te</th>\n",
       "      <td>0.067675</td>\n",
       "      <td>0.093704</td>\n",
       "      <td>0.05702</td>\n",
       "      <td>0.064918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_depth_te</th>\n",
       "      <td>0.067674</td>\n",
       "      <td>0.073584</td>\n",
       "      <td>0.062456</td>\n",
       "      <td>0.067776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city_development_index_te</th>\n",
       "      <td>0.067676</td>\n",
       "      <td>0.068444</td>\n",
       "      <td>0.065814</td>\n",
       "      <td>0.068444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_1_te</th>\n",
       "      <td>0.067675</td>\n",
       "      <td>0.07129</td>\n",
       "      <td>0.065046</td>\n",
       "      <td>0.065198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_category_te</th>\n",
       "      <td>0.067675</td>\n",
       "      <td>0.25821</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.058936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id_blend</th>\n",
       "      <td>0.064283</td>\n",
       "      <td>0.311783</td>\n",
       "      <td>0.007779</td>\n",
       "      <td>0.061523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_blend</th>\n",
       "      <td>0.067689</td>\n",
       "      <td>0.094044</td>\n",
       "      <td>0.04566</td>\n",
       "      <td>0.068735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>campaign_id_blend</th>\n",
       "      <td>0.067667</td>\n",
       "      <td>0.090821</td>\n",
       "      <td>0.045638</td>\n",
       "      <td>0.05871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>webpage_id_blend</th>\n",
       "      <td>0.067671</td>\n",
       "      <td>0.090821</td>\n",
       "      <td>0.054066</td>\n",
       "      <td>0.054487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_group_id_blend</th>\n",
       "      <td>0.067693</td>\n",
       "      <td>0.087937</td>\n",
       "      <td>0.053437</td>\n",
       "      <td>0.064566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender_blend</th>\n",
       "      <td>0.067683</td>\n",
       "      <td>0.068062</td>\n",
       "      <td>0.064794</td>\n",
       "      <td>0.068062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_level_blend</th>\n",
       "      <td>0.067674</td>\n",
       "      <td>0.0864</td>\n",
       "      <td>0.058125</td>\n",
       "      <td>0.064876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_depth_blend</th>\n",
       "      <td>0.067675</td>\n",
       "      <td>0.07149</td>\n",
       "      <td>0.063406</td>\n",
       "      <td>0.067875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city_development_index_blend</th>\n",
       "      <td>0.067675</td>\n",
       "      <td>0.068114</td>\n",
       "      <td>0.066554</td>\n",
       "      <td>0.068114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_1_blend</th>\n",
       "      <td>0.067675</td>\n",
       "      <td>0.070955</td>\n",
       "      <td>0.065288</td>\n",
       "      <td>0.065288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_category_blend</th>\n",
       "      <td>0.067682</td>\n",
       "      <td>0.161267</td>\n",
       "      <td>0.058967</td>\n",
       "      <td>0.059263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day</th>\n",
       "      <td>4.145765</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hour</th>\n",
       "      <td>12.144533</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Minute</th>\n",
       "      <td>23.830973</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekday</th>\n",
       "      <td>2.359523</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>campaign_duration_hours</th>\n",
       "      <td>65.713333</td>\n",
       "      <td>143.966667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.983333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    mean         max       min       mode\n",
       "product                              NaN         NaN       NaN          C\n",
       "campaign_id                          NaN         NaN       NaN     359520\n",
       "webpage_id                           NaN         NaN       NaN      13787\n",
       "user_group_id                        NaN         NaN       NaN          3\n",
       "gender                               NaN         NaN       NaN       Male\n",
       "age_level                       2.791836         6.0       0.0        3.0\n",
       "user_depth                      2.882903         3.0       1.0        3.0\n",
       "city_development_index          2.451127         4.0       1.0        2.0\n",
       "var_1                           0.421193         1.0       0.0        0.0\n",
       "product_category                     NaN         NaN       NaN          4\n",
       "user_id_smooth                  0.064283    0.311783  0.007779   0.061523\n",
       "product_smooth                  0.067689    0.094044   0.04566   0.068735\n",
       "campaign_id_smooth              0.067667    0.090821  0.045638    0.05871\n",
       "webpage_id_smooth               0.067671    0.090821  0.054066   0.054487\n",
       "user_group_id_smooth            0.067693    0.087937  0.053437   0.064566\n",
       "gender_smooth                   0.067683    0.068062  0.064794   0.068062\n",
       "age_level_smooth                0.067674      0.0864  0.058125   0.064876\n",
       "user_depth_smooth               0.067675     0.07149  0.063406   0.067875\n",
       "city_development_index_smooth   0.067675    0.068114  0.066554   0.068114\n",
       "var_1_smooth                    0.067675    0.070955  0.065288   0.065288\n",
       "product_category_smooth         0.067682    0.161267  0.058967   0.059263\n",
       "user_id_te                      0.054488         1.0       0.0        0.0\n",
       "product_te                      0.067675    0.097442  0.044625   0.068671\n",
       "campaign_id_te                  0.067677    0.091618  0.044669   0.058053\n",
       "webpage_id_te                   0.067677    0.091618  0.053065   0.054145\n",
       "user_group_id_te                0.067677    0.095613  0.052385   0.064476\n",
       "gender_te                       0.067677     0.07021  0.064336   0.068034\n",
       "age_level_te                    0.067675    0.093704   0.05702   0.064918\n",
       "user_depth_te                   0.067674    0.073584  0.062456   0.067776\n",
       "city_development_index_te       0.067676    0.068444  0.065814   0.068444\n",
       "var_1_te                        0.067675     0.07129  0.065046   0.065198\n",
       "product_category_te             0.067675     0.25821       0.0   0.058936\n",
       "user_id_blend                   0.064283    0.311783  0.007779   0.061523\n",
       "product_blend                   0.067689    0.094044   0.04566   0.068735\n",
       "campaign_id_blend               0.067667    0.090821  0.045638    0.05871\n",
       "webpage_id_blend                0.067671    0.090821  0.054066   0.054487\n",
       "user_group_id_blend             0.067693    0.087937  0.053437   0.064566\n",
       "gender_blend                    0.067683    0.068062  0.064794   0.068062\n",
       "age_level_blend                 0.067674      0.0864  0.058125   0.064876\n",
       "user_depth_blend                0.067675     0.07149  0.063406   0.067875\n",
       "city_development_index_blend    0.067675    0.068114  0.066554   0.068114\n",
       "var_1_blend                     0.067675    0.070955  0.065288   0.065288\n",
       "product_category_blend          0.067682    0.161267  0.058967   0.059263\n",
       "Day                             4.145765         7.0       2.0        2.0\n",
       "Hour                           12.144533        23.0       0.0       10.0\n",
       "Minute                         23.830973        59.0       0.0        0.0\n",
       "weekday                         2.359523         6.0       0.0        0.0\n",
       "campaign_duration_hours        65.713333  143.966667       0.0  43.983333"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the mean, max, mode value in each column in an organized way\n",
    "def show_stats(df):\n",
    "    stats = pd.DataFrame(index=df.columns, columns=['mean', 'max', 'min','mode'])\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == 'object' or df[column].dtype.name == 'category':\n",
    "            stats.loc[column] = [np.nan, np.nan, np.nan, df[column].mode().values[0]]\n",
    "        else:\n",
    "            stats.loc[column] = [df[column].mean(), df[column].max(),df[column].min(),  df[column].mode().values[0]]\n",
    "    return stats\n",
    "\n",
    "show_stats(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>product</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>campaign_id</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>359520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>webpage_id</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_group_id</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_level</th>\n",
       "      <td>2.799319</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_depth</th>\n",
       "      <td>2.881997</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city_development_index</th>\n",
       "      <td>2.449552</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_1</th>\n",
       "      <td>0.424422</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_category</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id_smooth</th>\n",
       "      <td>0.064535</td>\n",
       "      <td>0.311783</td>\n",
       "      <td>0.007779</td>\n",
       "      <td>0.061523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_smooth</th>\n",
       "      <td>0.067701</td>\n",
       "      <td>0.094044</td>\n",
       "      <td>0.04566</td>\n",
       "      <td>0.068735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>campaign_id_smooth</th>\n",
       "      <td>0.067661</td>\n",
       "      <td>0.090821</td>\n",
       "      <td>0.045638</td>\n",
       "      <td>0.05871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>webpage_id_smooth</th>\n",
       "      <td>0.067662</td>\n",
       "      <td>0.090821</td>\n",
       "      <td>0.054066</td>\n",
       "      <td>0.054487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_group_id_smooth</th>\n",
       "      <td>0.067658</td>\n",
       "      <td>0.087937</td>\n",
       "      <td>0.053437</td>\n",
       "      <td>0.064566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender_smooth</th>\n",
       "      <td>0.06768</td>\n",
       "      <td>0.068062</td>\n",
       "      <td>0.064794</td>\n",
       "      <td>0.068062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_level_smooth</th>\n",
       "      <td>0.067633</td>\n",
       "      <td>0.0864</td>\n",
       "      <td>0.058125</td>\n",
       "      <td>0.064876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_depth_smooth</th>\n",
       "      <td>0.067672</td>\n",
       "      <td>0.07149</td>\n",
       "      <td>0.063406</td>\n",
       "      <td>0.067875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city_development_index_smooth</th>\n",
       "      <td>0.067679</td>\n",
       "      <td>0.068114</td>\n",
       "      <td>0.066554</td>\n",
       "      <td>0.068114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_1_smooth</th>\n",
       "      <td>0.067693</td>\n",
       "      <td>0.070955</td>\n",
       "      <td>0.065288</td>\n",
       "      <td>0.065288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_category_smooth</th>\n",
       "      <td>0.067704</td>\n",
       "      <td>0.161267</td>\n",
       "      <td>0.058967</td>\n",
       "      <td>0.059263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id_te</th>\n",
       "      <td>0.054881</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_te</th>\n",
       "      <td>0.067689</td>\n",
       "      <td>0.097442</td>\n",
       "      <td>0.044625</td>\n",
       "      <td>0.068671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>campaign_id_te</th>\n",
       "      <td>0.067672</td>\n",
       "      <td>0.091618</td>\n",
       "      <td>0.044669</td>\n",
       "      <td>0.058053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>webpage_id_te</th>\n",
       "      <td>0.067669</td>\n",
       "      <td>0.091618</td>\n",
       "      <td>0.053065</td>\n",
       "      <td>0.054145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_group_id_te</th>\n",
       "      <td>0.067641</td>\n",
       "      <td>0.095613</td>\n",
       "      <td>0.052385</td>\n",
       "      <td>0.064476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender_te</th>\n",
       "      <td>0.067672</td>\n",
       "      <td>0.07021</td>\n",
       "      <td>0.064336</td>\n",
       "      <td>0.068034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_level_te</th>\n",
       "      <td>0.067633</td>\n",
       "      <td>0.093704</td>\n",
       "      <td>0.05702</td>\n",
       "      <td>0.064918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_depth_te</th>\n",
       "      <td>0.067668</td>\n",
       "      <td>0.073584</td>\n",
       "      <td>0.062456</td>\n",
       "      <td>0.067776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city_development_index_te</th>\n",
       "      <td>0.06768</td>\n",
       "      <td>0.068444</td>\n",
       "      <td>0.065814</td>\n",
       "      <td>0.067996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_1_te</th>\n",
       "      <td>0.067692</td>\n",
       "      <td>0.07129</td>\n",
       "      <td>0.065046</td>\n",
       "      <td>0.065282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_category_te</th>\n",
       "      <td>0.067699</td>\n",
       "      <td>0.25821</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.058936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id_blend</th>\n",
       "      <td>0.064535</td>\n",
       "      <td>0.311783</td>\n",
       "      <td>0.007779</td>\n",
       "      <td>0.061523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_blend</th>\n",
       "      <td>0.067701</td>\n",
       "      <td>0.094044</td>\n",
       "      <td>0.04566</td>\n",
       "      <td>0.068735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>campaign_id_blend</th>\n",
       "      <td>0.067661</td>\n",
       "      <td>0.090821</td>\n",
       "      <td>0.045638</td>\n",
       "      <td>0.05871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>webpage_id_blend</th>\n",
       "      <td>0.067662</td>\n",
       "      <td>0.090821</td>\n",
       "      <td>0.054066</td>\n",
       "      <td>0.054487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_group_id_blend</th>\n",
       "      <td>0.067658</td>\n",
       "      <td>0.087937</td>\n",
       "      <td>0.053437</td>\n",
       "      <td>0.064566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender_blend</th>\n",
       "      <td>0.06768</td>\n",
       "      <td>0.068062</td>\n",
       "      <td>0.064794</td>\n",
       "      <td>0.068062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_level_blend</th>\n",
       "      <td>0.067633</td>\n",
       "      <td>0.0864</td>\n",
       "      <td>0.058125</td>\n",
       "      <td>0.064876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_depth_blend</th>\n",
       "      <td>0.067672</td>\n",
       "      <td>0.07149</td>\n",
       "      <td>0.063406</td>\n",
       "      <td>0.067875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city_development_index_blend</th>\n",
       "      <td>0.067679</td>\n",
       "      <td>0.068114</td>\n",
       "      <td>0.066554</td>\n",
       "      <td>0.068114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>var_1_blend</th>\n",
       "      <td>0.067693</td>\n",
       "      <td>0.070955</td>\n",
       "      <td>0.065288</td>\n",
       "      <td>0.065288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_category_blend</th>\n",
       "      <td>0.067704</td>\n",
       "      <td>0.161267</td>\n",
       "      <td>0.058967</td>\n",
       "      <td>0.059263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day</th>\n",
       "      <td>4.147513</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hour</th>\n",
       "      <td>12.144245</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Minute</th>\n",
       "      <td>23.815571</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weekday</th>\n",
       "      <td>2.347201</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>campaign_duration_hours</th>\n",
       "      <td>65.785436</td>\n",
       "      <td>143.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.733333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    mean       max       min       mode\n",
       "product                              NaN       NaN       NaN          C\n",
       "campaign_id                          NaN       NaN       NaN     359520\n",
       "webpage_id                           NaN       NaN       NaN      13787\n",
       "user_group_id                        NaN       NaN       NaN          3\n",
       "gender                               NaN       NaN       NaN       Male\n",
       "age_level                       2.799319       6.0       0.0        3.0\n",
       "user_depth                      2.881997       3.0       1.0        3.0\n",
       "city_development_index          2.449552       4.0       1.0        2.0\n",
       "var_1                           0.424422       1.0       0.0        0.0\n",
       "product_category                     NaN       NaN       NaN          4\n",
       "user_id_smooth                  0.064535  0.311783  0.007779   0.061523\n",
       "product_smooth                  0.067701  0.094044   0.04566   0.068735\n",
       "campaign_id_smooth              0.067661  0.090821  0.045638    0.05871\n",
       "webpage_id_smooth               0.067662  0.090821  0.054066   0.054487\n",
       "user_group_id_smooth            0.067658  0.087937  0.053437   0.064566\n",
       "gender_smooth                    0.06768  0.068062  0.064794   0.068062\n",
       "age_level_smooth                0.067633    0.0864  0.058125   0.064876\n",
       "user_depth_smooth               0.067672   0.07149  0.063406   0.067875\n",
       "city_development_index_smooth   0.067679  0.068114  0.066554   0.068114\n",
       "var_1_smooth                    0.067693  0.070955  0.065288   0.065288\n",
       "product_category_smooth         0.067704  0.161267  0.058967   0.059263\n",
       "user_id_te                      0.054881       1.0       0.0        0.0\n",
       "product_te                      0.067689  0.097442  0.044625   0.068671\n",
       "campaign_id_te                  0.067672  0.091618  0.044669   0.058053\n",
       "webpage_id_te                   0.067669  0.091618  0.053065   0.054145\n",
       "user_group_id_te                0.067641  0.095613  0.052385   0.064476\n",
       "gender_te                       0.067672   0.07021  0.064336   0.068034\n",
       "age_level_te                    0.067633  0.093704   0.05702   0.064918\n",
       "user_depth_te                   0.067668  0.073584  0.062456   0.067776\n",
       "city_development_index_te        0.06768  0.068444  0.065814   0.067996\n",
       "var_1_te                        0.067692   0.07129  0.065046   0.065282\n",
       "product_category_te             0.067699   0.25821       0.0   0.058936\n",
       "user_id_blend                   0.064535  0.311783  0.007779   0.061523\n",
       "product_blend                   0.067701  0.094044   0.04566   0.068735\n",
       "campaign_id_blend               0.067661  0.090821  0.045638    0.05871\n",
       "webpage_id_blend                0.067662  0.090821  0.054066   0.054487\n",
       "user_group_id_blend             0.067658  0.087937  0.053437   0.064566\n",
       "gender_blend                     0.06768  0.068062  0.064794   0.068062\n",
       "age_level_blend                 0.067633    0.0864  0.058125   0.064876\n",
       "user_depth_blend                0.067672   0.07149  0.063406   0.067875\n",
       "city_development_index_blend    0.067679  0.068114  0.066554   0.068114\n",
       "var_1_blend                     0.067693  0.070955  0.065288   0.065288\n",
       "product_category_blend          0.067704  0.161267  0.058967   0.059263\n",
       "Day                             4.147513       7.0       2.0        2.0\n",
       "Hour                           12.144245      23.0       0.0       10.0\n",
       "Minute                         23.815571      59.0       0.0        0.0\n",
       "weekday                         2.347201       6.0       0.0        0.0\n",
       "campaign_duration_hours        65.785436     143.9       0.0  32.733333"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_stats(X_val_fold_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(r\"C:\\Users\\maorb\\Classes\\Classical_ML\\YDATA-kaggle-assignment\\data\\raw\\train_dataset_full.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 74.48% of the test users are also in train\n",
      "✅ 100.00% of the test campaigns are also in train\n",
      "✅ 100.00% of the test products are also in train\n",
      "✅ 100.00% of the test webpage are also in train\n",
      "✅ 87.50% of the test age_level are also in train\n",
      "✅ 85.71% of the test user_group_id are also in train\n",
      "✅ 100.00% of the test product_category_1 are also in train\n",
      "✅ 66.67% of the test user_depth are also in train\n"
     ]
    }
   ],
   "source": [
    "users_train = set(raw_data['user_id'].unique())\n",
    "users_test = set(raw_test['user_id'].unique())\n",
    "campaigns_train = set(raw_data['campaign_id'].unique())\n",
    "campaigns_test = set(raw_test['campaign_id'].unique())\n",
    "products_train = set(raw_data['product'].unique())\n",
    "products_test = set(raw_test['product'].unique())\n",
    "webpage_train = set(raw_data['webpage_id'].unique())\n",
    "webpage_test = set(raw_test['webpage_id'].unique())\n",
    "age_level_train = set(raw_data['age_level'].unique())\n",
    "age_level_test = set(raw_test['age_level'].unique())\n",
    "user_group_id_train = set(raw_data['user_group_id'].unique())\n",
    "user_group_id_test = set(raw_test['user_group_id'].unique())\n",
    "product_category_1_train = set(raw_data['product_category_1'].unique())\n",
    "product_category_1_test = set(raw_test['product_category_1'].unique())\n",
    "user_depth_train = set(raw_data['user_depth'].unique())\n",
    "user_depth_test = set(raw_test['user_depth'].unique())\n",
    "\n",
    "\n",
    "\n",
    "# Count how many test users are also in train\n",
    "common_users = users_test.intersection(users_train)\n",
    "common_campaigns = campaigns_test.intersection(campaigns_train)\n",
    "common_products = products_test.intersection(products_train)\n",
    "common_webpage = webpage_test.intersection(webpage_train)\n",
    "common_age_level = age_level_test.intersection(age_level_train)\n",
    "common_user_group_id = user_group_id_test.intersection(user_group_id_train)\n",
    "common_product_category_1 = product_category_1_test.intersection(product_category_1_train)\n",
    "common_user_depth = user_depth_test.intersection(user_depth_train)\n",
    "\n",
    "\n",
    "# Compute the percentage\n",
    "percentage_users_in_train = len(common_users) / len(users_test) * 100\n",
    "percentage_campaigns_in_train = len(common_campaigns) / len(campaigns_test) * 100\n",
    "percentage_products_in_train = len(common_products) / len(products_test) * 100\n",
    "percentage_webpage_in_train = len(common_webpage) / len(webpage_test) * 100\n",
    "percentage_age_level_in_train = len(common_age_level) / len(age_level_test) * 100\n",
    "percentage_user_group_id_in_train = len(common_user_group_id) / len(user_group_id_test) * 100\n",
    "percentage_product_category_1_in_train = len(common_product_category_1) / len(product_category_1_test) * 100\n",
    "percentage_user_depth_in_train = len(common_user_depth) / len(user_depth_test) * 100\n",
    "\n",
    "\n",
    "print(f\"✅ {percentage_users_in_train:.2f}% of the test users are also in train\")\n",
    "print(f\"✅ {percentage_campaigns_in_train:.2f}% of the test campaigns are also in train\")\n",
    "print(f\"✅ {percentage_products_in_train:.2f}% of the test products are also in train\")\n",
    "print(f\"✅ {percentage_webpage_in_train:.2f}% of the test webpage are also in train\")\n",
    "print(f\"✅ {percentage_age_level_in_train:.2f}% of the test age_level are also in train\")\n",
    "print(f\"✅ {percentage_user_group_id_in_train:.2f}% of the test user_group_id are also in train\")\n",
    "print(f\"✅ {percentage_product_category_1_in_train:.2f}% of the test product_category_1 are also in train\")\n",
    "print(f\"✅ {percentage_user_depth_in_train:.2f}% of the test user_depth are also in train\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>user_id</th>\n",
       "      <th>product</th>\n",
       "      <th>campaign_id</th>\n",
       "      <th>webpage_id</th>\n",
       "      <th>user_group_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age_level</th>\n",
       "      <th>user_depth</th>\n",
       "      <th>city_development_index</th>\n",
       "      <th>var_1</th>\n",
       "      <th>is_click</th>\n",
       "      <th>product_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>171888</th>\n",
       "      <td>500379.0</td>\n",
       "      <td>2017-07-03 06:52:00</td>\n",
       "      <td>980231.0</td>\n",
       "      <td>H</td>\n",
       "      <td>405490</td>\n",
       "      <td>60305</td>\n",
       "      <td>5</td>\n",
       "      <td>Male</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200018</th>\n",
       "      <td>95832.0</td>\n",
       "      <td>2017-07-07 19:40:00</td>\n",
       "      <td>980231.0</td>\n",
       "      <td>C</td>\n",
       "      <td>405490</td>\n",
       "      <td>60305</td>\n",
       "      <td>5</td>\n",
       "      <td>Male</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        session_id            DateTime   user_id product campaign_id  \\\n",
       "171888    500379.0 2017-07-03 06:52:00  980231.0       H      405490   \n",
       "200018     95832.0 2017-07-07 19:40:00  980231.0       C      405490   \n",
       "\n",
       "       webpage_id user_group_id gender  age_level  user_depth  \\\n",
       "171888      60305             5   Male        5.0         3.0   \n",
       "200018      60305             5   Male        5.0         3.0   \n",
       "\n",
       "        city_development_index  var_1  is_click product_category  \n",
       "171888                     NaN    0.0       0.0                3  \n",
       "200018                     NaN    0.0       0.0                3  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_users = [7716.0, 1035283.0, 65994.0,75976.0,987498.0]\n",
    "cleaned_data[cleaned_data['user_id'] == 980231]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>user_id</th>\n",
       "      <th>product</th>\n",
       "      <th>campaign_id</th>\n",
       "      <th>webpage_id</th>\n",
       "      <th>product_category_1</th>\n",
       "      <th>product_category_2</th>\n",
       "      <th>user_group_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age_level</th>\n",
       "      <th>user_depth</th>\n",
       "      <th>city_development_index</th>\n",
       "      <th>var_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121580</td>\n",
       "      <td>2017-07-03 10:03</td>\n",
       "      <td>352186</td>\n",
       "      <td>H</td>\n",
       "      <td>82320</td>\n",
       "      <td>1734</td>\n",
       "      <td>1</td>\n",
       "      <td>146115.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95831</td>\n",
       "      <td>2017-07-03 14:21</td>\n",
       "      <td>980231</td>\n",
       "      <td>C</td>\n",
       "      <td>405490</td>\n",
       "      <td>60305</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>421806</td>\n",
       "      <td>2017-07-05 17:47</td>\n",
       "      <td>610332</td>\n",
       "      <td>D</td>\n",
       "      <td>404347</td>\n",
       "      <td>53587</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>585403</td>\n",
       "      <td>2017-07-06 11:01</td>\n",
       "      <td>849506</td>\n",
       "      <td>H</td>\n",
       "      <td>118601</td>\n",
       "      <td>28529</td>\n",
       "      <td>5</td>\n",
       "      <td>82527.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>496398</td>\n",
       "      <td>2017-07-02 07:50</td>\n",
       "      <td>499495</td>\n",
       "      <td>B</td>\n",
       "      <td>98970</td>\n",
       "      <td>6970</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>340792</td>\n",
       "      <td>2017-07-06 12:05</td>\n",
       "      <td>1138735</td>\n",
       "      <td>H</td>\n",
       "      <td>359520</td>\n",
       "      <td>13787</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>75278</td>\n",
       "      <td>2017-07-07 09:10</td>\n",
       "      <td>470151</td>\n",
       "      <td>C</td>\n",
       "      <td>405490</td>\n",
       "      <td>60305</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>31980</td>\n",
       "      <td>2017-07-05 16:56</td>\n",
       "      <td>538480</td>\n",
       "      <td>E</td>\n",
       "      <td>82320</td>\n",
       "      <td>1734</td>\n",
       "      <td>1</td>\n",
       "      <td>146115.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>54082</td>\n",
       "      <td>2017-07-02 15:06</td>\n",
       "      <td>345136</td>\n",
       "      <td>C</td>\n",
       "      <td>405490</td>\n",
       "      <td>60305</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>236163</td>\n",
       "      <td>2017-07-07 08:28</td>\n",
       "      <td>487171</td>\n",
       "      <td>I</td>\n",
       "      <td>118601</td>\n",
       "      <td>28529</td>\n",
       "      <td>4</td>\n",
       "      <td>82527.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   session_id          DateTime  user_id product  campaign_id  webpage_id  \\\n",
       "0      121580  2017-07-03 10:03   352186       H        82320        1734   \n",
       "1       95831  2017-07-03 14:21   980231       C       405490       60305   \n",
       "2      421806  2017-07-05 17:47   610332       D       404347       53587   \n",
       "3      585403  2017-07-06 11:01   849506       H       118601       28529   \n",
       "4      496398  2017-07-02 07:50   499495       B        98970        6970   \n",
       "5      340792  2017-07-06 12:05  1138735       H       359520       13787   \n",
       "6       75278  2017-07-07 09:10   470151       C       405490       60305   \n",
       "7       31980  2017-07-05 16:56   538480       E        82320        1734   \n",
       "8       54082  2017-07-02 15:06   345136       C       405490       60305   \n",
       "9      236163  2017-07-07 08:28   487171       I       118601       28529   \n",
       "\n",
       "   product_category_1  product_category_2  user_group_id  gender  age_level  \\\n",
       "0                   1            146115.0            2.0    Male        1.0   \n",
       "1                   3                 NaN            6.0    Male        5.0   \n",
       "2                   1                 NaN            3.0    Male        2.0   \n",
       "3                   5             82527.0            3.0    Male        2.0   \n",
       "4                   2                 NaN            9.0  Female        2.0   \n",
       "5                   4                 NaN            3.0    Male        2.0   \n",
       "6                   3                 NaN            4.0    Male        3.0   \n",
       "7                   1            146115.0            3.0    Male        2.0   \n",
       "8                   3                 NaN            2.0    Male        1.0   \n",
       "9                   4             82527.0            4.0    Male        3.0   \n",
       "\n",
       "   user_depth  city_development_index  var_1  \n",
       "0         3.0                     4.0      1  \n",
       "1         3.0                     NaN      0  \n",
       "2         3.0                     1.0      0  \n",
       "3         3.0                     3.0      0  \n",
       "4         3.0                     4.0      1  \n",
       "5         3.0                     4.0      0  \n",
       "6         3.0                     2.0      0  \n",
       "7         3.0                     3.0      1  \n",
       "8         3.0                     NaN      0  \n",
       "9         3.0                     2.0      0  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean rows per user in train: 2.88\n",
      "Mean rows per user in test: 1.45\n"
     ]
    }
   ],
   "source": [
    "#mean rows of users in train\n",
    "mean_rows_per_user_train = raw_data.groupby('user_id').size().mean()\n",
    "mean_rows_per_user_test = raw_test.groupby('user_id').size().mean()\n",
    "print(f\"Mean rows per user in train: {mean_rows_per_user_train:.2f}\")\n",
    "print(f\"Mean rows per user in test: {mean_rows_per_user_test:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "users_train = raw_data['user_id'].unique()\n",
    "users_test = raw_test['user_id'].unique()\n",
    "#Check if the users in the test set are a subset of the users in the train set\n",
    "print(np.all(np.isin(users_test, users_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 60228 entries, 0 to 60227\n",
      "Data columns (total 15 columns):\n",
      " #   Column                   Non-Null Count  Dtype   \n",
      "---  ------                   --------------  -----   \n",
      " 0   product                  60228 non-null  category\n",
      " 1   campaign_id              60228 non-null  category\n",
      " 2   webpage_id               60228 non-null  category\n",
      " 3   user_group_id            60228 non-null  category\n",
      " 4   gender                   60228 non-null  category\n",
      " 5   age_level                60228 non-null  float64 \n",
      " 6   user_depth               60228 non-null  float64 \n",
      " 7   city_development_index   60228 non-null  float64 \n",
      " 8   var_1                    60228 non-null  int64   \n",
      " 9   product_category         60228 non-null  category\n",
      " 10  Day                      60228 non-null  int32   \n",
      " 11  Hour                     60228 non-null  int32   \n",
      " 12  Minute                   60228 non-null  int32   \n",
      " 13  weekday                  60228 non-null  int32   \n",
      " 14  campaign_duration_hours  60228 non-null  float64 \n",
      "dtypes: category(6), float64(4), int32(4), int64(1)\n",
      "memory usage: 3.6 MB\n"
     ]
    }
   ],
   "source": [
    "X_test_1st.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60223</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60224</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60225</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60226</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60227</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60228 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0\n",
       "0      0.0\n",
       "1      1.0\n",
       "2      1.0\n",
       "3      0.0\n",
       "4      0.0\n",
       "...    ...\n",
       "60223  1.0\n",
       "60224  0.0\n",
       "60225  0.0\n",
       "60226  0.0\n",
       "60227  0.0\n",
       "\n",
       "[60228 rows x 1 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First value should be the header. Strip header and make it first values in first row\n",
    "predictions_1st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9319820664496002"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_fold_3.value_counts()[0]/y_val_fold_3.value_counts().sum()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "session_id                  4166\n",
       "DateTime                    4109\n",
       "user_id                     4108\n",
       "product                     4174\n",
       "campaign_id                 4188\n",
       "webpage_id                  4157\n",
       "product_category_1          4201\n",
       "product_category_2        308235\n",
       "user_group_id              19319\n",
       "gender                     19324\n",
       "age_level                  19309\n",
       "user_depth                 19322\n",
       "city_development_index    108137\n",
       "var_1                       4161\n",
       "is_click                    4132\n",
       "dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in 'campaign_duration_days' within each campaign_id group using the mode\n",
    "X_train['age_level'] = X_train.groupby('user_id', observed=True)['campaign_duration_hours'].transform(\n",
    "    lambda x: x.ffill().bfill() if not x.mode().empty else x.fillna(0)\n",
    ")\n",
    "\n",
    "X_test['campaign_duration_hours'] = X_test.groupby('webpage_id', observed=True)['campaign_duration_hours'].transform(\n",
    "    lambda x: x.ffill().bfill() if not x.mode().empty else x.fillna(0)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product                    0\n",
       "campaign_id                0\n",
       "webpage_id                 0\n",
       "user_group_id              0\n",
       "gender                     0\n",
       "age_level                  0\n",
       "user_depth                 0\n",
       "city_development_index     0\n",
       "var_1                      0\n",
       "product_category           0\n",
       "Day                        0\n",
       "Hour                       0\n",
       "Minute                     0\n",
       "weekday                    0\n",
       "campaign_duration_hours    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = X_train.select_dtypes(include=['category', 'object']).columns\n",
    "X_train2 = X_train.copy()\n",
    "\n",
    "for col in categorical_cols:\n",
    "    mode_value = X_train2.loc[X_train2[col] != \"missing\", col].mode()[0]\n",
    "    mask = X_train2[col] == \"missing\"\n",
    "    X_train2.loc[mask, col] = mode_value\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test2 = X_test.copy()\n",
    "\n",
    "for col in categorical_cols:\n",
    "    mode_value = X_test2.loc[X_test2[col] != \"missing\", col].mode()[0]\n",
    "    mask = X_test2[col] == \"missing\"\n",
    "    X_test2.loc[mask, col] = mode_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((293307, 14),\n",
       " (73327, 14),\n",
       " (293307,),\n",
       " (73327,),\n",
       " (73160, 1),\n",
       " (365798, 14),\n",
       " (389163, 15))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape, predictions.shape, cleaned_data.shape, raw_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product                        0\n",
       "campaign_id                    0\n",
       "webpage_id                     0\n",
       "gender                         0\n",
       "age_level                  11626\n",
       "user_depth                 11630\n",
       "city_development_index     79202\n",
       "var_1                         94\n",
       "product_category               0\n",
       "Day                            0\n",
       "Hour                           0\n",
       "Minute                         0\n",
       "weekday                        0\n",
       "campaign_duration_hours        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((292638, 13),\n",
       " (73160, 13),\n",
       " (292638,),\n",
       " (73160,),\n",
       " (73160, 1),\n",
       " (365798, 14),\n",
       " (389163, 15))"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape, predictions.shape, cleaned_data.shape, raw_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19510, 15)"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find how many duplicated rows we have\n",
    "duplicates = raw_data[raw_data.duplicated()]\n",
    "duplicates.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month\n",
      "Day\n",
      "Hour\n",
      "Minute\n",
      "weekday\n",
      "product\n",
      "campaign_id\n",
      "webpage_id\n",
      "gender\n",
      "age_level\n",
      "user_depth\n",
      "city_development_index\n",
      "var_1\n",
      "product_category\n",
      "Month\n",
      "Day\n",
      "Hour\n",
      "Minute\n",
      "weekday\n",
      "product\n",
      "campaign_id\n",
      "webpage_id\n",
      "gender\n",
      "age_level\n",
      "user_depth\n",
      "city_development_index\n",
      "var_1\n",
      "product_category\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def feature_generation(df):\n",
    "    \"\"\"Generate date/time features and fill missing values in a faster, \n",
    "       more scalable way without repeated group-based ffill/bfill.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # If not already a datetime, convert:\n",
    "    # df['DateTime'] = pd.to_datetime(df['DateTime'])\n",
    "    \n",
    "    # -- 1) Create date/time features --\n",
    "    df['Month'] = df['DateTime'].dt.month\n",
    "    df['Day'] = df['DateTime'].dt.day\n",
    "    df['Hour'] = df['DateTime'].dt.hour\n",
    "    df['Minute'] = df['DateTime'].dt.minute\n",
    "    df['weekday'] = df['DateTime'].dt.weekday\n",
    "    \n",
    "    # -- 2) Drop unnecessary columns --\n",
    "    df.drop(columns=['DateTime', 'session_id'], inplace=True, errors='ignore')\n",
    "    \n",
    "    # -- 3) Make user_id a consistent type --\n",
    "    # (Strings are often safer keys for merges.)\n",
    "    df['user_id'] = df['user_id'].astype(str)\n",
    "    \n",
    "    # -- 4) Identify columns to fill by median vs. mode --\n",
    "    #    (You can tune these lists as needed.)\n",
    "    columns_to_fill_median = ['Month', 'Day', 'Hour', 'Minute', 'weekday']\n",
    "    columns_to_fill_mode = [\n",
    "        'product', 'campaign_id', 'webpage_id', 'gender', \n",
    "        'age_level', 'user_depth', 'city_development_index', \n",
    "        'var_1', 'product_category'\n",
    "    ]\n",
    "    \n",
    "    # Keep only columns that actually exist in df\n",
    "    columns_to_fill_median = [c for c in columns_to_fill_median if c in df.columns]\n",
    "    columns_to_fill_mode = [c for c in columns_to_fill_mode if c in df.columns]\n",
    "    \n",
    "    # -- 5) Precompute the user-level medians/modes in one pass each --\n",
    "    if columns_to_fill_median:\n",
    "        median_df = (\n",
    "            df.groupby('user_id')[columns_to_fill_median]\n",
    "            .median()\n",
    "            .reset_index()\n",
    "        )\n",
    "    \n",
    "    # Mode can be tricky (pandas mode can return multiple values).\n",
    "    # We'll define a custom aggregator that picks the first mode if multiple modes exist.\n",
    "    def agg_mode(s):\n",
    "        m = s.mode(dropna=True)\n",
    "        return m.iloc[0] if len(m) > 0 else np.nan\n",
    "        \n",
    "    if columns_to_fill_mode:\n",
    "        mode_df = (\n",
    "            df.groupby('user_id')[columns_to_fill_mode]\n",
    "            .agg(agg_mode)\n",
    "            .reset_index()\n",
    "        )\n",
    "        \n",
    "    # -- 6) Merge those statistics back to df --\n",
    "    # This is usually much more performant than repeated group transforms:\n",
    "    if columns_to_fill_median:\n",
    "        df = df.merge(\n",
    "            median_df, \n",
    "            on='user_id', \n",
    "            suffixes=('', '_median')\n",
    "        )\n",
    "    if columns_to_fill_mode:\n",
    "        df = df.merge(\n",
    "            mode_df, \n",
    "            on='user_id', \n",
    "            suffixes=('', '_mode')\n",
    "        )\n",
    "        \n",
    "    # -- 7) Fill missing values in df using the merged median/mode --\n",
    "    if columns_to_fill_median:\n",
    "        for col in columns_to_fill_median:\n",
    "            df[col] = df[col].fillna(df[f'{col}_median'])\n",
    "            df.drop(columns=[f'{col}_median'], inplace=True, errors='ignore')\n",
    "            \n",
    "    if columns_to_fill_mode:\n",
    "        for col in columns_to_fill_mode:\n",
    "            df[col] = df[col].fillna(df[f'{col}_mode'])\n",
    "            df.drop(columns=[f'{col}_mode'], inplace=True, errors='ignore')\n",
    "    \n",
    "    for col in columns_to_fill_median:\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "    for col in columns_to_fill_mode:\n",
    "        df[col] = df[col].fillna(df[col].mode()[0])\n",
    "    \n",
    "    df.drop(columns=['user_id','user_group_id'], inplace=True, errors='ignore')\n",
    "            \n",
    "    return df\n",
    "\n",
    "# Example usage:\n",
    "X_train_u = feature_generation(X_train)\n",
    "X_test_u  = feature_generation(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_with_mode(df: pd.DataFrame, columns: list):\n",
    "    df = df.copy()\n",
    "    for column in columns:\n",
    "        if column in df.columns:\n",
    "            mode_value = df[column].mode()[0]  # Calculate the mode\n",
    "            df[column] = df[column].fillna(mode_value)  # Fill missing values with the mode\n",
    "    return df\n",
    "\n",
    "def fill_missing_with_median(df: pd.DataFrame, columns: list):\n",
    "    df = df.copy()\n",
    "    for column in columns:\n",
    "        if column in df.columns:\n",
    "            median_value = df[column].median()  # Calculate the median\n",
    "            df[column] = df[column].fillna(median_value)  # Fill missing values with the median\n",
    "    return df   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['session_id', 'DateTime', 'user_id', 'product', 'campaign_id',\n",
       "       'webpage_id', 'user_group_id', 'gender', 'age_level', 'user_depth',\n",
       "       'city_development_index', 'var_1', 'product_category'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_with_mode(df: pd.DataFrame, columns: list):\n",
    "    df = df.copy()\n",
    "    for column in columns:\n",
    "        if column in df.columns:\n",
    "            mode_value = df[column].mode()[0]  # Calculate the mode\n",
    "            df[column] = df[column].fillna(mode_value)  # Fill missing values with the mode\n",
    "    return df\n",
    "\n",
    "def fill_missing_with_median(df: pd.DataFrame, columns: list):\n",
    "    df = df.copy()\n",
    "    for column in columns:\n",
    "        if column in df.columns:\n",
    "            median_value = df[column].median()  # Calculate the median\n",
    "            df[column] = df[column].fillna(median_value)  # Fill missing values with the median\n",
    "    return df\n",
    "\n",
    "def determine_categorical_features(df: pd.DataFrame, cat_features: list = None):\n",
    "\n",
    "    if cat_features:\n",
    "        cat_features = [col for col in cat_features if col in df.columns]\n",
    "    else:\n",
    "        cat_features = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "    for col in cat_features:\n",
    "        if col in df.columns:\n",
    "            # Ensure column is treated as category\n",
    "            df[col] = df[col].astype(\"category\")\n",
    "\n",
    "            # Add \"missing\" only if it's not already a category\n",
    "            if \"missing\" not in df[col].cat.categories:\n",
    "                df[col] = df[col].cat.add_categories(\"missing\")\n",
    "\n",
    "            # Fill missing values with \"missing\"\n",
    "            df[col] = df[col].fillna(\"missing\")\n",
    "\n",
    "    return cat_features\n",
    "\n",
    "def feature_generation2(df, use_missing_with_mode=False, get_dumm=False, catb=True, cat_features=None):\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    # Generate time-based features\n",
    "    df['Month'] = df['DateTime'].dt.month\n",
    "    df['Day'] = df['DateTime'].dt.day\n",
    "    df['Hour'] = df['DateTime'].dt.hour\n",
    "    df['Minute'] = df['DateTime'].dt.minute\n",
    "    df['weekday'] = df['DateTime'].dt.weekday\n",
    "\n",
    "    # Handle categorical features if `catb` is True\n",
    "    if catb:\n",
    "        cat_features = determine_categorical_features(df, cat_features)\n",
    "\n",
    "    # Fill missing values\n",
    "    if use_missing_with_mode:\n",
    "        print(\"Filling missing values with mode\")\n",
    "        columns_to_fill_mode = [\"product\", \"campaign_id\", \"webpage_id\", \"user_group_id\", \"gender\", \"age_level\", \"user_depth\", \"city_development_index\", \"var_1\", \"product_category\",\n",
    "                                \"Month\", \"Day\", \"Hour\"]\n",
    "        df = fill_missing_with_mode(df, columns_to_fill_mode)\n",
    "\n",
    "    columns_to_fill_median = [\"Month\", \"Day\", \"Hour\", \"Minute\", \"weekday\", \"city_development_index\", \"age_level\", \"user_depth\"]\n",
    "    df['campaign_id'] = df['campaign_id'].fillna(df['campaign_id'].mode()[0]) #userid and sessionid have nas. What can we do else?\n",
    "    df['var_1'] = df['var_1'].fillna(df['var_1'].mode()[0])\n",
    "    df = fill_missing_with_median(df, columns_to_fill_median)\n",
    "\n",
    "    # Generate campaign-based features\n",
    "    df['start_date'] = df.groupby('campaign_id', observed=True)['DateTime'].transform('min')\n",
    "    df['campaign_duration'] = df['DateTime'] - df['start_date']\n",
    "    df['campaign_duration_days'] = df['campaign_duration'].dt.total_seconds() / (3600*24)\n",
    "    df['campaign_duration_days'] = df['campaign_duration_days'].fillna(\n",
    "        df.groupby('campaign_id', observed=True)['campaign_duration_days'].transform(lambda x: x.mode().iloc[0])).astype(int)\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    df.drop(columns=['DateTime', 'start_date', 'campaign_duration', 'session_id', 'user_id', 'user_group_id'], inplace=True)\n",
    "\n",
    "    # One-hot encoding if `get_dumm` is True\n",
    "    if get_dumm:\n",
    "        columns_to_d = [\"product\", \"campaign_id\", \"webpage_id\", \"product_category\", \"gender\"]\n",
    "        df = pd.get_dummies(df, columns=columns_to_d)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'DateTime'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\maorb\\anaconda3\\envs\\Yofi\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'DateTime'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_train2 \u001b[38;5;241m=\u001b[39m \u001b[43mfeature_generation2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m X_test2 \u001b[38;5;241m=\u001b[39m feature_generation2(X_test)\n\u001b[0;32m      3\u001b[0m cat_features \u001b[38;5;241m=\u001b[39m determine_categorical_features(X_train2)\n",
      "Cell \u001b[1;32mIn[25], line 43\u001b[0m, in \u001b[0;36mfeature_generation2\u001b[1;34m(df, use_missing_with_mode, get_dumm, catb, cat_features)\u001b[0m\n\u001b[0;32m     40\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Generate time-based features\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMonth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDateTime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mmonth\n\u001b[0;32m     44\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDay\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDateTime\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mday\n\u001b[0;32m     45\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHour\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDateTime\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mhour\n",
      "File \u001b[1;32mc:\\Users\\maorb\\anaconda3\\envs\\Yofi\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\maorb\\anaconda3\\envs\\Yofi\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'DateTime'"
     ]
    }
   ],
   "source": [
    "X_train2 = feature_generation2(X_train)\n",
    "X_test2 = feature_generation2(X_test)\n",
    "cat_features = determine_categorical_features(X_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_d = [\"product\", \"campaign_id\", \"webpage_id\", \"product_category\", \"gender\",\"user_group_id\"]\n",
    "X_train_d = pd.get_dummies(X_train2, columns=columns_to_d)\n",
    "X_test_d = pd.get_dummies(X_test2, columns=columns_to_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender\n",
       "Male       248397\n",
       "Female      32776\n",
       "missing     11465\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train2['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.040829346092503986"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42,class_weight='balanced')\n",
    "rf.fit(X_train_d, y_train)\n",
    "y_pred = rf.predict(X_test_d)\n",
    "\n",
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.13929004519898577\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Compute sample weights\n",
    "sample_weights = compute_sample_weight(class_weight=\"balanced\", y=y_train)\n",
    "\n",
    "# Train AdaBoost with sample weights\n",
    "adamodel = AdaBoostClassifier(n_estimators=100, random_state=42, algorithm='SAMME')\n",
    "adamodel.fit(X_train_d, y_train, sample_weight=sample_weights)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = adamodel.predict(X_test_d)\n",
    "\n",
    "# Evaluate\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"F1 Score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Apply SMOTE to balance the training set\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train2, y_train)\n",
    "\n",
    "# Train Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred2 = rf.predict(X_test2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14371159806427056\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, classification_report\n",
    "#adjuct the balance of the classes\n",
    "model = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42, solver='liblinear',\n",
    "                           penalty='l2', C=1)\n",
    "model.fit(X_train_d, y_train)\n",
    "\n",
    "y_pred_LR = model.predict(X_test_d)\n",
    "print(f1_score(y_test, y_pred_LR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.14191397, 0.14630052, 0.14374937, 0.1396726 , 0.14359774])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "model = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42, solver='liblinear',\n",
    "                           penalty='l2', C=1)\n",
    "#run it on all\n",
    "scores = cross_val_score(model, X_train_d, y_train, cv=5, scoring='f1')\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14304684"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([0.14191397, 0.14630052, 0.14374937, 0.1396726 , 0.14359774])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complement Bayes:  [0.13291654 0.13741399 0.13816756 0.13567328 0.13666374]\n",
      "Gaussian Bayes:  [0.13584671 0.14390066 0.13671663 0.13889985 0.13384344]\n",
      "Multinomial Bayes:  [0.00100806 0.         0.         0.         0.        ]\n",
      "Bernoulli Bayes:  [0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "#import cross_val_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB, ComplementNB\n",
    "\n",
    "\n",
    "model1 = ComplementNB()\n",
    "model2 = GaussianNB()\n",
    "model3 = MultinomialNB()\n",
    "model4 = BernoulliNB()   \n",
    "print(\"Complement Bayes: \", cross_val_score(model1, X_train_d, y_train, cv=5, scoring='f1'))\n",
    "print(\"Gaussian Bayes: \", cross_val_score(model2, X_train_d, y_train, cv=5, scoring='f1'))\n",
    "print(\"Multinomial Bayes: \", cross_val_score(model3, X_train_d, y_train, cv=5, scoring='f1'))\n",
    "print(\"Bernoulli Bayes: \", cross_val_score(model4, X_train_d, y_train, cv=5, scoring='f1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complement Bayes: [0.13285236 0.13694722 0.13831141 0.13642458 0.13636068]\n",
      "Gaussian Bayes: [0.13413932 0.14055185 0.13428364 0.13605852 0.13060411]\n",
      "Multinomial Bayes: [0. 0. 0. 0. 0.]\n",
      "Bernoulli Bayes: [0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB, ComplementNB\n",
    "\n",
    "# Compute sample weights\n",
    "sample_weights = compute_sample_weight(class_weight=\"balanced\", y=y_train)\n",
    "\n",
    "# Define models without random_state\n",
    "model1 = ComplementNB()\n",
    "model2 = GaussianNB()\n",
    "model3 = MultinomialNB()\n",
    "model4 = BernoulliNB()\n",
    "\n",
    "# Fit models with sample weights\n",
    "model1.fit(X_train_d, y_train, sample_weight=sample_weights)\n",
    "model2.fit(X_train_d, y_train, sample_weight=sample_weights)\n",
    "model3.fit(X_train_d, y_train, sample_weight=sample_weights)\n",
    "model4.fit(X_train_d, y_train, sample_weight=sample_weights)\n",
    "\n",
    "# Cross-validation with sample weights\n",
    "print(\"Complement Bayes:\", cross_val_score(model1, X_train_d, y_train, cv=5, scoring='f1'))\n",
    "print(\"Gaussian Bayes:\", cross_val_score(model2, X_train_d, y_train, cv=5, scoring='f1'))\n",
    "print(\"Multinomial Bayes:\", cross_val_score(model3, X_train_d, y_train, cv=5, scoring='f1'))\n",
    "print(\"Bernoulli Bayes:\", cross_val_score(model4, X_train_d, y_train, cv=5, scoring='f1'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.14070554937834834\n"
     ]
    }
   ],
   "source": [
    "#import sgdclassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "model = SGDClassifier(random_state=42, loss='log_loss', class_weight='balanced')\n",
    "model.fit(X_train_d, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test_d)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f\"F1-score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score with RBF SGD: 0.12733747750277624\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.kernel_approximation import RBFSampler,Nystroem\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load CTR data (Assume df is the CTR dataset)\n",
    "\n",
    "\n",
    "# Define the full pipeline\n",
    "rbf_pipeline = Pipeline([\n",
    "    (\"rbf_feature_map\", Nystroem(gamma=1, n_components=300)),  # RBF feature map\n",
    "    (\"sgd\", SGDClassifier(random_state=42, loss='log_loss', class_weight='balanced'))  # SGD with log-loss\n",
    "])\n",
    "\n",
    "# Split the data\n",
    "\n",
    "\n",
    "# Train the model\n",
    "rbf_pipeline.fit(X_train_d, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_rbf = rbf_pipeline.predict(X_test_d)\n",
    "\n",
    "# Evaluate\n",
    "f1_rbf = f1_score(y_test, y_pred_rbf)\n",
    "print(f\"F1-score with RBF SGD: {f1_rbf}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Baseline? :()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9323260378678943"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data['is_click'].value_counts()[0]/cleaned_data['is_click'].value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1- cleaned_data['is_click'].value_counts()[0]/cleaned_data['is_click'].value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1 = X_train.drop(columns=['session_id', 'DateTime', 'user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Configure logger\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def objective(trial):\n",
    "    # Define hyperparameters to optimize\n",
    "    params = {\n",
    "        \"iterations\": 1000,\n",
    "        \"depth\": trial.suggest_int(\"depth\", 4, 8),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.1),\n",
    "        \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 1, 100),\n",
    "        \"grow_policy\": trial.suggest_categorical(\"grow_policy\", [\"SymmetricTree\", \"Depthwise\", \"Lossguide\"]),\n",
    "        \"bootstrap_type\": trial.suggest_categorical(\"bootstrap_type\", [\"Bayesian\", \"Bernoulli\"]),\n",
    "        \"class_weights\": [1, 1 / 0.06767396213210575],  # Fixed class weights\n",
    "        \"eval_metric\": \"F1\",\n",
    "        \"early_stopping_rounds\": 100,\n",
    "        \"random_seed\": 42,\n",
    "        \"verbose\": 0,\n",
    "    }\n",
    "\n",
    "    # Add bagging_temperature or subsample based on bootstrap_type\n",
    "    if params[\"bootstrap_type\"] == \"Bayesian\":\n",
    "        params[\"bagging_temperature\"] = trial.suggest_float(\"bagging_temperature\", 0.0, 1.0)\n",
    "    elif params[\"bootstrap_type\"] == \"Bernoulli\":\n",
    "        params[\"subsample\"] = trial.suggest_float(\"subsample\", 0.5, 1.0)\n",
    "\n",
    "    # Initialize the model\n",
    "    model = CatBoostClassifier(**params)\n",
    "\n",
    "    # Cross-validation\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scores = []\n",
    "\n",
    "    for fold_index, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train)):\n",
    "        # Create train-validation splits\n",
    "        X_train_cv, X_val_cv = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_train_cv, y_val_cv = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "        # Check if both classes are present in the training and validation sets\n",
    "        if len(np.unique(y_train_cv)) < 2 or len(np.unique(y_val_cv)) < 2:\n",
    "            logger.warning(f\"Fold {fold_index}: Skipping due to only one class in y_train_cv or y_val_cv\")\n",
    "            continue\n",
    "\n",
    "        # Train the model\n",
    "        model.fit(\n",
    "            X_train_cv,\n",
    "            y_train_cv,\n",
    "            cat_features=cat_features,\n",
    "            eval_set=(X_val_cv, y_val_cv),\n",
    "            early_stopping_rounds=50,\n",
    "            use_best_model=True\n",
    "        )\n",
    "\n",
    "        # Predict on the validation set\n",
    "        y_pred_val = model.predict(X_val_cv)\n",
    "\n",
    "        # Calculate F1 score\n",
    "        try:\n",
    "            score = f1_score(y_val_cv, y_pred_val)\n",
    "            scores.append(score)\n",
    "            logger.info(f\"Fold {fold_index}: F1 score = {score}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error calculating F1 score on fold {fold_index}: {e}\")\n",
    "            continue\n",
    "\n",
    "    # Return the average F1 score across folds\n",
    "    if scores:\n",
    "        return np.mean(scores)\n",
    "    else:\n",
    "        logger.warning(\"All folds were skipped. Returning 0.0.\")\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        \"iterations\": 1000,\n",
    "        \"depth\": trial.suggest_int(\"depth\", 3, 5),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.08, 0.15),\n",
    "        \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 15, 40),\n",
    "        \"random_strength\": trial.suggest_float(\"random_strength\", 0.1, 1.5),\n",
    "        #\"bagging_temperature\": trial.suggest_float(\"bagging_temperature\", 0.0, 1.0),\n",
    "        \"grow_policy\": trial.suggest_categorical(\"grow_policy\", [\"SymmetricTree\", \"Depthwise\"]),\n",
    "        \"bootstrap_type\": trial.suggest_categorical(\"bootstrap_type\", [\"Bayesian\", \"Bernoulli\", \"MVS\"]),\n",
    "        #\"class_weights\": [1, 1 / trial.suggest_float(\"class_weight_ratio\", 1.0, 10.0)],\n",
    "        \"eval_metric\": \"F1\",\n",
    "        \"class_weights\": [1, 1 / 0.06767396213210575],\n",
    "        \"early_stopping_rounds\": 100,\n",
    "        \"random_seed\": 42,\n",
    "        \"verbose\": 0,\n",
    "    }\n",
    "\n",
    "    if params[\"bootstrap_type\"] == \"Bayesian\":\n",
    "        params[\"bagging_temperature\"] = trial.suggest_float(\"bagging_temperature\", 0.1, 0.8)\n",
    "    if params['grow_policy'] == 'Depthwise':\n",
    "        params['min_data_in_leaf'] = trial.suggest_int(\"min_data_in_leaf\", 1, 10)\n",
    "    elif params[\"bootstrap_type\"] == \"Bernoulli\":\n",
    "        params[\"subsample\"] = trial.suggest_float(\"subsample\", 0.6, .9)\n",
    "\n",
    "    model = CatBoostClassifier(**params)\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=y_train\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        cat_features=cat_features,\n",
    "        eval_set=(X_val, y_val),\n",
    "        early_stopping_rounds=50,\n",
    "        use_best_model=True\n",
    "    )\n",
    "\n",
    "    y_pred_val = model.predict(X_val)\n",
    "    f1 = f1_score(y_val, y_pred_val)\n",
    "    return f1\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create study that aims to maximize F1\n",
    "import optuna\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "\n",
    "# Optimize over 'objective' for a certain number of trials\n",
    "study.optimize(objective, n_trials=100, show_progress_bar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "params2 = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'depth': 4,\n",
       " 'learning_rate': 0.12751986192358583,\n",
       " 'l2_leaf_reg': 28.56605893525792,\n",
       " 'random_strength': 1.4329403288787461,\n",
       " 'grow_policy': 'SymmetricTree',\n",
       " 'bootstrap_type': 'Bayesian',\n",
       " 'bagging_temperature': 0.31033906089109137}"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "params =  study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'depth': 4,\n",
       " 'learning_rate': 0.1264579533008154,\n",
       " 'l2_leaf_reg': 30.03825012048619,\n",
       " 'grow_policy': 'SymmetricTree',\n",
       " 'subsample': 0.7558041984536977}"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "completed_trials = [trial for trial in study.trials if trial.state == optuna.trial.TrialState.COMPLETE]\n",
    "\n",
    "# Sort the trials by the value (objective) in descending order (maximize performance)\n",
    "sorted_trials = sorted(completed_trials, key=lambda trial: trial.value, reverse=True)\n",
    "\n",
    "# Extract the top 5 parameter sets\n",
    "top_5_params = [trial.params for trial in sorted_trials[:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'depth': 4,\n",
       "  'learning_rate': 0.12751986192358583,\n",
       "  'l2_leaf_reg': 28.56605893525792,\n",
       "  'random_strength': 1.4329403288787461,\n",
       "  'grow_policy': 'SymmetricTree',\n",
       "  'bootstrap_type': 'Bayesian',\n",
       "  'bagging_temperature': 0.31033906089109137},\n",
       " {'depth': 4,\n",
       "  'learning_rate': 0.1248507739152174,\n",
       "  'l2_leaf_reg': 24.826390939702126,\n",
       "  'random_strength': 1.4094504738081457,\n",
       "  'grow_policy': 'SymmetricTree',\n",
       "  'bootstrap_type': 'Bayesian',\n",
       "  'bagging_temperature': 0.3773129429403069},\n",
       " {'depth': 4,\n",
       "  'learning_rate': 0.10889824051169908,\n",
       "  'l2_leaf_reg': 24.326419520439615,\n",
       "  'random_strength': 1.4322494067371123,\n",
       "  'grow_policy': 'SymmetricTree',\n",
       "  'bootstrap_type': 'Bayesian',\n",
       "  'bagging_temperature': 0.481893039827185},\n",
       " {'depth': 4,\n",
       "  'learning_rate': 0.1178823321005181,\n",
       "  'l2_leaf_reg': 22.111997922334616,\n",
       "  'random_strength': 1.428924662511862,\n",
       "  'grow_policy': 'SymmetricTree',\n",
       "  'bootstrap_type': 'Bayesian',\n",
       "  'bagging_temperature': 0.4705315566363708},\n",
       " {'depth': 4,\n",
       "  'learning_rate': 0.11005049955756034,\n",
       "  'l2_leaf_reg': 31.17690823161114,\n",
       "  'random_strength': 1.4254682793767415,\n",
       "  'grow_policy': 'SymmetricTree',\n",
       "  'bootstrap_type': 'Bayesian',\n",
       "  'bagging_temperature': 0.31345433019930435}]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_5_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Categorical features: ['product', 'campaign_id', 'webpage_id', 'user_group_id', 'gender', 'product_category', 'part_of_day']\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "# Define the ModelTrainer class\n",
    "class ModelTrainer:\n",
    "    def __init__(self, data_dir: False, model_name: str = \"catboost\", cat_features: list = None):\n",
    "        #self.data_dir = Path(data_dir)\n",
    "        self.model_name = model_name\n",
    "        self.cat_features = cat_features\n",
    "\n",
    "        logging.basicConfig(level=logging.INFO)\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "\n",
    "    def load_data(self):\n",
    "        self.logger.info(f\"Loading preprocessed data from {self.data_dir}...\")\n",
    "        X_train = pd.read_pickle(self.data_dir / \"X_train.pkl\")\n",
    "        y_train = pd.read_pickle(self.data_dir / \"y_train.pkl\").squeeze()\n",
    "        return X_train, y_train\n",
    "\n",
    "    def determine_categorical_features(self, X_train: pd.DataFrame):\n",
    "        if self.cat_features:\n",
    "            cat_features = [col for col in self.cat_features if col in X_train.columns]\n",
    "        else:\n",
    "            cat_features = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "        self.logger.info(f\"Categorical features: {cat_features}\")\n",
    "        return cat_features\n",
    "\n",
    "\n",
    "    def cross_validate_model(self, X_train: pd.DataFrame, y_train: pd.Series, cat_features: list, cv: int = 5):\n",
    "        if self.model_name == 'catboost':\n",
    "            model = CatBoostClassifier(\n",
    "                random_seed=42, verbose=0, eval_metric='F1',\n",
    "                cat_features=cat_features, class_weights=[1, 10]\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported model: {self.model_name}\")\n",
    "\n",
    "        self.logger.info(f\"Performing {cv}-fold cross-validation...\")\n",
    "        skf = StratifiedKFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "\n",
    "        fold_scores = []\n",
    "        for fold, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train)):\n",
    "            self.logger.info(f\"Processing fold {fold + 1}...\")\n",
    "\n",
    "            X_fold_train, X_fold_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "            y_fold_train, y_fold_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "            self.logger.info(f\"Validation set shape for fold {fold + 1}: {X_fold_val.shape}\")\n",
    "\n",
    "            model.fit(X_fold_train, y_fold_train, eval_set=(X_fold_val, y_fold_val), use_best_model=True)\n",
    "\n",
    "            fold_score = model.best_score_['validation']['F1']\n",
    "            fold_scores.append(fold_score)\n",
    "\n",
    "            self.logger.info(f\"Fold {fold + 1} F1 score: {fold_score}\")\n",
    "\n",
    "        mean_cv_score = sum(fold_scores) / len(fold_scores)\n",
    "        self.logger.info(f\"Mean cross-validation F1 score: {mean_cv_score}\")\n",
    "        return mean_cv_score\n",
    "\n",
    "    def train_model(self, X_train: pd.DataFrame, y_train: pd.Series, cat_features: list, val_size: float = 0.2):\n",
    "        if self.model_name == 'catboost':\n",
    "            model = CatBoostClassifier(\n",
    "            random_seed=42,\n",
    "            verbose=100,\n",
    "            eval_metric='F1',\n",
    "            loss_function='Logloss',\n",
    "            cat_features=cat_features,\n",
    "           #auto_class_weights='Balanced',\n",
    "            #bootstrap_type= \"Bernoulli\",\n",
    "            #grow_policy= \"SymmetricTree\",\n",
    "            class_weights=[1, 1 / a],\n",
    "            early_stopping_rounds=100,\n",
    "            **params2\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported model: {self.model_name}\")\n",
    "\n",
    "        self.logger.info(f\"Training {self.model_name} model...\")\n",
    "        X_train.drop(columns=['session_id', 'DateTime', 'user_id'], inplace=True, errors='ignore')\n",
    "\n",
    "        X_train_final, X_valid, y_train_final, y_valid = train_test_split(\n",
    "            X_train, y_train, test_size=val_size, random_state=42)\n",
    "        \n",
    "\n",
    "        self.logger.info(f\"Training {self.model_name} model with validation set...\")\n",
    "        model.fit(X_train_final, y_train_final, eval_set=(X_valid, y_valid), use_best_model=True)\n",
    "\n",
    "        return model\n",
    "\n",
    "# Interactive Workflow for Jupyter Notebook\n",
    "# Define the data directory\n",
    "DATA_DIR = \"path/to/data\"  # Replace with your actual path\n",
    "\n",
    "# Initialize ModelTrainer\n",
    "trainer = ModelTrainer(DATA_DIR,model_name=\"catboost\")\n",
    "cat_features = trainer.determine_categorical_features(X_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Categorical features: ['product', 'campaign_id', 'webpage_id', 'user_group_id', 'gender', 'product_category']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['product',\n",
       " 'campaign_id',\n",
       " 'webpage_id',\n",
       " 'user_group_id',\n",
       " 'gender',\n",
       " 'product_category']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = ModelTrainer(DATA_DIR, model_name=\"catboost\")\n",
    "trainer.determine_categorical_features(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(365349, 44)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #1 out of 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 32\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Now perform feature selection\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m n_features_list:\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;66;03m# Use column indices for feature selection\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m     selected_features \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect_features\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_features_to_select\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_final_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeatures_for_select\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[43malgorithm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRecursiveByPredictionValuesChange\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogging_level\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mVerbose\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[43mplot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;66;03m# Get selected feature names\u001b[39;00m\n\u001b[0;32m     45\u001b[0m     selected_feature_names \u001b[38;5;241m=\u001b[39m selected_features[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mselected_features_names\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\maorb\\anaconda3\\envs\\Yofi\\Lib\\site-packages\\catboost\\core.py:4519\u001b[0m, in \u001b[0;36mCatBoost.select_features\u001b[1;34m(self, X, y, eval_set, features_for_select, num_features_to_select, algorithm, steps, shap_calc_type, train_final_model, verbose, logging_level, plot, plot_file, log_cout, log_cerr, grouping, features_tags_for_select, num_features_tags_to_select)\u001b[0m\n\u001b[0;32m   4516\u001b[0m     create_dir_if_not_exist(plot_dir)\n\u001b[0;32m   4518\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m plot_wrapper(plot, plot_file\u001b[38;5;241m=\u001b[39mplot_file, plot_title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSelect features plot\u001b[39m\u001b[38;5;124m'\u001b[39m, train_dirs\u001b[38;5;241m=\u001b[39mplot_dirs):\n\u001b[1;32m-> 4519\u001b[0m     summary \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_object\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_select_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4521\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m train_final_model:\n\u001b[0;32m   4522\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_trained_model_attributes()\n",
      "File \u001b[1;32m_catboost.pyx:5622\u001b[0m, in \u001b[0;36m_catboost._CatBoost._select_features\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_catboost.pyx:5636\u001b[0m, in \u001b[0;36m_catboost._CatBoost._select_features\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, precision_recall_curve, auc\n",
    "sample_params = {'depth': 4,\n",
    "  'learning_rate': 0.12751986192358583,\n",
    "  'l2_leaf_reg': 28.56605893525792,\n",
    "  'random_strength': 1.4329403288787461,\n",
    "  'grow_policy': 'SymmetricTree',\n",
    "  'bootstrap_type': 'Bayesian',\n",
    "  'bagging_temperature': 0.31033906089109137}\n",
    "\n",
    "\n",
    "\n",
    "pr_auc_list = []\n",
    "f1_list = []\n",
    "selected_features_list = []\n",
    "n_features_list = [5] + list(np.arange(10, 43, 1))\n",
    "\n",
    "# Get categorical features ONCE before the loop\n",
    "cat_features = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "# Initialize the first model with categorical features\n",
    "model = CatBoostClassifier(\n",
    "    **sample_params,\n",
    "    random_seed=42,\n",
    "    verbose=0,\n",
    "    eval_metric='PRAUC:type=Classic',\n",
    "    cat_features=cat_features,  # Initial categorical features\n",
    "    auto_class_weights='Balanced'\n",
    ")\n",
    "\n",
    "# Now perform feature selection\n",
    "for k in n_features_list:\n",
    "    # Use column indices for feature selection\n",
    "    selected_features = model.select_features(\n",
    "        X=X_train,\n",
    "        y=y_train,\n",
    "        eval_set=(X_val, y_val),\n",
    "        num_features_to_select=k,\n",
    "        train_final_model=False,\n",
    "        features_for_select=list(range(X_train.shape[1])),\n",
    "        algorithm=\"RecursiveByPredictionValuesChange\",\n",
    "        logging_level=\"Verbose\",\n",
    "        plot=False\n",
    "    )\n",
    "    \n",
    "    # Get selected feature names\n",
    "    selected_feature_names = selected_features['selected_features_names']\n",
    "    selected_features_list.append(selected_feature_names)\n",
    "    X_train_new = X_train[selected_feature_names]\n",
    "    X_val_new = X_val[selected_feature_names]\n",
    "    \n",
    "    # Update categorical features based on selected features\n",
    "    new_cat_features = [col for col in cat_features if col in selected_feature_names]\n",
    "    \n",
    "    # Create new model with updated categorical features\n",
    "    model_new = CatBoostClassifier(\n",
    "        **sample_params,\n",
    "        random_seed=42,\n",
    "        verbose=0,\n",
    "        eval_metric='PRAUC:type=Classic',\n",
    "        cat_features=new_cat_features,\n",
    "        auto_class_weights='Balanced'\n",
    "    )\n",
    "    \n",
    "    # Fit and evaluate\n",
    "    model_new.fit(X_train_new, y_train, eval_set=(X_val_new, y_val), use_best_model=True)\n",
    "    y_pred = model_new.predict(X_val_new)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "    pr, rc, _ = precision_recall_curve(y_val, model_new.predict_proba(X_val_new)[:, 1])\n",
    "    pr_auc = auc(rc, pr)\n",
    "    \n",
    "    pr_auc_list.append(pr_auc)\n",
    "    f1_list.append(f1)\n",
    "\n",
    "import pickle\n",
    "# save the features list to disk\n",
    "with open(r'data\\Predictions\\selected_features_list.pkl', 'wb') as f:\n",
    "    pickle.dump(selected_features_list, f)\n",
    "with open(r'data\\Predictions\\pr_auc_list.pkl', 'wb') as f:\n",
    "    pickle.dump(pr_auc_list, f)\n",
    "with open(r'data\\Predictions\\f1_list.pkl', 'wb') as f:\n",
    "    pickle.dump(f1_list, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pr_auc_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mpr_auc_list\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pr_auc_list' is not defined"
     ]
    }
   ],
   "source": [
    "pr_auc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.16133067955644015,\n",
       " 0.16425175780694012,\n",
       " 0.16293301892089157,\n",
       " 0.16506237822432895,\n",
       " 0.162909460260136,\n",
       " 0.16297520661157025,\n",
       " 0.16230575868372943]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'selected_features': [0,\n",
       "  1,\n",
       "  2,\n",
       "  4,\n",
       "  5,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  12,\n",
       "  13,\n",
       "  14,\n",
       "  15,\n",
       "  16,\n",
       "  17,\n",
       "  18,\n",
       "  19,\n",
       "  20,\n",
       "  21,\n",
       "  22,\n",
       "  23,\n",
       "  24,\n",
       "  25,\n",
       "  26,\n",
       "  27,\n",
       "  28,\n",
       "  29,\n",
       "  30,\n",
       "  31,\n",
       "  32,\n",
       "  33,\n",
       "  34,\n",
       "  35,\n",
       "  36],\n",
       " 'eliminated_features_names': ['user_depth', 'user_group_id'],\n",
       " 'loss_graph': {'main_indices': [0, 1],\n",
       "  'removed_features_count': [0, 2],\n",
       "  'loss_values': [0.6654878215931778, 0.665332564717526]},\n",
       " 'eliminated_features': [6, 3],\n",
       " 'selected_features_names': ['product',\n",
       "  'campaign_id',\n",
       "  'webpage_id',\n",
       "  'gender',\n",
       "  'age_level',\n",
       "  'city_development_index',\n",
       "  'var_1',\n",
       "  'product_category',\n",
       "  'user_id_ctrS',\n",
       "  'product_ctrS',\n",
       "  'campaign_id_ctrS',\n",
       "  'webpage_id_ctrS',\n",
       "  'user_group_id_ctrS',\n",
       "  'gender_ctrS',\n",
       "  'age_level_ctrS',\n",
       "  'user_depth_ctrS',\n",
       "  'city_development_index_ctrS',\n",
       "  'var_1_ctrS',\n",
       "  'product_category_ctrS',\n",
       "  'user_id_te',\n",
       "  'product_te',\n",
       "  'campaign_id_te',\n",
       "  'webpage_id_te',\n",
       "  'user_group_id_te',\n",
       "  'gender_te',\n",
       "  'age_level_te',\n",
       "  'user_depth_te',\n",
       "  'city_development_index_te',\n",
       "  'var_1_te',\n",
       "  'product_category_te',\n",
       "  'Day',\n",
       "  'Hour',\n",
       "  'Minute',\n",
       "  'weekday',\n",
       "  'campaign_duration_hours']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['user_id_ctrS', 'campaign_id_ctrS']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features['selected_features_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id_ctrS</th>\n",
       "      <th>campaign_id_ctrS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>157476</th>\n",
       "      <td>0.139729</td>\n",
       "      <td>0.054978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224130</th>\n",
       "      <td>0.048339</td>\n",
       "      <td>0.091021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199364</th>\n",
       "      <td>0.061523</td>\n",
       "      <td>0.067421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2240</th>\n",
       "      <td>0.157456</td>\n",
       "      <td>0.059314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28399</th>\n",
       "      <td>0.042297</td>\n",
       "      <td>0.069128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339396</th>\n",
       "      <td>0.067675</td>\n",
       "      <td>0.076125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367797</th>\n",
       "      <td>0.030761</td>\n",
       "      <td>0.052454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255805</th>\n",
       "      <td>0.048339</td>\n",
       "      <td>0.058462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153188</th>\n",
       "      <td>0.057819</td>\n",
       "      <td>0.058769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318278</th>\n",
       "      <td>0.052058</td>\n",
       "      <td>0.059314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73070 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id_ctrS  campaign_id_ctrS\n",
       "157476      0.139729          0.054978\n",
       "224130      0.048339          0.091021\n",
       "199364      0.061523          0.067421\n",
       "2240        0.157456          0.059314\n",
       "28399       0.042297          0.069128\n",
       "...              ...               ...\n",
       "339396      0.067675          0.076125\n",
       "367797      0.030761          0.052454\n",
       "255805      0.048339          0.058462\n",
       "153188      0.057819          0.058769\n",
       "318278      0.052058          0.059314\n",
       "\n",
       "[73070 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val[selected_features['selected_features_names']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'product' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39m cleaned_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_click\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m/\u001b[39mcleaned_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_click\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_sub\u001b[49m\u001b[43m[\u001b[49m\u001b[43mselected_features\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mselected_features_names\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m          \u001b[49m\u001b[43my_train_sub\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val_sub\u001b[49m\u001b[43m[\u001b[49m\u001b[43mselected_features\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mselected_features_names\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_sub\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_best_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\maorb\\anaconda3\\envs\\Yofi\\Lib\\site-packages\\catboost\\core.py:5245\u001b[0m, in \u001b[0;36mCatBoostClassifier.fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, graph, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   5242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[0;32m   5243\u001b[0m     CatBoostClassifier\u001b[38;5;241m.\u001b[39m_check_is_compatible_loss(params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m-> 5245\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_best_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5246\u001b[0m \u001b[43m          \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogging_level\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_description\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_period\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5247\u001b[0m \u001b[43m          \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_snapshot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cerr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\maorb\\anaconda3\\envs\\Yofi\\Lib\\site-packages\\catboost\\core.py:2395\u001b[0m, in \u001b[0;36mCatBoost._fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, pairs, graph, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   2392\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X, PATH_TYPES \u001b[38;5;241m+\u001b[39m (Pool,)):\n\u001b[0;32m   2393\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CatBoostError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my may be None only when X is an instance of catboost.Pool or string\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2395\u001b[0m train_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_train_params\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2396\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2397\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpairs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpairs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2398\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubgroup_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubgroup_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpairs_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpairs_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_best_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_best_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2399\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogging_level\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogging_level\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplot_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2400\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumn_description\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumn_description\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_period\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_period\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2401\u001b[0m \u001b[43m    \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_snapshot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_snapshot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2402\u001b[0m \u001b[43m    \u001b[49m\u001b[43msnapshot_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msnapshot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msnapshot_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2403\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\n\u001b[0;32m   2404\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2405\u001b[0m params \u001b[38;5;241m=\u001b[39m train_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   2406\u001b[0m train_pool \u001b[38;5;241m=\u001b[39m train_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_pool\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\maorb\\anaconda3\\envs\\Yofi\\Lib\\site-packages\\catboost\\core.py:2275\u001b[0m, in \u001b[0;36mCatBoost._prepare_train_params\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, pairs, graph, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks)\u001b[0m\n\u001b[0;32m   2272\u001b[0m text_features \u001b[38;5;241m=\u001b[39m _process_feature_indices(text_features, X, params, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext_features\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   2273\u001b[0m embedding_features \u001b[38;5;241m=\u001b[39m _process_feature_indices(embedding_features, X, params, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124membedding_features\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 2275\u001b[0m train_pool \u001b[38;5;241m=\u001b[39m \u001b[43m_build_train_pool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpairs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2276\u001b[0m \u001b[43m                               \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgroup_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpairs_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2277\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_description\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m train_pool\u001b[38;5;241m.\u001b[39mis_empty_:\n\u001b[0;32m   2279\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CatBoostError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX is empty.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\maorb\\anaconda3\\envs\\Yofi\\Lib\\site-packages\\catboost\\core.py:1513\u001b[0m, in \u001b[0;36m_build_train_pool\u001b[1;34m(X, y, cat_features, text_features, embedding_features, pairs, graph, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, column_description)\u001b[0m\n\u001b[0;32m   1511\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1512\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m CatBoostError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my has not initialized in fit(): X is not catboost.Pool object, y must be not None in fit().\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1513\u001b[0m     train_pool \u001b[38;5;241m=\u001b[39m \u001b[43mPool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpairs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpairs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1514\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mgroup_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgroup_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubgroup_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpairs_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpairs_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbaseline\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m train_pool\n",
      "File \u001b[1;32mc:\\Users\\maorb\\anaconda3\\envs\\Yofi\\Lib\\site-packages\\catboost\\core.py:855\u001b[0m, in \u001b[0;36mPool.__init__\u001b[1;34m(self, data, label, cat_features, text_features, embedding_features, embedding_features_data, column_description, pairs, graph, delimiter, has_header, ignore_csv_quoting, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count, log_cout, log_cerr, data_can_be_none)\u001b[0m\n\u001b[0;32m    849\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(feature_names, PATH_TYPES):\n\u001b[0;32m    850\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m CatBoostError(\n\u001b[0;32m    851\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature_names must be None or have non-string type when the pool is created from \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    852\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython objects.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    853\u001b[0m             )\n\u001b[1;32m--> 855\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpairs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    856\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mgroup_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgroup_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpairs_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimestamp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_tags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthread_count\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data_can_be_none:\n\u001b[0;32m    858\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CatBoostError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m parameter can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be None\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\maorb\\anaconda3\\envs\\Yofi\\Lib\\site-packages\\catboost\\core.py:1438\u001b[0m, in \u001b[0;36mPool._init\u001b[1;34m(self, data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, graph, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count)\u001b[0m\n\u001b[0;32m   1436\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_feature_names(feature_names, features_count)\n\u001b[0;32m   1437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cat_features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1438\u001b[0m     cat_features \u001b[38;5;241m=\u001b[39m \u001b[43m_get_features_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_string_feature_type(cat_features, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcat_features\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   1440\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_string_feature_value(cat_features, features_count, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcat_features\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\maorb\\anaconda3\\envs\\Yofi\\Lib\\site-packages\\catboost\\core.py:318\u001b[0m, in \u001b[0;36m_get_features_indices\u001b[1;34m(features, feature_names)\u001b[0m\n\u001b[0;32m    316\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CatBoostError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature names should be a sequence, but got \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mrepr\u001b[39m(features))\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m feature_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 318\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSTRING_TYPES\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m features:\n",
      "File \u001b[1;32mc:\\Users\\maorb\\anaconda3\\envs\\Yofi\\Lib\\site-packages\\catboost\\core.py:319\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    316\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CatBoostError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature names should be a sequence, but got \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mrepr\u001b[39m(features))\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m feature_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m--> 319\u001b[0m         feature_names\u001b[38;5;241m.\u001b[39mindex(f) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, STRING_TYPES) \u001b[38;5;28;01melse\u001b[39;00m f\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m features\n\u001b[0;32m    321\u001b[0m     ]\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m features:\n",
      "\u001b[1;31mValueError\u001b[0m: 'product' is not in list"
     ]
    }
   ],
   "source": [
    "a = 1- cleaned_data['is_click'].value_counts()[0]/cleaned_data['is_click'].value_counts().sum()\n",
    "model.fit(X_train[selected_features['selected_features_names']], \n",
    "          y_train, eval_set=(X_val[selected_features['selected_features_names']], y_val), use_best_model=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9472    0.5222    0.6732     68404\n",
      "         1.0     0.0823    0.5954    0.1446      4923\n",
      "\n",
      "    accuracy                         0.5271     73327\n",
      "   macro avg     0.5147    0.5588    0.4089     73327\n",
      "weighted avg     0.8891    0.5271    0.6377     73327\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.5700000000000001\n",
      "Best F1 score: 0.15008745080891997\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# After training your CatBoost model:\n",
    "y_probs = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "best_threshold = 0.0\n",
    "best_f1 = 0.0\n",
    "\n",
    "# We can search thresholds from 0.0 to 1.0 in small steps\n",
    "for t in np.linspace(0, 1, 101):\n",
    "    y_pred = (y_probs >= t).astype(int)\n",
    "    score = f1_score(y_test, y_pred)\n",
    "    if score > best_f1:\n",
    "        best_f1 = score\n",
    "        best_threshold = t\n",
    "\n",
    "print(f\"Best threshold: {best_threshold}\")\n",
    "print(f\"Best F1 score: {best_f1}\")\n",
    "\n",
    "# When predicting on test data, use the best_threshold:\n",
    "y_probs_test = model.predict_proba(X_test)[:, 1]\n",
    "y_pred_test = (y_probs_test >= best_threshold).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive preprocessing (not my class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2= raw_data.drop(columns = ['session_id', 'DateTime', 'user_id','product_category_2'])\n",
    "data2.dropna(inplace = True) # Just close your eyes and drop the rows with missing values\n",
    "data2.drop_duplicates(inplace = True) # Drop duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11879, 11)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2 = data2.drop(columns = ['is_click'])\n",
    "y_2 = data2['is_click']\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_2, y_2, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_d2 = [\"product\", \"campaign_id\", \"webpage_id\", \"user_group_id\", \"gender\", \"product_category_1\"]\n",
    "\n",
    "X_train_2_d = pd.get_dummies(X_train_2, columns = columns_to_d2)\n",
    "X_test_2_d = pd.get_dummies(X_test_2, columns = columns_to_d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42,class_weight='balanced')\n",
    "rf.fit(X_train_2_d, y_train_2)\n",
    "y_pred_RF = rf.predict(X_test_2_d)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14298031865042174"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test_2, y_pred_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45353982300884954\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "model = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "model.fit(X_train_2_d, y_train_2)\n",
    "\n",
    "y_pred_LR = model.predict(X_test_2_d)\n",
    "print(f1_score(y_test_2, y_pred_LR))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Yofi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
