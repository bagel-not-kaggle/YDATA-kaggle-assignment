{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "cleaned_data = pd.read_pickle(r\"C:\\Users\\maorb\\Classes\\Classical_ML\\YDATA-kaggle-assignment\\data\\processed\\cleaned_data_Maor.pkl\")\n",
    "X_train = pd.read_pickle(r\"C:\\Users\\maorb\\Classes\\Classical_ML\\YDATA-kaggle-assignment\\data\\processed\\X_train.pkl\")\n",
    "X_test = pd.read_pickle(r\"C:\\Users\\maorb\\Classes\\Classical_ML\\YDATA-kaggle-assignment\\data\\processed\\X_test.pkl\")\n",
    "y_train = pd.read_pickle(r\"C:\\Users\\maorb\\Classes\\Classical_ML\\YDATA-kaggle-assignment\\data\\processed\\y_train.pkl\")\n",
    "y_test = pd.read_pickle(r\"C:\\Users\\maorb\\Classes\\Classical_ML\\YDATA-kaggle-assignment\\data\\processed\\y_test.pkl\")\n",
    "predictions = pd.read_csv(r'C:\\Users\\maorb\\Classes\\Classical_ML\\YDATA-kaggle-assignment\\predictions\\predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(r\"C:\\Users\\maorb\\Classes\\Classical_ML\\YDATA-kaggle-assignment\\data\\raw\\train_dataset_full.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(365798, 14)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19510, 15)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find how many duplicated rows we have\n",
    "duplicates = raw_data[raw_data.duplicated()]\n",
    "duplicates.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "369653"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>user_id</th>\n",
       "      <th>product</th>\n",
       "      <th>campaign_id</th>\n",
       "      <th>webpage_id</th>\n",
       "      <th>product_category_1</th>\n",
       "      <th>product_category_2</th>\n",
       "      <th>user_group_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age_level</th>\n",
       "      <th>user_depth</th>\n",
       "      <th>city_development_index</th>\n",
       "      <th>var_1</th>\n",
       "      <th>is_click</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>98528.0</td>\n",
       "      <td>2017-07-04 16:42</td>\n",
       "      <td>7716.0</td>\n",
       "      <td>C</td>\n",
       "      <td>405490.0</td>\n",
       "      <td>60305.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>589714.0</td>\n",
       "      <td>2017-07-07 07:40</td>\n",
       "      <td>1035283.0</td>\n",
       "      <td>I</td>\n",
       "      <td>118601.0</td>\n",
       "      <td>28529.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>82527.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>478652.0</td>\n",
       "      <td>2017-07-07 20:42</td>\n",
       "      <td>65994.0</td>\n",
       "      <td>H</td>\n",
       "      <td>359520.0</td>\n",
       "      <td>13787.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34536.0</td>\n",
       "      <td>2017-07-05 15:05</td>\n",
       "      <td>75976.0</td>\n",
       "      <td>H</td>\n",
       "      <td>405490.0</td>\n",
       "      <td>60305.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>71863.0</td>\n",
       "      <td>2017-07-06 20:11</td>\n",
       "      <td>987498.0</td>\n",
       "      <td>C</td>\n",
       "      <td>405490.0</td>\n",
       "      <td>60305.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   session_id          DateTime    user_id product  campaign_id  webpage_id  \\\n",
       "0     98528.0  2017-07-04 16:42     7716.0       C     405490.0     60305.0   \n",
       "1    589714.0  2017-07-07 07:40  1035283.0       I     118601.0     28529.0   \n",
       "2    478652.0  2017-07-07 20:42    65994.0       H     359520.0     13787.0   \n",
       "3     34536.0  2017-07-05 15:05    75976.0       H     405490.0     60305.0   \n",
       "4     71863.0  2017-07-06 20:11   987498.0       C     405490.0     60305.0   \n",
       "\n",
       "   product_category_1  product_category_2  user_group_id  gender  age_level  \\\n",
       "0                 3.0                 NaN            3.0    Male        3.0   \n",
       "1                 4.0             82527.0           10.0  Female        4.0   \n",
       "2                 4.0                 NaN            4.0    Male        4.0   \n",
       "3                 3.0                 NaN            3.0    Male        3.0   \n",
       "4                 3.0                 NaN            2.0    Male        2.0   \n",
       "\n",
       "   user_depth  city_development_index  var_1  is_click  \n",
       "0         3.0                     NaN    1.0       1.0  \n",
       "1         3.0                     3.0    1.0       0.0  \n",
       "2         3.0                     2.0    0.0       0.0  \n",
       "3         3.0                     3.0    0.0       0.0  \n",
       "4         3.0                     2.0    0.0       0.0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 365798 entries, 0 to 370631\n",
      "Data columns (total 14 columns):\n",
      " #   Column                  Non-Null Count   Dtype         \n",
      "---  ------                  --------------   -----         \n",
      " 0   session_id              365107 non-null  float64       \n",
      " 1   DateTime                365073 non-null  datetime64[ns]\n",
      " 2   user_id                 365798 non-null  float64       \n",
      " 3   product                 365736 non-null  category      \n",
      " 4   campaign_id             365072 non-null  category      \n",
      " 5   webpage_id              365070 non-null  category      \n",
      " 6   user_group_id           350779 non-null  category      \n",
      " 7   gender                  351429 non-null  category      \n",
      " 8   age_level               351436 non-null  float64       \n",
      " 9   user_depth              350771 non-null  float64       \n",
      " 10  city_development_index  266504 non-null  float64       \n",
      " 11  var_1                   365737 non-null  float64       \n",
      " 12  is_click                365798 non-null  float64       \n",
      " 13  product_category        365167 non-null  category      \n",
      "dtypes: category(6), datetime64[ns](1), float64(7)\n",
      "memory usage: 27.2 MB\n"
     ]
    }
   ],
   "source": [
    "cleaned_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['month'] = X_train['DateTime'].dt.month\n",
    "X_train['day'] = X_train['DateTime'].dt.day\n",
    "X_train['hour'] = X_train['DateTime'].dt.hour\n",
    "\n",
    "X_test['month'] = X_test['DateTime'].dt.month\n",
    "X_test['day'] = X_test['DateTime'].dt.day\n",
    "X_test['hour'] = X_test['DateTime'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_with_mode(df: pd.DataFrame, columns: list):\n",
    "    \"\"\"\n",
    "    Fills missing values in specified columns with their mode.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing the data.\n",
    "        columns (list): List of column names to process.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with missing values imputed.\n",
    "    \"\"\"\n",
    "    for column in columns:\n",
    "        if column in df.columns:\n",
    "            mode_value = df[column].mode()[0]  # Calculate the mode\n",
    "            df[column] = df[column].fillna(mode_value)  # Fill missing values with the mode\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill each Na with X_trai\n",
    "columns_to_fill = [\"product\", \"campaign_id\", \"webpage_id\", \"user_group_id\", \"gender\", \"age_level\", \"user_depth\", \"city_development_index\", \"var_1\", \"product_category\",\n",
    "                     \"month\", \"day\", \"hour\"]\n",
    "\n",
    "X_train_filled = fill_missing_with_mode(X_train, columns_to_fill)\n",
    "X_test_filled = fill_missing_with_mode(X_test, columns_to_fill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "session_id                562\n",
       "DateTime                  589\n",
       "user_id                     0\n",
       "product                     0\n",
       "campaign_id                 0\n",
       "webpage_id                  0\n",
       "user_group_id               0\n",
       "gender                      0\n",
       "age_level                   0\n",
       "user_depth                  0\n",
       "city_development_index      0\n",
       "var_1                       0\n",
       "product_category            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_filled.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_filled.drop(columns = ['session_id', 'DateTime'], inplace = True)\n",
    "X_test_filled.drop(columns = ['session_id', 'DateTime'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id                   0\n",
       "product                   0\n",
       "campaign_id               0\n",
       "webpage_id                0\n",
       "user_group_id             0\n",
       "gender                    0\n",
       "age_level                 0\n",
       "user_depth                0\n",
       "city_development_index    0\n",
       "var_1                     0\n",
       "product_category          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_filled.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_d = [\"product\", \"campaign_id\", \"webpage_id\", \"user_group_id\", \"gender\", \"product_category\"]\n",
    "\n",
    "X_train_filled_d = pd.get_dummies(X_train_filled, columns = columns_to_d)\n",
    "X_test_filled_d = pd.get_dummies(X_test_filled, columns = columns_to_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[497], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m f1_score\n\u001b[0;32m      4\u001b[0m rf \u001b[38;5;241m=\u001b[39m RandomForestClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m,class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mrf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_filled_d\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m rf\u001b[38;5;241m.\u001b[39mpredict(X_test_filled_d)\n\u001b[0;32m      8\u001b[0m f1_score(y_test, y_pred)\n",
      "File \u001b[1;32mc:\\Users\\maorb\\anaconda3\\envs\\Yofi\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\maorb\\anaconda3\\envs\\Yofi\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:489\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    478\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    480\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    481\u001b[0m ]\n\u001b[0;32m    483\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 489\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Users\\maorb\\anaconda3\\envs\\Yofi\\Lib\\site-packages\\sklearn\\utils\\parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     73\u001b[0m )\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\maorb\\anaconda3\\envs\\Yofi\\Lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\maorb\\anaconda3\\envs\\Yofi\\Lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\maorb\\anaconda3\\envs\\Yofi\\Lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\maorb\\anaconda3\\envs\\Yofi\\Lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\maorb\\anaconda3\\envs\\Yofi\\Lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\maorb\\anaconda3\\envs\\Yofi\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\maorb\\anaconda3\\envs\\Yofi\\Lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\maorb\\anaconda3\\envs\\Yofi\\Lib\\site-packages\\sklearn\\utils\\parallel.py:136\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\maorb\\anaconda3\\envs\\Yofi\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:192\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    190\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[1;32m--> 192\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    200\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[0;32m    201\u001b[0m         X,\n\u001b[0;32m    202\u001b[0m         y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    205\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[0;32m    206\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\maorb\\anaconda3\\envs\\Yofi\\Lib\\site-packages\\sklearn\\tree\\_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    463\u001b[0m         splitter,\n\u001b[0;32m    464\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    470\u001b[0m     )\n\u001b[1;32m--> 472\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42,class_weight='balanced')\n",
    "rf.fit(X_train_filled_d, y_train)\n",
    "y_pred = rf.predict(X_test_filled_d)\n",
    "\n",
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Apply SMOTE to balance the training set\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_filled_d, y_train)\n",
    "\n",
    "# Train Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred2 = rf.predict(X_test_filled_d)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score (minority class): 0.08470909711943528\n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(y_test, y_pred2)\n",
    "print(f\"F1-score (minority class): {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.93      0.93     68166\n",
      "         1.0       0.09      0.09      0.09      4994\n",
      "\n",
      "    accuracy                           0.87     73160\n",
      "   macro avg       0.51      0.51      0.51     73160\n",
      "weighted avg       0.88      0.87      0.87     73160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "816"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_filled_d.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1453661769579145\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, classification_report\n",
    "#adjuct the balance of the classes\n",
    "model = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42, solver='liblinear',\n",
    "                           penalty='l2', C=0.1)\n",
    "model.fit(X_train_filled_d, y_train)\n",
    "\n",
    "y_pred_LR = model.predict(X_test_filled_d)\n",
    "print(f1_score(y_test, y_pred_LR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.14614835099416598\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.62      0.75     68166\n",
      "         1.0       0.09      0.49      0.15      4994\n",
      "\n",
      "    accuracy                           0.61     73160\n",
      "   macro avg       0.51      0.55      0.45     73160\n",
      "weighted avg       0.88      0.61      0.70     73160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB, ComplementNB\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "model = ComplementNB()\n",
    "model.fit(X_train_filled_d, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test_filled_d)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f\"F1-score: {f1}\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.09819028847876725\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=42, class_weight='balanced')\n",
    "model.fit(X_train_filled_d, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test_filled_d)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f\"F1-score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.57      0.71     68166\n",
      "         1.0       0.08      0.54      0.15      4994\n",
      "\n",
      "    accuracy                           0.57     73160\n",
      "   macro avg       0.51      0.55      0.43     73160\n",
      "weighted avg       0.89      0.57      0.67     73160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report  \n",
    "print(classification_report(y_test, y_pred_LR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Baseline? :()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9323260378678943"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data['is_click'].value_counts()[0]/cleaned_data['is_click'].value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1- cleaned_data['is_click'].value_counts()[0]/cleaned_data['is_click'].value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>user_id</th>\n",
       "      <th>product</th>\n",
       "      <th>campaign_id</th>\n",
       "      <th>webpage_id</th>\n",
       "      <th>user_group_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age_level</th>\n",
       "      <th>user_depth</th>\n",
       "      <th>city_development_index</th>\n",
       "      <th>var_1</th>\n",
       "      <th>product_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>370001</th>\n",
       "      <td>392485.0</td>\n",
       "      <td>2017-07-02 11:17:00</td>\n",
       "      <td>308642.0</td>\n",
       "      <td>D</td>\n",
       "      <td>82320</td>\n",
       "      <td>1734</td>\n",
       "      <td>12</td>\n",
       "      <td>Female</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227178</th>\n",
       "      <td>63873.0</td>\n",
       "      <td>2017-07-03 16:25:00</td>\n",
       "      <td>238993.0</td>\n",
       "      <td>C</td>\n",
       "      <td>405490</td>\n",
       "      <td>60305</td>\n",
       "      <td>3</td>\n",
       "      <td>Male</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84936</th>\n",
       "      <td>475022.0</td>\n",
       "      <td>2017-07-02 09:46:00</td>\n",
       "      <td>3307.0</td>\n",
       "      <td>H</td>\n",
       "      <td>359520</td>\n",
       "      <td>13787</td>\n",
       "      <td>4</td>\n",
       "      <td>Male</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110154</th>\n",
       "      <td>524314.0</td>\n",
       "      <td>2017-07-04 19:25:00</td>\n",
       "      <td>946940.0</td>\n",
       "      <td>H</td>\n",
       "      <td>105960</td>\n",
       "      <td>11085</td>\n",
       "      <td>3</td>\n",
       "      <td>Male</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6988</th>\n",
       "      <td>3653.0</td>\n",
       "      <td>2017-07-02 12:13:00</td>\n",
       "      <td>860243.0</td>\n",
       "      <td>I</td>\n",
       "      <td>404347</td>\n",
       "      <td>53587</td>\n",
       "      <td>9</td>\n",
       "      <td>Female</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        session_id            DateTime   user_id product campaign_id  \\\n",
       "370001    392485.0 2017-07-02 11:17:00  308642.0       D       82320   \n",
       "227178     63873.0 2017-07-03 16:25:00  238993.0       C      405490   \n",
       "84936     475022.0 2017-07-02 09:46:00    3307.0       H      359520   \n",
       "110154    524314.0 2017-07-04 19:25:00  946940.0       H      105960   \n",
       "6988        3653.0 2017-07-02 12:13:00  860243.0       I      404347   \n",
       "\n",
       "       webpage_id user_group_id  gender  age_level  user_depth  \\\n",
       "370001       1734            12  Female        6.0         3.0   \n",
       "227178      60305             3    Male        3.0         3.0   \n",
       "84936       13787             4    Male        4.0         3.0   \n",
       "110154      11085             3    Male        3.0         2.0   \n",
       "6988        53587             9  Female        3.0         3.0   \n",
       "\n",
       "        city_development_index  var_1 product_category  \n",
       "370001                     4.0    0.0                1  \n",
       "227178                     2.0    1.0                3  \n",
       "84936                      2.0    0.0                4  \n",
       "110154                     NaN    1.0                4  \n",
       "6988                       3.0    0.0                1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "model = CatBoostClassifier(\n",
    "                random_seed=42, verbose=0, eval_metric='F1',\n",
    "                cat_features=cat_features, class_weights=[1, 10]\n",
    "            )\n",
    "model.fit(X_train_filled_d, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 292638 entries, 196 to 123594\n",
      "Data columns (total 13 columns):\n",
      " #   Column                  Non-Null Count   Dtype         \n",
      "---  ------                  --------------   -----         \n",
      " 0   session_id              292076 non-null  float64       \n",
      " 1   DateTime                292049 non-null  datetime64[ns]\n",
      " 2   user_id                 292638 non-null  float64       \n",
      " 3   product                 292638 non-null  category      \n",
      " 4   campaign_id             292638 non-null  category      \n",
      " 5   webpage_id              292638 non-null  category      \n",
      " 6   user_group_id           292638 non-null  category      \n",
      " 7   gender                  292638 non-null  category      \n",
      " 8   age_level               281178 non-null  float64       \n",
      " 9   user_depth              280646 non-null  float64       \n",
      " 10  city_development_index  213253 non-null  float64       \n",
      " 11  var_1                   292591 non-null  float64       \n",
      " 12  product_category        292638 non-null  category      \n",
      "dtypes: category(6), datetime64[ns](1), float64(6)\n",
      "memory usage: 19.5 MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['hour'] = X_train['DateTime'].dt.hour\n",
    "X_train['day'] = X_train['DateTime'].dt.day\n",
    "X_train['month'] = X_train['DateTime'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1 = X_train.drop(columns=['session_id', 'DateTime', 'user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # --- 1) Suggest hyperparams ---\n",
    "    # Example search space: Feel free to expand or tune ranges\n",
    "    params = {\n",
    "        \"iterations\": 1000,\n",
    "        \"depth\": trial.suggest_int(\"depth\", 4, 8),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.1),\n",
    "        \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 1, 100),\n",
    "        \"bagging_temperature\": trial.suggest_float(\"bagging_temperature\", 0.0, 1.0),\n",
    "        # Commonly used knobs; random_strength, subsample, etc. can also be tuned\n",
    "        \"eval_metric\": \"F1\",\n",
    "        \"random_seed\": 42,\n",
    "        \"auto_class_weights\": \"Balanced\",\n",
    "        \"verbose\": 0  # Keep CatBoost silent\n",
    "    }\n",
    "\n",
    "    # --- 2) Create CatBoost model ---\n",
    "    model = CatBoostClassifier(**params)\n",
    "\n",
    "    # --- 3) Train/Validation split ---\n",
    "    X_train_sub, X_val_sub, y_train_sub, y_val_sub = train_test_split(\n",
    "        X_train1,\n",
    "        y_train,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=y_train\n",
    "    )\n",
    "\n",
    "    # --- 4) Train ---\n",
    "    model.fit(\n",
    "        X_train_sub,\n",
    "        y_train_sub,\n",
    "        cat_features=cat_features,\n",
    "        eval_set=(X_val_sub, y_val_sub),\n",
    "        early_stopping_rounds=50,\n",
    "        use_best_model=True\n",
    "    )\n",
    "\n",
    "    # --- 5) Predict ---\n",
    "    y_pred_val = model.predict(X_val_sub)\n",
    "\n",
    "    # --- 6) Evaluate ---\n",
    "    f1 = f1_score(y_val_sub, y_pred_val)\n",
    "\n",
    "    # Return the F1 (Optuna will try to maximize this)\n",
    "    return f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-23 21:27:34,790] A new study created in memory with name: no-name-8ce8d20c-b456-437c-8c24-278df2096bb7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbdc95c3af0e49d083c41c6c90b7cb93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-23 21:27:52,779] Trial 0 finished with value: 0.14241381636645753 and parameters: {'iterations': 700, 'depth': 7, 'learning_rate': 0.09744541619010162, 'l2_leaf_reg': 4.6845889641307, 'bagging_temperature': 0.6083577649428933}. Best is trial 0 with value: 0.14241381636645753.\n",
      "[I 2025-01-23 21:29:00,012] Trial 1 finished with value: 0.14715379312846932 and parameters: {'iterations': 900, 'depth': 8, 'learning_rate': 0.06056087732149749, 'l2_leaf_reg': 44.82689039760325, 'bagging_temperature': 0.3545388999625765}. Best is trial 1 with value: 0.14715379312846932.\n",
      "[I 2025-01-23 21:29:18,804] Trial 2 finished with value: 0.14246593421096043 and parameters: {'iterations': 400, 'depth': 6, 'learning_rate': 0.012942977089435637, 'l2_leaf_reg': 23.56083041913574, 'bagging_temperature': 0.4558729858095575}. Best is trial 1 with value: 0.14715379312846932.\n",
      "[I 2025-01-23 21:29:34,801] Trial 3 finished with value: 0.14265668849391955 and parameters: {'iterations': 700, 'depth': 7, 'learning_rate': 0.080796438459713, 'l2_leaf_reg': 92.0943432488394, 'bagging_temperature': 0.475600614080402}. Best is trial 1 with value: 0.14715379312846932.\n",
      "[I 2025-01-23 21:31:07,688] Trial 4 finished with value: 0.1476639519931419 and parameters: {'iterations': 1000, 'depth': 6, 'learning_rate': 0.09878531291168284, 'l2_leaf_reg': 75.88220809988779, 'bagging_temperature': 0.5426526136974688}. Best is trial 4 with value: 0.1476639519931419.\n",
      "[I 2025-01-23 21:31:14,758] Trial 5 finished with value: 0.14193717106338466 and parameters: {'iterations': 100, 'depth': 5, 'learning_rate': 0.07919274800341754, 'l2_leaf_reg': 21.655654371660916, 'bagging_temperature': 0.2731348218643188}. Best is trial 4 with value: 0.1476639519931419.\n",
      "[I 2025-01-23 21:31:38,377] Trial 6 finished with value: 0.14265668849391955 and parameters: {'iterations': 700, 'depth': 7, 'learning_rate': 0.07313717065119897, 'l2_leaf_reg': 43.54707008765233, 'bagging_temperature': 0.3064446390337354}. Best is trial 4 with value: 0.1476639519931419.\n",
      "[I 2025-01-23 21:32:05,187] Trial 7 finished with value: 0.1426403641881639 and parameters: {'iterations': 400, 'depth': 8, 'learning_rate': 0.031049701486487724, 'l2_leaf_reg': 96.73421630866153, 'bagging_temperature': 0.05288639536409112}. Best is trial 4 with value: 0.1476639519931419.\n",
      "[I 2025-01-23 21:32:19,125] Trial 8 finished with value: 0.14228179057176812 and parameters: {'iterations': 400, 'depth': 4, 'learning_rate': 0.05740633926082669, 'l2_leaf_reg': 16.671189982269283, 'bagging_temperature': 0.5555896608966858}. Best is trial 4 with value: 0.1476639519931419.\n",
      "[I 2025-01-23 21:32:45,839] Trial 9 finished with value: 0.14265743803061817 and parameters: {'iterations': 400, 'depth': 7, 'learning_rate': 0.0027632081531127053, 'l2_leaf_reg': 30.97229508667193, 'bagging_temperature': 0.6683993695585385}. Best is trial 4 with value: 0.1476639519931419.\n",
      "[I 2025-01-23 21:33:05,554] Trial 10 finished with value: 0.14198398431116196 and parameters: {'iterations': 1000, 'depth': 5, 'learning_rate': 0.03761110219796429, 'l2_leaf_reg': 72.55075722853606, 'bagging_temperature': 0.9453440034853672}. Best is trial 4 with value: 0.1476639519931419.\n",
      "[I 2025-01-23 21:33:33,086] Trial 11 finished with value: 0.1421941711527752 and parameters: {'iterations': 1000, 'depth': 8, 'learning_rate': 0.0929529962862502, 'l2_leaf_reg': 64.33952272843467, 'bagging_temperature': 0.7830590926048931}. Best is trial 4 with value: 0.1476639519931419.\n",
      "[I 2025-01-23 21:33:51,274] Trial 12 finished with value: 0.1433358407987417 and parameters: {'iterations': 900, 'depth': 6, 'learning_rate': 0.05891503727110363, 'l2_leaf_reg': 60.757133260029896, 'bagging_temperature': 0.271256291978086}. Best is trial 4 with value: 0.1476639519931419.\n",
      "[I 2025-01-23 21:34:04,181] Trial 13 finished with value: 0.14195573282767188 and parameters: {'iterations': 800, 'depth': 5, 'learning_rate': 0.04522327290581978, 'l2_leaf_reg': 76.57520207708575, 'bagging_temperature': 0.09596522705782784}. Best is trial 4 with value: 0.1476639519931419.\n",
      "[I 2025-01-23 21:36:43,461] Trial 14 finished with value: 0.14685642226625834 and parameters: {'iterations': 900, 'depth': 8, 'learning_rate': 0.06732309624113147, 'l2_leaf_reg': 45.250976255460664, 'bagging_temperature': 0.32834021621388704}. Best is trial 4 with value: 0.1476639519931419.\n",
      "[I 2025-01-23 21:37:15,302] Trial 15 finished with value: 0.14398544131028207 and parameters: {'iterations': 1000, 'depth': 6, 'learning_rate': 0.08612888043149991, 'l2_leaf_reg': 82.70889319860106, 'bagging_temperature': 0.7856572385711114}. Best is trial 4 with value: 0.1476639519931419.\n",
      "[I 2025-01-23 21:37:32,643] Trial 16 finished with value: 0.14198398431116196 and parameters: {'iterations': 600, 'depth': 4, 'learning_rate': 0.02301173283485969, 'l2_leaf_reg': 54.95664099116852, 'bagging_temperature': 0.16643462522036656}. Best is trial 4 with value: 0.1476639519931419.\n",
      "[I 2025-01-23 21:37:50,223] Trial 17 finished with value: 0.14205827528696163 and parameters: {'iterations': 800, 'depth': 5, 'learning_rate': 0.06475781964812169, 'l2_leaf_reg': 37.13556167482765, 'bagging_temperature': 0.4307283433006669}. Best is trial 4 with value: 0.1476639519931419.\n",
      "[I 2025-01-23 21:39:04,031] Trial 18 finished with value: 0.1462921510578381 and parameters: {'iterations': 900, 'depth': 6, 'learning_rate': 0.09722642044234332, 'l2_leaf_reg': 67.10077386399205, 'bagging_temperature': 0.7275165541861098}. Best is trial 4 with value: 0.1476639519931419.\n",
      "[I 2025-01-23 21:39:12,640] Trial 19 finished with value: 0.14193717106338466 and parameters: {'iterations': 100, 'depth': 7, 'learning_rate': 0.038977556807282585, 'l2_leaf_reg': 52.49479356567382, 'bagging_temperature': 0.39635227325266853}. Best is trial 4 with value: 0.1476639519931419.\n"
     ]
    }
   ],
   "source": [
    "# Create study that aims to maximize F1\n",
    "import optuna\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "\n",
    "# Optimize over 'objective' for a certain number of trials\n",
    "study.optimize(objective, n_trials=20, show_progress_bar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>campaign_id</th>\n",
       "      <th>webpage_id</th>\n",
       "      <th>user_group_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age_level</th>\n",
       "      <th>user_depth</th>\n",
       "      <th>city_development_index</th>\n",
       "      <th>var_1</th>\n",
       "      <th>product_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>C</td>\n",
       "      <td>359520</td>\n",
       "      <td>13787</td>\n",
       "      <td>4</td>\n",
       "      <td>Male</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197581</th>\n",
       "      <td>C</td>\n",
       "      <td>405490</td>\n",
       "      <td>60305</td>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43920</th>\n",
       "      <td>H</td>\n",
       "      <td>105960</td>\n",
       "      <td>11085</td>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332522</th>\n",
       "      <td>I</td>\n",
       "      <td>118601</td>\n",
       "      <td>28529</td>\n",
       "      <td>3</td>\n",
       "      <td>Male</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45995</th>\n",
       "      <td>C</td>\n",
       "      <td>359520</td>\n",
       "      <td>13787</td>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       product campaign_id webpage_id user_group_id gender  age_level  \\\n",
       "196          C      359520      13787             4   Male        4.0   \n",
       "197581       C      405490      60305             1   Male        1.0   \n",
       "43920        H      105960      11085             2   Male        2.0   \n",
       "332522       I      118601      28529             3   Male        3.0   \n",
       "45995        C      359520      13787             1   Male        1.0   \n",
       "\n",
       "        user_depth  city_development_index  var_1 product_category  \n",
       "196            3.0                     NaN    0.0                4  \n",
       "197581         3.0                     2.0    0.0                3  \n",
       "43920          3.0                     4.0    0.0                5  \n",
       "332522         3.0                     2.0    1.0                4  \n",
       "45995          3.0                     3.0    0.0                4  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Categorical features: ['product', 'campaign_id', 'webpage_id', 'gender', 'product_category']\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "# Define the ModelTrainer class\n",
    "class ModelTrainer:\n",
    "    def __init__(self, data_dir: False, model_name: str = \"catboost\", cat_features: list = None):\n",
    "        #self.data_dir = Path(data_dir)\n",
    "        self.model_name = model_name\n",
    "        self.cat_features = cat_features\n",
    "\n",
    "        logging.basicConfig(level=logging.INFO)\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "\n",
    "    def load_data(self):\n",
    "        self.logger.info(f\"Loading preprocessed data from {self.data_dir}...\")\n",
    "        X_train = pd.read_pickle(self.data_dir / \"X_train.pkl\")\n",
    "        y_train = pd.read_pickle(self.data_dir / \"y_train.pkl\").squeeze()\n",
    "        return X_train, y_train\n",
    "\n",
    "    def determine_categorical_features(self, X_train: pd.DataFrame):\n",
    "        if self.cat_features:\n",
    "            cat_features = [col for col in self.cat_features if col in X_train.columns]\n",
    "        else:\n",
    "            cat_features = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "        for col in cat_features:\n",
    "            if col in X_train.columns:\n",
    "                # Ensure column is treated as category\n",
    "                X_train[col] = X_train[col].astype(\"category\")\n",
    "                \n",
    "                # Add \"missing\" only if it's not already a category\n",
    "                if \"missing\" not in X_train[col].cat.categories:\n",
    "                    X_train[col] = X_train[col].cat.add_categories(\"missing\")\n",
    "                \n",
    "                # Fill missing values with \"missing\"\n",
    "                X_train[col] = X_train[col].fillna(\"missing\")\n",
    "\n",
    "        self.logger.info(f\"Categorical features: {cat_features}\")\n",
    "        return cat_features\n",
    "\n",
    "\n",
    "    def cross_validate_model(self, X_train: pd.DataFrame, y_train: pd.Series, cat_features: list, cv: int = 5):\n",
    "        if self.model_name == 'catboost':\n",
    "            model = CatBoostClassifier(\n",
    "                random_seed=42, verbose=0, eval_metric='F1',\n",
    "                cat_features=cat_features, class_weights=[1, 10]\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported model: {self.model_name}\")\n",
    "\n",
    "        self.logger.info(f\"Performing {cv}-fold cross-validation...\")\n",
    "        skf = StratifiedKFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "\n",
    "        fold_scores = []\n",
    "        for fold, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train)):\n",
    "            self.logger.info(f\"Processing fold {fold + 1}...\")\n",
    "\n",
    "            X_fold_train, X_fold_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "            y_fold_train, y_fold_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "            self.logger.info(f\"Validation set shape for fold {fold + 1}: {X_fold_val.shape}\")\n",
    "\n",
    "            model.fit(X_fold_train, y_fold_train, eval_set=(X_fold_val, y_fold_val), use_best_model=True)\n",
    "\n",
    "            fold_score = model.best_score_['validation']['F1']\n",
    "            fold_scores.append(fold_score)\n",
    "\n",
    "            self.logger.info(f\"Fold {fold + 1} F1 score: {fold_score}\")\n",
    "\n",
    "        mean_cv_score = sum(fold_scores) / len(fold_scores)\n",
    "        self.logger.info(f\"Mean cross-validation F1 score: {mean_cv_score}\")\n",
    "        return mean_cv_score\n",
    "\n",
    "    def train_model(self, X_train: pd.DataFrame, y_train: pd.Series, cat_features: list, val_size: float = 0.2):\n",
    "        if self.model_name == 'catboost':\n",
    "            model = CatBoostClassifier(\n",
    "            random_seed=42,\n",
    "            verbose=100,\n",
    "            eval_metric='F1',\n",
    "            cat_features=cat_features,\n",
    "           #auto_class_weights='Balanced',\n",
    "            max_depth=4,\n",
    "           #colsample_bylevel=0.7,\n",
    "            class_weights=[1, 1/a],\n",
    "          # bagging_temperature=.4,\n",
    "            grow_policy='SymmetricTree',\n",
    "          # one_hot_max_size = 15,\n",
    "           #earning_rate=0.2,\n",
    "          \n",
    "            bootstrap_type='Bernoulli',\n",
    "            early_stopping_rounds=100,\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported model: {self.model_name}\")\n",
    "\n",
    "        self.logger.info(f\"Training {self.model_name} model...\")\n",
    "        X_train.drop(columns=['session_id', 'DateTime', 'user_id'], inplace=True, errors='ignore')\n",
    "\n",
    "        X_train_final, X_valid, y_train_final, y_valid = train_test_split(\n",
    "            X_train, y_train, test_size=val_size, random_state=42)\n",
    "        \n",
    "\n",
    "        self.logger.info(f\"Training {self.model_name} model with validation set...\")\n",
    "        model.fit(X_train_final, y_train_final, eval_set=(X_valid, y_valid), use_best_model=True)\n",
    "\n",
    "        return model\n",
    "\n",
    "# Interactive Workflow for Jupyter Notebook\n",
    "# Define the data directory\n",
    "DATA_DIR = \"path/to/data\"  # Replace with your actual path\n",
    "\n",
    "# Initialize ModelTrainer\n",
    "trainer = ModelTrainer(DATA_DIR,model_name=\"catboost\")\n",
    "\n",
    "# Load data\n",
    "#X_train, y_train = trainer.load_data()\n",
    "\n",
    "# Determine categorical features\n",
    "cat_features = trainer.determine_categorical_features(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>campaign_id</th>\n",
       "      <th>webpage_id</th>\n",
       "      <th>user_group_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age_level</th>\n",
       "      <th>user_depth</th>\n",
       "      <th>city_development_index</th>\n",
       "      <th>var_1</th>\n",
       "      <th>product_category</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>C</td>\n",
       "      <td>359520</td>\n",
       "      <td>13787</td>\n",
       "      <td>4</td>\n",
       "      <td>Male</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197581</th>\n",
       "      <td>C</td>\n",
       "      <td>405490</td>\n",
       "      <td>60305</td>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43920</th>\n",
       "      <td>H</td>\n",
       "      <td>105960</td>\n",
       "      <td>11085</td>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332522</th>\n",
       "      <td>I</td>\n",
       "      <td>118601</td>\n",
       "      <td>28529</td>\n",
       "      <td>3</td>\n",
       "      <td>Male</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45995</th>\n",
       "      <td>C</td>\n",
       "      <td>359520</td>\n",
       "      <td>13787</td>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       product campaign_id webpage_id user_group_id gender  age_level  \\\n",
       "196          C      359520      13787             4   Male        4.0   \n",
       "197581       C      405490      60305             1   Male        1.0   \n",
       "43920        H      105960      11085             2   Male        2.0   \n",
       "332522       I      118601      28529             3   Male        3.0   \n",
       "45995        C      359520      13787             1   Male        1.0   \n",
       "\n",
       "        user_depth  city_development_index  var_1 product_category  hour  day  \\\n",
       "196            3.0                     NaN    0.0                4  11.0  4.0   \n",
       "197581         3.0                     2.0    0.0                3   7.0  6.0   \n",
       "43920          3.0                     4.0    0.0                5  13.0  4.0   \n",
       "332522         3.0                     2.0    1.0                4  22.0  7.0   \n",
       "45995          3.0                     3.0    0.0                4  12.0  2.0   \n",
       "\n",
       "        month  \n",
       "196       7.0  \n",
       "197581    7.0  \n",
       "43920     7.0  \n",
       "332522    7.0  \n",
       "45995     7.0  "
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop('user_group_id', inplace=True, axis=1)\n",
    "X_test.drop('user_group_id', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Training catboost model...\n",
      "INFO:__main__:Training catboost model with validation set...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.121943\n",
      "0:\tlearn: 0.5912225\ttest: 0.5956382\tbest: 0.5956382 (0)\ttotal: 295ms\tremaining: 4m 55s\n",
      "100:\tlearn: 0.5904047\ttest: 0.5874867\tbest: 0.5959797 (1)\ttotal: 41s\tremaining: 6m 4s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.5959797396\n",
      "bestIteration = 1\n",
      "\n",
      "Shrink model to first 2 iterations.\n"
     ]
    }
   ],
   "source": [
    "model = trainer.train_model(X_train, y_train, cat_features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['hour'] = X_test['DateTime'].dt.hour\n",
    "X_test['day'] = X_test['DateTime'].dt.day\n",
    "X_test['month'] = X_test['DateTime'].dt.month\n",
    "\n",
    "X_test = X_test.drop(columns=['session_id', 'DateTime', 'user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Categorical features: ['product', 'campaign_id', 'webpage_id', 'gender', 'product_category']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['product', 'campaign_id', 'webpage_id', 'gender', 'product_category']"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.determine_categorical_features(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9464    0.4739    0.6316     68166\n",
      "         1.0     0.0811    0.6334    0.1437      4994\n",
      "\n",
      "    accuracy                         0.4848     73160\n",
      "   macro avg     0.5137    0.5536    0.3876     73160\n",
      "weighted avg     0.8873    0.4848    0.5983     73160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "print(classification_report(y_test, y_pred,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.53\n",
      "Best F1 score: 0.15259781911481718\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# After training your CatBoost model:\n",
    "y_probs = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "best_threshold = 0.0\n",
    "best_f1 = 0.0\n",
    "\n",
    "# We can search thresholds from 0.0 to 1.0 in small steps\n",
    "for t in np.linspace(0, 1, 101):\n",
    "    y_pred = (y_probs >= t).astype(int)\n",
    "    score = f1_score(y_test, y_pred)\n",
    "    if score > best_f1:\n",
    "        best_f1 = score\n",
    "        best_threshold = t\n",
    "\n",
    "print(f\"Best threshold: {best_threshold}\")\n",
    "print(f\"Best F1 score: {best_f1}\")\n",
    "\n",
    "# When predicting on test data, use the best_threshold:\n",
    "y_probs_test = model.predict_proba(X_test)[:, 1]\n",
    "y_pred_test = (y_probs_test >= best_threshold).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive preprocessing (not my class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2= raw_data.drop(columns = ['session_id', 'DateTime', 'user_id','product_category_2'])\n",
    "data2.dropna(inplace = True) # Just close your eyes and drop the rows with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2 = data2.drop(columns = ['is_click'])\n",
    "y_2 = data2['is_click']\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_2, y_2, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_d2 = [\"product\", \"campaign_id\", \"webpage_id\", \"user_group_id\", \"gender\", \"product_category_1\"]\n",
    "\n",
    "X_train_2_d = pd.get_dummies(X_train_2, columns = columns_to_d2)\n",
    "X_test_2_d = pd.get_dummies(X_test_2, columns = columns_to_d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42,class_weight='balanced')\n",
    "rf.fit(X_train_2_d, y_train_2)\n",
    "y_pred_RF = rf.predict(X_test_2_d)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14298031865042174"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test_2, y_pred_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14430736693690518\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "model = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "model.fit(X_train_2_d, y_train_2)\n",
    "\n",
    "y_pred_LR = model.predict(X_test_2_d)\n",
    "print(f1_score(y_test_2, y_pred_LR))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Yofi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
