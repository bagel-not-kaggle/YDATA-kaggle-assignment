{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pickled data\n",
    "import pickle\n",
    "cleaned_data = pd.read_pickle(r\"C:\\Users\\maorb\\Classes\\Classical_ML\\YDATA-kaggle-assignment\\data\\processed\\cleaned_data_Maor.pkl\")\n",
    "X_train = pd.read_pickle(r\"C:\\Users\\maorb\\Classes\\Classical_ML\\YDATA-kaggle-assignment\\data\\processed\\X_train.pkl\")\n",
    "X_test = pd.read_pickle(r\"C:\\Users\\maorb\\Classes\\Classical_ML\\YDATA-kaggle-assignment\\data\\processed\\X_test.pkl\")\n",
    "y_train = pd.read_pickle(r\"C:\\Users\\maorb\\Classes\\Classical_ML\\YDATA-kaggle-assignment\\data\\processed\\y_train.pkl\")\n",
    "y_test = pd.read_pickle(r\"C:\\Users\\maorb\\Classes\\Classical_ML\\YDATA-kaggle-assignment\\data\\processed\\y_test.pkl\")\n",
    "predictions = pd.read_csv(r'C:\\Users\\maorb\\Classes\\Classical_ML\\YDATA-kaggle-assignment\\predictions\\predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(r\"C:\\Users\\maorb\\Classes\\Classical_ML\\YDATA-kaggle-assignment\\data\\raw\\train_dataset_full.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((293307, 15),\n",
       " (73327, 15),\n",
       " (293307,),\n",
       " (73327,),\n",
       " (73160, 1),\n",
       " (365798, 14),\n",
       " (389163, 15))"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape, predictions.shape, cleaned_data.shape, raw_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product                   0\n",
       "campaign_id               0\n",
       "webpage_id                0\n",
       "gender                    0\n",
       "age_level                 0\n",
       "user_depth                0\n",
       "city_development_index    0\n",
       "var_1                     0\n",
       "product_category          0\n",
       "Month                     0\n",
       "Day                       0\n",
       "Hour                      0\n",
       "Minute                    0\n",
       "weekday                   0\n",
       "campaign_duration_days    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((292638, 13),\n",
       " (73160, 13),\n",
       " (292638,),\n",
       " (73160,),\n",
       " (73160, 1),\n",
       " (365798, 14),\n",
       " (389163, 15))"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape, predictions.shape, cleaned_data.shape, raw_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19510, 15)"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find how many duplicated rows we have\n",
    "duplicates = raw_data[raw_data.duplicated()]\n",
    "duplicates.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.isna().sum()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month\n",
      "Day\n",
      "Hour\n",
      "Minute\n",
      "weekday\n",
      "product\n",
      "campaign_id\n",
      "webpage_id\n",
      "gender\n",
      "age_level\n",
      "user_depth\n",
      "city_development_index\n",
      "var_1\n",
      "product_category\n",
      "Month\n",
      "Day\n",
      "Hour\n",
      "Minute\n",
      "weekday\n",
      "product\n",
      "campaign_id\n",
      "webpage_id\n",
      "gender\n",
      "age_level\n",
      "user_depth\n",
      "city_development_index\n",
      "var_1\n",
      "product_category\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def feature_generation(df):\n",
    "    \"\"\"Generate date/time features and fill missing values in a faster, \n",
    "       more scalable way without repeated group-based ffill/bfill.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # If not already a datetime, convert:\n",
    "    # df['DateTime'] = pd.to_datetime(df['DateTime'])\n",
    "    \n",
    "    # -- 1) Create date/time features --\n",
    "    df['Month'] = df['DateTime'].dt.month\n",
    "    df['Day'] = df['DateTime'].dt.day\n",
    "    df['Hour'] = df['DateTime'].dt.hour\n",
    "    df['Minute'] = df['DateTime'].dt.minute\n",
    "    df['weekday'] = df['DateTime'].dt.weekday\n",
    "    \n",
    "    # -- 2) Drop unnecessary columns --\n",
    "    df.drop(columns=['DateTime', 'session_id'], inplace=True, errors='ignore')\n",
    "    \n",
    "    # -- 3) Make user_id a consistent type --\n",
    "    # (Strings are often safer keys for merges.)\n",
    "    df['user_id'] = df['user_id'].astype(str)\n",
    "    \n",
    "    # -- 4) Identify columns to fill by median vs. mode --\n",
    "    #    (You can tune these lists as needed.)\n",
    "    columns_to_fill_median = ['Month', 'Day', 'Hour', 'Minute', 'weekday']\n",
    "    columns_to_fill_mode = [\n",
    "        'product', 'campaign_id', 'webpage_id', 'gender', \n",
    "        'age_level', 'user_depth', 'city_development_index', \n",
    "        'var_1', 'product_category'\n",
    "    ]\n",
    "    \n",
    "    # Keep only columns that actually exist in df\n",
    "    columns_to_fill_median = [c for c in columns_to_fill_median if c in df.columns]\n",
    "    columns_to_fill_mode = [c for c in columns_to_fill_mode if c in df.columns]\n",
    "    \n",
    "    # -- 5) Precompute the user-level medians/modes in one pass each --\n",
    "    if columns_to_fill_median:\n",
    "        median_df = (\n",
    "            df.groupby('user_id')[columns_to_fill_median]\n",
    "            .median()\n",
    "            .reset_index()\n",
    "        )\n",
    "    \n",
    "    # Mode can be tricky (pandas mode can return multiple values).\n",
    "    # We'll define a custom aggregator that picks the first mode if multiple modes exist.\n",
    "    def agg_mode(s):\n",
    "        m = s.mode(dropna=True)\n",
    "        return m.iloc[0] if len(m) > 0 else np.nan\n",
    "        \n",
    "    if columns_to_fill_mode:\n",
    "        mode_df = (\n",
    "            df.groupby('user_id')[columns_to_fill_mode]\n",
    "            .agg(agg_mode)\n",
    "            .reset_index()\n",
    "        )\n",
    "        \n",
    "    # -- 6) Merge those statistics back to df --\n",
    "    # This is usually much more performant than repeated group transforms:\n",
    "    if columns_to_fill_median:\n",
    "        df = df.merge(\n",
    "            median_df, \n",
    "            on='user_id', \n",
    "            suffixes=('', '_median')\n",
    "        )\n",
    "    if columns_to_fill_mode:\n",
    "        df = df.merge(\n",
    "            mode_df, \n",
    "            on='user_id', \n",
    "            suffixes=('', '_mode')\n",
    "        )\n",
    "        \n",
    "    # -- 7) Fill missing values in df using the merged median/mode --\n",
    "    if columns_to_fill_median:\n",
    "        for col in columns_to_fill_median:\n",
    "            df[col] = df[col].fillna(df[f'{col}_median'])\n",
    "            df.drop(columns=[f'{col}_median'], inplace=True, errors='ignore')\n",
    "            \n",
    "    if columns_to_fill_mode:\n",
    "        for col in columns_to_fill_mode:\n",
    "            df[col] = df[col].fillna(df[f'{col}_mode'])\n",
    "            df.drop(columns=[f'{col}_mode'], inplace=True, errors='ignore')\n",
    "    \n",
    "    for col in columns_to_fill_median:\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "    for col in columns_to_fill_mode:\n",
    "        df[col] = df[col].fillna(df[col].mode()[0])\n",
    "    \n",
    "    df.drop(columns=['user_id','user_group_id'], inplace=True, errors='ignore')\n",
    "            \n",
    "    return df\n",
    "\n",
    "# Example usage:\n",
    "X_train_u = feature_generation(X_train)\n",
    "X_test_u  = feature_generation(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_with_mode(df: pd.DataFrame, columns: list):\n",
    "    df = df.copy()\n",
    "    for column in columns:\n",
    "        if column in df.columns:\n",
    "            mode_value = df[column].mode()[0]  # Calculate the mode\n",
    "            df[column] = df[column].fillna(mode_value)  # Fill missing values with the mode\n",
    "    return df\n",
    "\n",
    "def fill_missing_with_median(df: pd.DataFrame, columns: list):\n",
    "    df = df.copy()\n",
    "    for column in columns:\n",
    "        if column in df.columns:\n",
    "            median_value = df[column].median()  # Calculate the median\n",
    "            df[column] = df[column].fillna(median_value)  # Fill missing values with the median\n",
    "    return df   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['session_id', 'DateTime', 'user_id', 'product', 'campaign_id',\n",
       "       'webpage_id', 'user_group_id', 'gender', 'age_level', 'user_depth',\n",
       "       'city_development_index', 'var_1', 'product_category'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_with_mode(df: pd.DataFrame, columns: list):\n",
    "    df = df.copy()\n",
    "    for column in columns:\n",
    "        if column in df.columns:\n",
    "            mode_value = df[column].mode()[0]  # Calculate the mode\n",
    "            df[column] = df[column].fillna(mode_value)  # Fill missing values with the mode\n",
    "    return df\n",
    "\n",
    "def fill_missing_with_median(df: pd.DataFrame, columns: list):\n",
    "    df = df.copy()\n",
    "    for column in columns:\n",
    "        if column in df.columns:\n",
    "            median_value = df[column].median()  # Calculate the median\n",
    "            df[column] = df[column].fillna(median_value)  # Fill missing values with the median\n",
    "    return df   \n",
    "\n",
    "def feature_generation(df, use_missing_with_mode=False, get_dumm=False,catb = True):\n",
    "    df = df.copy()\n",
    "    df['Month'] = df['DateTime'].dt.month\n",
    "    df['Day'] = df['DateTime'].dt.day\n",
    "    df['Hour'] = df['DateTime'].dt.hour\n",
    "    df['Minute'] = df['DateTime'].dt.minute\n",
    "    df['weekday'] = df['DateTime'].dt.weekday\n",
    "    \n",
    "    columns_to_fill_median = [\"Month\", \"Day\", \"Hour\", \"Minute\", \"weekday\"]\n",
    "    if use_missing_with_mode:\n",
    "        columns_to_fill_mode = [\"product\", \"campaign_id\", \"webpage_id\", \"user_group_id\", \"gender\", \"age_level\", \"user_depth\", \"city_development_index\", \"var_1\", \"product_category\",\n",
    "                     \"month\", \"day\", \"hour\"]\n",
    "        df = fill_missing_with_mode(df, columns_to_fill_mode)\n",
    "    df['campaign_id'] = df['campaign_id'].fillna(df['campaign_id'].mode()[0])\n",
    "    df = fill_missing_with_median(df, columns_to_fill_median)\n",
    "    print(df.isna().sum())\n",
    "    df['start_date'] = df.groupby('campaign_id',observed=True)['DateTime'].transform('min')\n",
    "    df['campaign_duration'] = df['DateTime'] - df['start_date']\n",
    "    df['campaign_duration_days'] = df['campaign_duration'].dt.total_seconds() / (3600) #hour did not improve, day didn't improve either\n",
    "    df['campaign_duration_days'] = df['campaign_duration_days'].fillna(\n",
    "    df.groupby('campaign_id',observed=True)['campaign_duration_days'].transform(lambda x: x.mode().iloc[0])).astype(int)\n",
    "    df.drop(columns=['DateTime', 'start_date', 'campaign_duration','session_id','user_id','user_group_id'], inplace=True)\n",
    "    if get_dumm:\n",
    "        columns_to_d = [\"product\", \"campaign_id\", \"webpage_id\", \"product_category\", \"gender\"]\n",
    "        df = pd.get_dummies(df, columns=columns_to_d)\n",
    "\n",
    "\n",
    "    return df\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_with_mode(df: pd.DataFrame, columns: list):\n",
    "    df = df.copy()\n",
    "    for column in columns:\n",
    "        if column in df.columns:\n",
    "            mode_value = df[column].mode()[0]  # Calculate the mode\n",
    "            df[column] = df[column].fillna(mode_value)  # Fill missing values with the mode\n",
    "    return df\n",
    "\n",
    "def fill_missing_with_median(df: pd.DataFrame, columns: list):\n",
    "    df = df.copy()\n",
    "    for column in columns:\n",
    "        if column in df.columns:\n",
    "            median_value = df[column].median()  # Calculate the median\n",
    "            df[column] = df[column].fillna(median_value)  # Fill missing values with the median\n",
    "    return df\n",
    "\n",
    "def determine_categorical_features(df: pd.DataFrame, cat_features: list = None):\n",
    "\n",
    "    if cat_features:\n",
    "        cat_features = [col for col in cat_features if col in df.columns]\n",
    "    else:\n",
    "        cat_features = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "    for col in cat_features:\n",
    "        if col in df.columns:\n",
    "            # Ensure column is treated as category\n",
    "            df[col] = df[col].astype(\"category\")\n",
    "\n",
    "            # Add \"missing\" only if it's not already a category\n",
    "            if \"missing\" not in df[col].cat.categories:\n",
    "                df[col] = df[col].cat.add_categories(\"missing\")\n",
    "\n",
    "            # Fill missing values with \"missing\"\n",
    "            df[col] = df[col].fillna(\"missing\")\n",
    "\n",
    "    return cat_features\n",
    "\n",
    "def feature_generation2(df, use_missing_with_mode=False, get_dumm=False, catb=True, cat_features=None):\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    # Generate time-based features\n",
    "    df['Month'] = df['DateTime'].dt.month\n",
    "    df['Day'] = df['DateTime'].dt.day\n",
    "    df['Hour'] = df['DateTime'].dt.hour\n",
    "    df['Minute'] = df['DateTime'].dt.minute\n",
    "    df['weekday'] = df['DateTime'].dt.weekday\n",
    "\n",
    "    # Handle categorical features if `catb` is True\n",
    "    if catb:\n",
    "        cat_features = determine_categorical_features(df, cat_features)\n",
    "\n",
    "    # Fill missing values\n",
    "    if use_missing_with_mode:\n",
    "        print(\"Filling missing values with mode\")\n",
    "        columns_to_fill_mode = [\"product\", \"campaign_id\", \"webpage_id\", \"user_group_id\", \"gender\", \"age_level\", \"user_depth\", \"city_development_index\", \"var_1\", \"product_category\",\n",
    "                                \"Month\", \"Day\", \"Hour\"]\n",
    "        df = fill_missing_with_mode(df, columns_to_fill_mode)\n",
    "\n",
    "    columns_to_fill_median = [\"Month\", \"Day\", \"Hour\", \"Minute\", \"weekday\", \"city_development_index\", \"age_level\", \"user_depth\"]\n",
    "    df['campaign_id'] = df['campaign_id'].fillna(df['campaign_id'].mode()[0]) #userid and sessionid have nas. What can we do else?\n",
    "    df['var_1'] = df['var_1'].fillna(df['var_1'].mode()[0])\n",
    "    df = fill_missing_with_median(df, columns_to_fill_median)\n",
    "\n",
    "    # Generate campaign-based features\n",
    "    df['start_date'] = df.groupby('campaign_id', observed=True)['DateTime'].transform('min')\n",
    "    df['campaign_duration'] = df['DateTime'] - df['start_date']\n",
    "    df['campaign_duration_days'] = df['campaign_duration'].dt.total_seconds() / (3600*24)\n",
    "    df['campaign_duration_days'] = df['campaign_duration_days'].fillna(\n",
    "        df.groupby('campaign_id', observed=True)['campaign_duration_days'].transform(lambda x: x.mode().iloc[0])).astype(int)\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    df.drop(columns=['DateTime', 'start_date', 'campaign_duration', 'session_id', 'user_id', 'user_group_id'], inplace=True)\n",
    "\n",
    "    # One-hot encoding if `get_dumm` is True\n",
    "    if get_dumm:\n",
    "        columns_to_d = [\"product\", \"campaign_id\", \"webpage_id\", \"product_category\", \"gender\"]\n",
    "        df = pd.get_dummies(df, columns=columns_to_d)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2 = feature_generation2(X_train)\n",
    "X_test2 = feature_generation2(X_test)\n",
    "cat_features = determine_categorical_features(X_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_d = [\"product\", \"campaign_id\", \"webpage_id\", \"product_category\", \"gender\"]\n",
    "X_train_d = pd.get_dummies(X_train, columns=columns_to_d)\n",
    "X_test_d = pd.get_dummies(X_test, columns=columns_to_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender\n",
       "Male       248397\n",
       "Female      32776\n",
       "missing     11465\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train2['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03980257920713262"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42,class_weight='balanced')\n",
    "rf.fit(X_train2, y_train)\n",
    "y_pred = rf.predict(X_test2)\n",
    "\n",
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Apply SMOTE to balance the training set\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train2, y_train)\n",
    "\n",
    "# Train Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred2 = rf.predict(X_test2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1433358256486943\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, classification_report\n",
    "#adjuct the balance of the classes\n",
    "model = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42, solver='liblinear',\n",
    "                           penalty='l2', C=0.1)\n",
    "model.fit(X_train_filled_d, y_train)\n",
    "\n",
    "y_pred_LR = model.predict(X_test_filled_d)\n",
    "print(f1_score(y_test, y_pred_LR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.14267398, 0.14025811, 0.14581596, 0.13800516, 0.14146667])"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB, ComplementNB\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "model = ComplementNB()\n",
    "cross_val_score(model, X_train_d, y_train, cv=5, scoring='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.14497621046739434\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.59      0.73     68818\n",
      "         1.0       0.08      0.51      0.14      5063\n",
      "\n",
      "    accuracy                           0.59     73881\n",
      "   macro avg       0.51      0.55      0.44     73881\n",
      "weighted avg       0.88      0.59      0.69     73881\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB, ComplementNB\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "model = ComplementNB()\n",
    "model.fit(X_train_d, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test_d)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f\"F1-score: {f1}\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Baseline? :()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9323260378678943"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data['is_click'].value_counts()[0]/cleaned_data['is_click'].value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1- cleaned_data['is_click'].value_counts()[0]/cleaned_data['is_click'].value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 292638 entries, 196 to 123594\n",
      "Data columns (total 16 columns):\n",
      " #   Column                  Non-Null Count   Dtype         \n",
      "---  ------                  --------------   -----         \n",
      " 0   session_id              292076 non-null  float64       \n",
      " 1   DateTime                292049 non-null  datetime64[ns]\n",
      " 2   user_id                 292638 non-null  float64       \n",
      " 3   product                 292584 non-null  category      \n",
      " 4   campaign_id             292063 non-null  category      \n",
      " 5   webpage_id              292048 non-null  category      \n",
      " 6   user_group_id           280649 non-null  category      \n",
      " 7   gender                  281173 non-null  category      \n",
      " 8   age_level               281178 non-null  float64       \n",
      " 9   user_depth              280646 non-null  float64       \n",
      " 10  city_development_index  213253 non-null  float64       \n",
      " 11  var_1                   292591 non-null  float64       \n",
      " 12  product_category        292139 non-null  category      \n",
      " 13  hour                    292049 non-null  float64       \n",
      " 14  day                     292049 non-null  float64       \n",
      " 15  month                   292049 non-null  float64       \n",
      "dtypes: category(6), datetime64[ns](1), float64(9)\n",
      "memory usage: 26.2 MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1 = X_train.drop(columns=['session_id', 'DateTime', 'user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "def objective(trial):\n",
    "    # --- 1) Suggest hyperparams ---\n",
    "    # Example search space: Feel free to expand or tune ranges\n",
    "    params = {\n",
    "        \"iterations\": 1000,\n",
    "        \"depth\": trial.suggest_int(\"depth\", 4, 8),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.1),\n",
    "        \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 1, 100),\n",
    "        \"bagging_temperature\": trial.suggest_float(\"bagging_temperature\", 0.0, 1.0),\n",
    "        # Commonly used knobs; random_strength, subsample, etc. can also be tuned\n",
    "        \"eval_metric\": \"F1\",\n",
    "        \"random_seed\": 42,\n",
    "        \"auto_class_weights\": \"Balanced\",\n",
    "        \"verbose\": 0  # Keep CatBoost silent\n",
    "    }\n",
    "\n",
    "    # --- 2) Create CatBoost model ---\n",
    "    model = CatBoostClassifier(**params)\n",
    "\n",
    "    # --- 3) Train/Validation split ---\n",
    "    X_train_sub, X_val_sub, y_train_sub, y_val_sub = train_test_split(\n",
    "        X_train1,\n",
    "        y_train,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=y_train\n",
    "    )\n",
    "\n",
    "    # --- 4) Train ---\n",
    "    model.fit(\n",
    "        X_train_sub,\n",
    "        y_train_sub,\n",
    "        cat_features=cat_features,\n",
    "        eval_set=(X_val_sub, y_val_sub),\n",
    "        early_stopping_rounds=50,\n",
    "        use_best_model=True\n",
    "    )\n",
    "\n",
    "    # --- 5) Predict ---\n",
    "    y_pred_val = model.predict(X_val_sub)\n",
    "\n",
    "    # --- 6) Evaluate ---\n",
    "    f1 = f1_score(y_val_sub, y_pred_val)\n",
    "\n",
    "    # Return the F1 (Optuna will try to maximize this)\n",
    "    return f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-23 21:27:34,790] A new study created in memory with name: no-name-8ce8d20c-b456-437c-8c24-278df2096bb7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbdc95c3af0e49d083c41c6c90b7cb93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-23 21:27:52,779] Trial 0 finished with value: 0.14241381636645753 and parameters: {'iterations': 700, 'depth': 7, 'learning_rate': 0.09744541619010162, 'l2_leaf_reg': 4.6845889641307, 'bagging_temperature': 0.6083577649428933}. Best is trial 0 with value: 0.14241381636645753.\n",
      "[I 2025-01-23 21:29:00,012] Trial 1 finished with value: 0.14715379312846932 and parameters: {'iterations': 900, 'depth': 8, 'learning_rate': 0.06056087732149749, 'l2_leaf_reg': 44.82689039760325, 'bagging_temperature': 0.3545388999625765}. Best is trial 1 with value: 0.14715379312846932.\n",
      "[I 2025-01-23 21:29:18,804] Trial 2 finished with value: 0.14246593421096043 and parameters: {'iterations': 400, 'depth': 6, 'learning_rate': 0.012942977089435637, 'l2_leaf_reg': 23.56083041913574, 'bagging_temperature': 0.4558729858095575}. Best is trial 1 with value: 0.14715379312846932.\n",
      "[I 2025-01-23 21:29:34,801] Trial 3 finished with value: 0.14265668849391955 and parameters: {'iterations': 700, 'depth': 7, 'learning_rate': 0.080796438459713, 'l2_leaf_reg': 92.0943432488394, 'bagging_temperature': 0.475600614080402}. Best is trial 1 with value: 0.14715379312846932.\n",
      "[I 2025-01-23 21:31:07,688] Trial 4 finished with value: 0.1476639519931419 and parameters: {'iterations': 1000, 'depth': 6, 'learning_rate': 0.09878531291168284, 'l2_leaf_reg': 75.88220809988779, 'bagging_temperature': 0.5426526136974688}. Best is trial 4 with value: 0.1476639519931419.\n",
      "[I 2025-01-23 21:31:14,758] Trial 5 finished with value: 0.14193717106338466 and parameters: {'iterations': 100, 'depth': 5, 'learning_rate': 0.07919274800341754, 'l2_leaf_reg': 21.655654371660916, 'bagging_temperature': 0.2731348218643188}. Best is trial 4 with value: 0.1476639519931419.\n",
      "[I 2025-01-23 21:31:38,377] Trial 6 finished with value: 0.14265668849391955 and parameters: {'iterations': 700, 'depth': 7, 'learning_rate': 0.07313717065119897, 'l2_leaf_reg': 43.54707008765233, 'bagging_temperature': 0.3064446390337354}. Best is trial 4 with value: 0.1476639519931419.\n",
      "[I 2025-01-23 21:32:05,187] Trial 7 finished with value: 0.1426403641881639 and parameters: {'iterations': 400, 'depth': 8, 'learning_rate': 0.031049701486487724, 'l2_leaf_reg': 96.73421630866153, 'bagging_temperature': 0.05288639536409112}. Best is trial 4 with value: 0.1476639519931419.\n",
      "[I 2025-01-23 21:32:19,125] Trial 8 finished with value: 0.14228179057176812 and parameters: {'iterations': 400, 'depth': 4, 'learning_rate': 0.05740633926082669, 'l2_leaf_reg': 16.671189982269283, 'bagging_temperature': 0.5555896608966858}. Best is trial 4 with value: 0.1476639519931419.\n",
      "[I 2025-01-23 21:32:45,839] Trial 9 finished with value: 0.14265743803061817 and parameters: {'iterations': 400, 'depth': 7, 'learning_rate': 0.0027632081531127053, 'l2_leaf_reg': 30.97229508667193, 'bagging_temperature': 0.6683993695585385}. Best is trial 4 with value: 0.1476639519931419.\n",
      "[I 2025-01-23 21:33:05,554] Trial 10 finished with value: 0.14198398431116196 and parameters: {'iterations': 1000, 'depth': 5, 'learning_rate': 0.03761110219796429, 'l2_leaf_reg': 72.55075722853606, 'bagging_temperature': 0.9453440034853672}. Best is trial 4 with value: 0.1476639519931419.\n",
      "[I 2025-01-23 21:33:33,086] Trial 11 finished with value: 0.1421941711527752 and parameters: {'iterations': 1000, 'depth': 8, 'learning_rate': 0.0929529962862502, 'l2_leaf_reg': 64.33952272843467, 'bagging_temperature': 0.7830590926048931}. Best is trial 4 with value: 0.1476639519931419.\n",
      "[I 2025-01-23 21:33:51,274] Trial 12 finished with value: 0.1433358407987417 and parameters: {'iterations': 900, 'depth': 6, 'learning_rate': 0.05891503727110363, 'l2_leaf_reg': 60.757133260029896, 'bagging_temperature': 0.271256291978086}. Best is trial 4 with value: 0.1476639519931419.\n",
      "[I 2025-01-23 21:34:04,181] Trial 13 finished with value: 0.14195573282767188 and parameters: {'iterations': 800, 'depth': 5, 'learning_rate': 0.04522327290581978, 'l2_leaf_reg': 76.57520207708575, 'bagging_temperature': 0.09596522705782784}. Best is trial 4 with value: 0.1476639519931419.\n",
      "[I 2025-01-23 21:36:43,461] Trial 14 finished with value: 0.14685642226625834 and parameters: {'iterations': 900, 'depth': 8, 'learning_rate': 0.06732309624113147, 'l2_leaf_reg': 45.250976255460664, 'bagging_temperature': 0.32834021621388704}. Best is trial 4 with value: 0.1476639519931419.\n",
      "[I 2025-01-23 21:37:15,302] Trial 15 finished with value: 0.14398544131028207 and parameters: {'iterations': 1000, 'depth': 6, 'learning_rate': 0.08612888043149991, 'l2_leaf_reg': 82.70889319860106, 'bagging_temperature': 0.7856572385711114}. Best is trial 4 with value: 0.1476639519931419.\n",
      "[I 2025-01-23 21:37:32,643] Trial 16 finished with value: 0.14198398431116196 and parameters: {'iterations': 600, 'depth': 4, 'learning_rate': 0.02301173283485969, 'l2_leaf_reg': 54.95664099116852, 'bagging_temperature': 0.16643462522036656}. Best is trial 4 with value: 0.1476639519931419.\n",
      "[I 2025-01-23 21:37:50,223] Trial 17 finished with value: 0.14205827528696163 and parameters: {'iterations': 800, 'depth': 5, 'learning_rate': 0.06475781964812169, 'l2_leaf_reg': 37.13556167482765, 'bagging_temperature': 0.4307283433006669}. Best is trial 4 with value: 0.1476639519931419.\n",
      "[I 2025-01-23 21:39:04,031] Trial 18 finished with value: 0.1462921510578381 and parameters: {'iterations': 900, 'depth': 6, 'learning_rate': 0.09722642044234332, 'l2_leaf_reg': 67.10077386399205, 'bagging_temperature': 0.7275165541861098}. Best is trial 4 with value: 0.1476639519931419.\n",
      "[I 2025-01-23 21:39:12,640] Trial 19 finished with value: 0.14193717106338466 and parameters: {'iterations': 100, 'depth': 7, 'learning_rate': 0.038977556807282585, 'l2_leaf_reg': 52.49479356567382, 'bagging_temperature': 0.39635227325266853}. Best is trial 4 with value: 0.1476639519931419.\n"
     ]
    }
   ],
   "source": [
    "# Create study that aims to maximize F1\n",
    "import optuna\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "\n",
    "# Optimize over 'objective' for a certain number of trials\n",
    "study.optimize(objective, n_trials=20, show_progress_bar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Categorical features: ['product', 'campaign_id', 'webpage_id', 'gender', 'product_category']\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "# Define the ModelTrainer class\n",
    "class ModelTrainer:\n",
    "    def __init__(self, data_dir: False, model_name: str = \"catboost\", cat_features: list = None):\n",
    "        #self.data_dir = Path(data_dir)\n",
    "        self.model_name = model_name\n",
    "        self.cat_features = cat_features\n",
    "\n",
    "        logging.basicConfig(level=logging.INFO)\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "\n",
    "    def load_data(self):\n",
    "        self.logger.info(f\"Loading preprocessed data from {self.data_dir}...\")\n",
    "        X_train = pd.read_pickle(self.data_dir / \"X_train.pkl\")\n",
    "        y_train = pd.read_pickle(self.data_dir / \"y_train.pkl\").squeeze()\n",
    "        return X_train, y_train\n",
    "\n",
    "    def determine_categorical_features(self, X_train: pd.DataFrame):\n",
    "        if self.cat_features:\n",
    "            cat_features = [col for col in self.cat_features if col in X_train.columns]\n",
    "        else:\n",
    "            cat_features = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "        self.logger.info(f\"Categorical features: {cat_features}\")\n",
    "        return cat_features\n",
    "\n",
    "\n",
    "    def cross_validate_model(self, X_train: pd.DataFrame, y_train: pd.Series, cat_features: list, cv: int = 5):\n",
    "        if self.model_name == 'catboost':\n",
    "            model = CatBoostClassifier(\n",
    "                random_seed=42, verbose=0, eval_metric='F1',\n",
    "                cat_features=cat_features, class_weights=[1, 10]\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported model: {self.model_name}\")\n",
    "\n",
    "        self.logger.info(f\"Performing {cv}-fold cross-validation...\")\n",
    "        skf = StratifiedKFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "\n",
    "        fold_scores = []\n",
    "        for fold, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train)):\n",
    "            self.logger.info(f\"Processing fold {fold + 1}...\")\n",
    "\n",
    "            X_fold_train, X_fold_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "            y_fold_train, y_fold_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "            self.logger.info(f\"Validation set shape for fold {fold + 1}: {X_fold_val.shape}\")\n",
    "\n",
    "            model.fit(X_fold_train, y_fold_train, eval_set=(X_fold_val, y_fold_val), use_best_model=True)\n",
    "\n",
    "            fold_score = model.best_score_['validation']['F1']\n",
    "            fold_scores.append(fold_score)\n",
    "\n",
    "            self.logger.info(f\"Fold {fold + 1} F1 score: {fold_score}\")\n",
    "\n",
    "        mean_cv_score = sum(fold_scores) / len(fold_scores)\n",
    "        self.logger.info(f\"Mean cross-validation F1 score: {mean_cv_score}\")\n",
    "        return mean_cv_score\n",
    "\n",
    "    def train_model(self, X_train: pd.DataFrame, y_train: pd.Series, cat_features: list, val_size: float = 0.2):\n",
    "        if self.model_name == 'catboost':\n",
    "            model = CatBoostClassifier(\n",
    "            random_seed=42,\n",
    "            verbose=100,\n",
    "            eval_metric='F1',\n",
    "            cat_features=cat_features,\n",
    "           #auto_class_weights='Balanced',\n",
    "            max_depth=5,\n",
    "           #colsample_bylevel=0.7,\n",
    "            class_weights=[1, 1/a],\n",
    "            bagging_temperature=0.4,\n",
    "            grow_policy='SymmetricTree',\n",
    "          # one_hot_max_size = 40,\n",
    "          # learning_rate=0.1,\n",
    "         #  subsample=.67,   #lower subsample showed progress\n",
    "         #  max_leaves= 64, #only with lossguide\n",
    "            bootstrap_type = \"Bayesian\", #Bayesian uses the posterior probability of the object \n",
    "                                        #to sample the trees in the growing process. Good for regularization and overfitting control.\n",
    "          # bootstrap_type='Bernoulli', #Bernoulli is Stochastic Gradient Boosting on random subsets of features, faster and less overfitting\n",
    "            early_stopping_rounds=100,\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported model: {self.model_name}\")\n",
    "\n",
    "        self.logger.info(f\"Training {self.model_name} model...\")\n",
    "        X_train.drop(columns=['session_id', 'DateTime', 'user_id'], inplace=True, errors='ignore')\n",
    "\n",
    "        X_train_final, X_valid, y_train_final, y_valid = train_test_split(\n",
    "            X_train, y_train, test_size=val_size, random_state=42)\n",
    "        \n",
    "\n",
    "        self.logger.info(f\"Training {self.model_name} model with validation set...\")\n",
    "        model.fit(X_train_final, y_train_final, eval_set=(X_valid, y_valid), use_best_model=True)\n",
    "\n",
    "        return model\n",
    "\n",
    "# Interactive Workflow for Jupyter Notebook\n",
    "# Define the data directory\n",
    "DATA_DIR = \"path/to/data\"  # Replace with your actual path\n",
    "\n",
    "# Initialize ModelTrainer\n",
    "trainer = ModelTrainer(DATA_DIR,model_name=\"catboost\")\n",
    "cat_features = trainer.determine_categorical_features(X_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06767396213210575"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Training catboost model...\n",
      "INFO:__main__:Training catboost model with validation set...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.122239\n",
      "0:\tlearn: 0.5681503\ttest: 0.5585585\tbest: 0.5585585 (0)\ttotal: 191ms\tremaining: 3m 10s\n",
      "100:\tlearn: 0.6083793\ttest: 0.5910177\tbest: 0.5937677 (39)\ttotal: 26.1s\tremaining: 3m 52s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.5937676693\n",
      "bestIteration = 39\n",
      "\n",
      "Shrink model to first 40 iterations.\n"
     ]
    }
   ],
   "source": [
    "model = trainer.train_model(X_train, y_train, cat_features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9462    0.4857    0.6419     68818\n",
      "         1.0     0.0820    0.6245    0.1450      5063\n",
      "\n",
      "    accuracy                         0.4952     73881\n",
      "   macro avg     0.5141    0.5551    0.3934     73881\n",
      "weighted avg     0.8870    0.4952    0.6078     73881\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "print(classification_report(y_test, y_pred,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.54\n",
      "Best F1 score: 0.1525829895894716\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# After training your CatBoost model:\n",
    "y_probs = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "best_threshold = 0.0\n",
    "best_f1 = 0.0\n",
    "\n",
    "# We can search thresholds from 0.0 to 1.0 in small steps\n",
    "for t in np.linspace(0, 1, 101):\n",
    "    y_pred = (y_probs >= t).astype(int)\n",
    "    score = f1_score(y_test, y_pred)\n",
    "    if score > best_f1:\n",
    "        best_f1 = score\n",
    "        best_threshold = t\n",
    "\n",
    "print(f\"Best threshold: {best_threshold}\")\n",
    "print(f\"Best F1 score: {best_f1}\")\n",
    "\n",
    "# When predicting on test data, use the best_threshold:\n",
    "y_probs_test = model.predict_proba(X_test)[:, 1]\n",
    "y_pred_test = (y_probs_test >= best_threshold).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive preprocessing (not my class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2= raw_data.drop(columns = ['session_id', 'DateTime', 'user_id','product_category_2'])\n",
    "data2.dropna(inplace = True) # Just close your eyes and drop the rows with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2 = data2.drop(columns = ['is_click'])\n",
    "y_2 = data2['is_click']\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_2, y_2, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_d2 = [\"product\", \"campaign_id\", \"webpage_id\", \"user_group_id\", \"gender\", \"product_category_1\"]\n",
    "\n",
    "X_train_2_d = pd.get_dummies(X_train_2, columns = columns_to_d2)\n",
    "X_test_2_d = pd.get_dummies(X_test_2, columns = columns_to_d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42,class_weight='balanced')\n",
    "rf.fit(X_train_2_d, y_train_2)\n",
    "y_pred_RF = rf.predict(X_test_2_d)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14298031865042174"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test_2, y_pred_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14430736693690518\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "model = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "model.fit(X_train_2_d, y_train_2)\n",
    "\n",
    "y_pred_LR = model.predict(X_test_2_d)\n",
    "print(f1_score(y_test_2, y_pred_LR))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Yofi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
