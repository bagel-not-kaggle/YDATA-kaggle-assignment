{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pickled data\n",
    "import pickle\n",
    "cleaned_data = pd.read_pickle(r\"C:\\Users\\maorb\\Classes\\Classical_ML\\YDATA-kaggle-assignment\\data\\processed\\cleaned_data_Maor.pkl\")\n",
    "X_train = pd.read_pickle(r\"C:\\Users\\maorb\\Classes\\Classical_ML\\YDATA-kaggle-assignment\\data\\processed\\X_train.pkl\")\n",
    "X_test = pd.read_pickle(r\"C:\\Users\\maorb\\Classes\\Classical_ML\\YDATA-kaggle-assignment\\data\\processed\\X_test.pkl\")\n",
    "y_train = pd.read_pickle(r\"C:\\Users\\maorb\\Classes\\Classical_ML\\YDATA-kaggle-assignment\\data\\processed\\y_train.pkl\")\n",
    "y_test = pd.read_pickle(r\"C:\\Users\\maorb\\Classes\\Classical_ML\\YDATA-kaggle-assignment\\data\\processed\\y_test.pkl\")\n",
    "predictions = pd.read_csv(r'C:\\Users\\maorb\\Classes\\Classical_ML\\YDATA-kaggle-assignment\\predictions\\predictions.csv')\n",
    "X_train_fold_0 = pd.read_pickle(r\"C:\\Users\\maorb\\Classes\\Classical_ML\\YDATA-kaggle-assignment\\data\\processed\\X_train_fold_0.pkl\")\n",
    "y_val_fold_3 = pd.read_pickle(r\"C:\\Users\\maorb\\Classes\\Classical_ML\\YDATA-kaggle-assignment\\data\\processed\\y_val_fold_3.pkl\")\n",
    "X_test_1st = pd.read_pickle(r\"C:\\Users\\maorb\\Classes\\Classical_ML\\YDATA-kaggle-assignment\\data\\processed\\X_test_DoNotTouch.pkl\")\n",
    "predictions_1st = pd.read_csv(r'C:\\Users\\maorb\\Classes\\Classical_ML\\YDATA-kaggle-assignment\\data\\Predictions\\predictionscatboost.csv',\n",
    "                                header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>campaign_id</th>\n",
       "      <th>webpage_id</th>\n",
       "      <th>user_group_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age_level</th>\n",
       "      <th>user_depth</th>\n",
       "      <th>city_development_index</th>\n",
       "      <th>var_1</th>\n",
       "      <th>product_category</th>\n",
       "      <th>user_id_ctr</th>\n",
       "      <th>product_ctr</th>\n",
       "      <th>campaign_id_ctr</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "      <th>weekday</th>\n",
       "      <th>campaign_duration_hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>292288</th>\n",
       "      <td>C</td>\n",
       "      <td>360936</td>\n",
       "      <td>13787</td>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.037261</td>\n",
       "      <td>0.069039</td>\n",
       "      <td>0.045040</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18031</th>\n",
       "      <td>H</td>\n",
       "      <td>359520</td>\n",
       "      <td>13787</td>\n",
       "      <td>3</td>\n",
       "      <td>Male</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.104797</td>\n",
       "      <td>0.069920</td>\n",
       "      <td>0.059076</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>91.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202102</th>\n",
       "      <td>A</td>\n",
       "      <td>105960</td>\n",
       "      <td>11085</td>\n",
       "      <td>10</td>\n",
       "      <td>Female</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.061523</td>\n",
       "      <td>0.063782</td>\n",
       "      <td>0.068523</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>109.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227832</th>\n",
       "      <td>C</td>\n",
       "      <td>359520</td>\n",
       "      <td>13787</td>\n",
       "      <td>3</td>\n",
       "      <td>Male</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.024170</td>\n",
       "      <td>0.069039</td>\n",
       "      <td>0.059076</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10866</th>\n",
       "      <td>I</td>\n",
       "      <td>118601</td>\n",
       "      <td>28529</td>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.052058</td>\n",
       "      <td>0.063976</td>\n",
       "      <td>0.053211</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>57.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325041</th>\n",
       "      <td>H</td>\n",
       "      <td>82320</td>\n",
       "      <td>1734</td>\n",
       "      <td>5</td>\n",
       "      <td>Male</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.028198</td>\n",
       "      <td>0.069920</td>\n",
       "      <td>0.062465</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363708</th>\n",
       "      <td>I</td>\n",
       "      <td>118601</td>\n",
       "      <td>28529</td>\n",
       "      <td>2</td>\n",
       "      <td>Male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.030761</td>\n",
       "      <td>0.063976</td>\n",
       "      <td>0.053211</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>53.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5006</th>\n",
       "      <td>C</td>\n",
       "      <td>360936</td>\n",
       "      <td>13787</td>\n",
       "      <td>3</td>\n",
       "      <td>Male</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.061523</td>\n",
       "      <td>0.069039</td>\n",
       "      <td>0.045040</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.383333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255918</th>\n",
       "      <td>H</td>\n",
       "      <td>105960</td>\n",
       "      <td>11085</td>\n",
       "      <td>4</td>\n",
       "      <td>Male</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.088250</td>\n",
       "      <td>0.069920</td>\n",
       "      <td>0.068523</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>61.383333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31958</th>\n",
       "      <td>C</td>\n",
       "      <td>405490</td>\n",
       "      <td>60305</td>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.056396</td>\n",
       "      <td>0.069039</td>\n",
       "      <td>0.091419</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.350000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73070 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       product campaign_id webpage_id user_group_id  gender  age_level  \\\n",
       "292288       C      360936      13787             2    Male        2.0   \n",
       "18031        H      359520      13787             3    Male        3.0   \n",
       "202102       A      105960      11085            10  Female        4.0   \n",
       "227832       C      359520      13787             3    Male        3.0   \n",
       "10866        I      118601      28529             2    Male        2.0   \n",
       "...        ...         ...        ...           ...     ...        ...   \n",
       "325041       H       82320       1734             5    Male        5.0   \n",
       "363708       I      118601      28529             2    Male        2.0   \n",
       "5006         C      360936      13787             3    Male        3.0   \n",
       "255918       H      105960      11085             4    Male        4.0   \n",
       "31958        C      405490      60305             1    Male        1.0   \n",
       "\n",
       "        user_depth  city_development_index  var_1 product_category  \\\n",
       "292288         3.0                     2.0    1.0                3   \n",
       "18031          3.0                     3.0    0.0                4   \n",
       "202102         3.0                     1.0    1.0                2   \n",
       "227832         3.0                     3.0    1.0                4   \n",
       "10866          3.0                     2.0    0.0                4   \n",
       "...            ...                     ...    ...              ...   \n",
       "325041         3.0                     2.0    0.0                1   \n",
       "363708         3.0                     2.0    0.0                4   \n",
       "5006           3.0                     2.0    1.0                3   \n",
       "255918         3.0                     2.0    1.0                5   \n",
       "31958          3.0                     2.0    0.0                3   \n",
       "\n",
       "        user_id_ctr  product_ctr  campaign_id_ctr  Day  Hour  Minute  weekday  \\\n",
       "292288     0.037261     0.069039         0.045040  5.0  11.0    56.0      2.0   \n",
       "18031      0.104797     0.069920         0.059076  5.0  14.0    53.0      2.0   \n",
       "202102     0.061523     0.063782         0.068523  6.0  13.0    38.0      3.0   \n",
       "227832     0.024170     0.069039         0.059076  4.0  16.0    40.0      1.0   \n",
       "10866      0.052058     0.063976         0.053211  5.0   6.0    23.0      2.0   \n",
       "...             ...          ...              ...  ...   ...     ...      ...   \n",
       "325041     0.028198     0.069920         0.062465  2.0  10.0    11.0      1.0   \n",
       "363708     0.030761     0.063976         0.053211  2.0  15.0    26.0      3.0   \n",
       "5006       0.061523     0.069039         0.045040  2.0  18.0    24.0      6.0   \n",
       "255918     0.088250     0.069920         0.068523  4.0   6.0    48.0      1.0   \n",
       "31958      0.056396     0.069039         0.091419  2.0   9.0    12.0      6.0   \n",
       "\n",
       "        campaign_duration_hours  \n",
       "292288                19.166667  \n",
       "18031                 91.533333  \n",
       "202102               109.633333  \n",
       "227832                62.900000  \n",
       "10866                 57.300000  \n",
       "...                         ...  \n",
       "325041                 9.733333  \n",
       "363708                53.083333  \n",
       "5006                  18.383333  \n",
       "255918                61.383333  \n",
       "31958                  9.350000  \n",
       "\n",
       "[73070 rows x 18 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(r\"C:\\Users\\maorb\\Classes\\Classical_ML\\YDATA-kaggle-assignment\\data\\raw\\train_dataset_full.csv\")\n",
    "raw_test = pd.read_csv(r\"C:\\Users\\maorb\\Classes\\Classical_ML\\YDATA-kaggle-assignment\\data\\raw\\X_test_1st.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 74.48% of the test users are also in train\n",
      "✅ 100.00% of the test campaigns are also in train\n",
      "✅ 100.00% of the test products are also in train\n",
      "✅ 100.00% of the test webpage are also in train\n",
      "✅ 87.50% of the test age_level are also in train\n",
      "✅ 85.71% of the test user_group_id are also in train\n",
      "✅ 100.00% of the test product_category_1 are also in train\n",
      "✅ 66.67% of the test user_depth are also in train\n"
     ]
    }
   ],
   "source": [
    "users_train = set(raw_data['user_id'].unique())\n",
    "users_test = set(raw_test['user_id'].unique())\n",
    "campaigns_train = set(raw_data['campaign_id'].unique())\n",
    "campaigns_test = set(raw_test['campaign_id'].unique())\n",
    "products_train = set(raw_data['product'].unique())\n",
    "products_test = set(raw_test['product'].unique())\n",
    "webpage_train = set(raw_data['webpage_id'].unique())\n",
    "webpage_test = set(raw_test['webpage_id'].unique())\n",
    "age_level_train = set(raw_data['age_level'].unique())\n",
    "age_level_test = set(raw_test['age_level'].unique())\n",
    "user_group_id_train = set(raw_data['user_group_id'].unique())\n",
    "user_group_id_test = set(raw_test['user_group_id'].unique())\n",
    "product_category_1_train = set(raw_data['product_category_1'].unique())\n",
    "product_category_1_test = set(raw_test['product_category_1'].unique())\n",
    "user_depth_train = set(raw_data['user_depth'].unique())\n",
    "user_depth_test = set(raw_test['user_depth'].unique())\n",
    "\n",
    "\n",
    "\n",
    "# Count how many test users are also in train\n",
    "common_users = users_test.intersection(users_train)\n",
    "common_campaigns = campaigns_test.intersection(campaigns_train)\n",
    "common_products = products_test.intersection(products_train)\n",
    "common_webpage = webpage_test.intersection(webpage_train)\n",
    "common_age_level = age_level_test.intersection(age_level_train)\n",
    "common_user_group_id = user_group_id_test.intersection(user_group_id_train)\n",
    "common_product_category_1 = product_category_1_test.intersection(product_category_1_train)\n",
    "common_user_depth = user_depth_test.intersection(user_depth_train)\n",
    "\n",
    "\n",
    "# Compute the percentage\n",
    "percentage_users_in_train = len(common_users) / len(users_test) * 100\n",
    "percentage_campaigns_in_train = len(common_campaigns) / len(campaigns_test) * 100\n",
    "percentage_products_in_train = len(common_products) / len(products_test) * 100\n",
    "percentage_webpage_in_train = len(common_webpage) / len(webpage_test) * 100\n",
    "percentage_age_level_in_train = len(common_age_level) / len(age_level_test) * 100\n",
    "percentage_user_group_id_in_train = len(common_user_group_id) / len(user_group_id_test) * 100\n",
    "percentage_product_category_1_in_train = len(common_product_category_1) / len(product_category_1_test) * 100\n",
    "percentage_user_depth_in_train = len(common_user_depth) / len(user_depth_test) * 100\n",
    "\n",
    "\n",
    "print(f\"✅ {percentage_users_in_train:.2f}% of the test users are also in train\")\n",
    "print(f\"✅ {percentage_campaigns_in_train:.2f}% of the test campaigns are also in train\")\n",
    "print(f\"✅ {percentage_products_in_train:.2f}% of the test products are also in train\")\n",
    "print(f\"✅ {percentage_webpage_in_train:.2f}% of the test webpage are also in train\")\n",
    "print(f\"✅ {percentage_age_level_in_train:.2f}% of the test age_level are also in train\")\n",
    "print(f\"✅ {percentage_user_group_id_in_train:.2f}% of the test user_group_id are also in train\")\n",
    "print(f\"✅ {percentage_product_category_1_in_train:.2f}% of the test product_category_1 are also in train\")\n",
    "print(f\"✅ {percentage_user_depth_in_train:.2f}% of the test user_depth are also in train\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>user_id</th>\n",
       "      <th>product</th>\n",
       "      <th>campaign_id</th>\n",
       "      <th>webpage_id</th>\n",
       "      <th>user_group_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age_level</th>\n",
       "      <th>user_depth</th>\n",
       "      <th>city_development_index</th>\n",
       "      <th>var_1</th>\n",
       "      <th>is_click</th>\n",
       "      <th>product_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>171888</th>\n",
       "      <td>500379.0</td>\n",
       "      <td>2017-07-03 06:52:00</td>\n",
       "      <td>980231.0</td>\n",
       "      <td>H</td>\n",
       "      <td>405490</td>\n",
       "      <td>60305</td>\n",
       "      <td>5</td>\n",
       "      <td>Male</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200018</th>\n",
       "      <td>95832.0</td>\n",
       "      <td>2017-07-07 19:40:00</td>\n",
       "      <td>980231.0</td>\n",
       "      <td>C</td>\n",
       "      <td>405490</td>\n",
       "      <td>60305</td>\n",
       "      <td>5</td>\n",
       "      <td>Male</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        session_id            DateTime   user_id product campaign_id  \\\n",
       "171888    500379.0 2017-07-03 06:52:00  980231.0       H      405490   \n",
       "200018     95832.0 2017-07-07 19:40:00  980231.0       C      405490   \n",
       "\n",
       "       webpage_id user_group_id gender  age_level  user_depth  \\\n",
       "171888      60305             5   Male        5.0         3.0   \n",
       "200018      60305             5   Male        5.0         3.0   \n",
       "\n",
       "        city_development_index  var_1  is_click product_category  \n",
       "171888                     NaN    0.0       0.0                3  \n",
       "200018                     NaN    0.0       0.0                3  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_users = [7716.0, 1035283.0, 65994.0,75976.0,987498.0]\n",
    "cleaned_data[cleaned_data['user_id'] == 980231]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>user_id</th>\n",
       "      <th>product</th>\n",
       "      <th>campaign_id</th>\n",
       "      <th>webpage_id</th>\n",
       "      <th>product_category_1</th>\n",
       "      <th>product_category_2</th>\n",
       "      <th>user_group_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age_level</th>\n",
       "      <th>user_depth</th>\n",
       "      <th>city_development_index</th>\n",
       "      <th>var_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121580</td>\n",
       "      <td>2017-07-03 10:03</td>\n",
       "      <td>352186</td>\n",
       "      <td>H</td>\n",
       "      <td>82320</td>\n",
       "      <td>1734</td>\n",
       "      <td>1</td>\n",
       "      <td>146115.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95831</td>\n",
       "      <td>2017-07-03 14:21</td>\n",
       "      <td>980231</td>\n",
       "      <td>C</td>\n",
       "      <td>405490</td>\n",
       "      <td>60305</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>421806</td>\n",
       "      <td>2017-07-05 17:47</td>\n",
       "      <td>610332</td>\n",
       "      <td>D</td>\n",
       "      <td>404347</td>\n",
       "      <td>53587</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>585403</td>\n",
       "      <td>2017-07-06 11:01</td>\n",
       "      <td>849506</td>\n",
       "      <td>H</td>\n",
       "      <td>118601</td>\n",
       "      <td>28529</td>\n",
       "      <td>5</td>\n",
       "      <td>82527.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>496398</td>\n",
       "      <td>2017-07-02 07:50</td>\n",
       "      <td>499495</td>\n",
       "      <td>B</td>\n",
       "      <td>98970</td>\n",
       "      <td>6970</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>340792</td>\n",
       "      <td>2017-07-06 12:05</td>\n",
       "      <td>1138735</td>\n",
       "      <td>H</td>\n",
       "      <td>359520</td>\n",
       "      <td>13787</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>75278</td>\n",
       "      <td>2017-07-07 09:10</td>\n",
       "      <td>470151</td>\n",
       "      <td>C</td>\n",
       "      <td>405490</td>\n",
       "      <td>60305</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>31980</td>\n",
       "      <td>2017-07-05 16:56</td>\n",
       "      <td>538480</td>\n",
       "      <td>E</td>\n",
       "      <td>82320</td>\n",
       "      <td>1734</td>\n",
       "      <td>1</td>\n",
       "      <td>146115.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>54082</td>\n",
       "      <td>2017-07-02 15:06</td>\n",
       "      <td>345136</td>\n",
       "      <td>C</td>\n",
       "      <td>405490</td>\n",
       "      <td>60305</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>236163</td>\n",
       "      <td>2017-07-07 08:28</td>\n",
       "      <td>487171</td>\n",
       "      <td>I</td>\n",
       "      <td>118601</td>\n",
       "      <td>28529</td>\n",
       "      <td>4</td>\n",
       "      <td>82527.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   session_id          DateTime  user_id product  campaign_id  webpage_id  \\\n",
       "0      121580  2017-07-03 10:03   352186       H        82320        1734   \n",
       "1       95831  2017-07-03 14:21   980231       C       405490       60305   \n",
       "2      421806  2017-07-05 17:47   610332       D       404347       53587   \n",
       "3      585403  2017-07-06 11:01   849506       H       118601       28529   \n",
       "4      496398  2017-07-02 07:50   499495       B        98970        6970   \n",
       "5      340792  2017-07-06 12:05  1138735       H       359520       13787   \n",
       "6       75278  2017-07-07 09:10   470151       C       405490       60305   \n",
       "7       31980  2017-07-05 16:56   538480       E        82320        1734   \n",
       "8       54082  2017-07-02 15:06   345136       C       405490       60305   \n",
       "9      236163  2017-07-07 08:28   487171       I       118601       28529   \n",
       "\n",
       "   product_category_1  product_category_2  user_group_id  gender  age_level  \\\n",
       "0                   1            146115.0            2.0    Male        1.0   \n",
       "1                   3                 NaN            6.0    Male        5.0   \n",
       "2                   1                 NaN            3.0    Male        2.0   \n",
       "3                   5             82527.0            3.0    Male        2.0   \n",
       "4                   2                 NaN            9.0  Female        2.0   \n",
       "5                   4                 NaN            3.0    Male        2.0   \n",
       "6                   3                 NaN            4.0    Male        3.0   \n",
       "7                   1            146115.0            3.0    Male        2.0   \n",
       "8                   3                 NaN            2.0    Male        1.0   \n",
       "9                   4             82527.0            4.0    Male        3.0   \n",
       "\n",
       "   user_depth  city_development_index  var_1  \n",
       "0         3.0                     4.0      1  \n",
       "1         3.0                     NaN      0  \n",
       "2         3.0                     1.0      0  \n",
       "3         3.0                     3.0      0  \n",
       "4         3.0                     4.0      1  \n",
       "5         3.0                     4.0      0  \n",
       "6         3.0                     2.0      0  \n",
       "7         3.0                     3.0      1  \n",
       "8         3.0                     NaN      0  \n",
       "9         3.0                     2.0      0  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean rows per user in train: 2.88\n",
      "Mean rows per user in test: 1.45\n"
     ]
    }
   ],
   "source": [
    "#mean rows of users in train\n",
    "mean_rows_per_user_train = raw_data.groupby('user_id').size().mean()\n",
    "mean_rows_per_user_test = raw_test.groupby('user_id').size().mean()\n",
    "print(f\"Mean rows per user in train: {mean_rows_per_user_train:.2f}\")\n",
    "print(f\"Mean rows per user in test: {mean_rows_per_user_test:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "users_train = raw_data['user_id'].unique()\n",
    "users_test = raw_test['user_id'].unique()\n",
    "#Check if the users in the test set are a subset of the users in the train set\n",
    "print(np.all(np.isin(users_test, users_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>user_id</th>\n",
       "      <th>product</th>\n",
       "      <th>campaign_id</th>\n",
       "      <th>webpage_id</th>\n",
       "      <th>product_category_1</th>\n",
       "      <th>product_category_2</th>\n",
       "      <th>user_group_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age_level</th>\n",
       "      <th>user_depth</th>\n",
       "      <th>city_development_index</th>\n",
       "      <th>var_1</th>\n",
       "      <th>is_click</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>98528.0</td>\n",
       "      <td>2017-07-04 16:42</td>\n",
       "      <td>7716.0</td>\n",
       "      <td>C</td>\n",
       "      <td>405490.0</td>\n",
       "      <td>60305.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>589714.0</td>\n",
       "      <td>2017-07-07 07:40</td>\n",
       "      <td>1035283.0</td>\n",
       "      <td>I</td>\n",
       "      <td>118601.0</td>\n",
       "      <td>28529.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>82527.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>478652.0</td>\n",
       "      <td>2017-07-07 20:42</td>\n",
       "      <td>65994.0</td>\n",
       "      <td>H</td>\n",
       "      <td>359520.0</td>\n",
       "      <td>13787.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34536.0</td>\n",
       "      <td>2017-07-05 15:05</td>\n",
       "      <td>75976.0</td>\n",
       "      <td>H</td>\n",
       "      <td>405490.0</td>\n",
       "      <td>60305.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>71863.0</td>\n",
       "      <td>2017-07-06 20:11</td>\n",
       "      <td>987498.0</td>\n",
       "      <td>C</td>\n",
       "      <td>405490.0</td>\n",
       "      <td>60305.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   session_id          DateTime    user_id product  campaign_id  webpage_id  \\\n",
       "0     98528.0  2017-07-04 16:42     7716.0       C     405490.0     60305.0   \n",
       "1    589714.0  2017-07-07 07:40  1035283.0       I     118601.0     28529.0   \n",
       "2    478652.0  2017-07-07 20:42    65994.0       H     359520.0     13787.0   \n",
       "3     34536.0  2017-07-05 15:05    75976.0       H     405490.0     60305.0   \n",
       "4     71863.0  2017-07-06 20:11   987498.0       C     405490.0     60305.0   \n",
       "\n",
       "   product_category_1  product_category_2  user_group_id  gender  age_level  \\\n",
       "0                 3.0                 NaN            3.0    Male        3.0   \n",
       "1                 4.0             82527.0           10.0  Female        4.0   \n",
       "2                 4.0                 NaN            4.0    Male        4.0   \n",
       "3                 3.0                 NaN            3.0    Male        3.0   \n",
       "4                 3.0                 NaN            2.0    Male        2.0   \n",
       "\n",
       "   user_depth  city_development_index  var_1  is_click  \n",
       "0         3.0                     NaN    1.0       1.0  \n",
       "1         3.0                     3.0    1.0       0.0  \n",
       "2         3.0                     2.0    0.0       0.0  \n",
       "3         3.0                     3.0    0.0       0.0  \n",
       "4         3.0                     2.0    0.0       0.0  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60223</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60224</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60225</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60226</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60227</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60228 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0\n",
       "0      0.0\n",
       "1      1.0\n",
       "2      1.0\n",
       "3      0.0\n",
       "4      0.0\n",
       "...    ...\n",
       "60223  1.0\n",
       "60224  0.0\n",
       "60225  0.0\n",
       "60226  0.0\n",
       "60227  0.0\n",
       "\n",
       "[60228 rows x 1 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First value should be the header. Strip header and make it first values in first row\n",
    "predictions_1st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9319820664496002"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_fold_3.value_counts()[0]/y_val_fold_3.value_counts().sum()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "session_id                  4166\n",
       "DateTime                    4109\n",
       "user_id                     4108\n",
       "product                     4174\n",
       "campaign_id                 4188\n",
       "webpage_id                  4157\n",
       "product_category_1          4201\n",
       "product_category_2        308235\n",
       "user_group_id              19319\n",
       "gender                     19324\n",
       "age_level                  19309\n",
       "user_depth                 19322\n",
       "city_development_index    108137\n",
       "var_1                       4161\n",
       "is_click                    4132\n",
       "dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in 'campaign_duration_days' within each campaign_id group using the mode\n",
    "X_train['age_level'] = X_train.groupby('user_id', observed=True)['campaign_duration_hours'].transform(\n",
    "    lambda x: x.ffill().bfill() if not x.mode().empty else x.fillna(0)\n",
    ")\n",
    "\n",
    "X_test['campaign_duration_hours'] = X_test.groupby('webpage_id', observed=True)['campaign_duration_hours'].transform(\n",
    "    lambda x: x.ffill().bfill() if not x.mode().empty else x.fillna(0)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product                    0\n",
       "campaign_id                0\n",
       "webpage_id                 0\n",
       "user_group_id              0\n",
       "gender                     0\n",
       "age_level                  0\n",
       "user_depth                 0\n",
       "city_development_index     0\n",
       "var_1                      0\n",
       "product_category           0\n",
       "Day                        0\n",
       "Hour                       0\n",
       "Minute                     0\n",
       "weekday                    0\n",
       "campaign_duration_hours    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = X_train.select_dtypes(include=['category', 'object']).columns\n",
    "X_train2 = X_train.copy()\n",
    "\n",
    "for col in categorical_cols:\n",
    "    mode_value = X_train2.loc[X_train2[col] != \"missing\", col].mode()[0]\n",
    "    mask = X_train2[col] == \"missing\"\n",
    "    X_train2.loc[mask, col] = mode_value\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test2 = X_test.copy()\n",
    "\n",
    "for col in categorical_cols:\n",
    "    mode_value = X_test2.loc[X_test2[col] != \"missing\", col].mode()[0]\n",
    "    mask = X_test2[col] == \"missing\"\n",
    "    X_test2.loc[mask, col] = mode_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((293307, 14),\n",
       " (73327, 14),\n",
       " (293307,),\n",
       " (73327,),\n",
       " (73160, 1),\n",
       " (365798, 14),\n",
       " (389163, 15))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape, predictions.shape, cleaned_data.shape, raw_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product                        0\n",
       "campaign_id                    0\n",
       "webpage_id                     0\n",
       "gender                         0\n",
       "age_level                  11626\n",
       "user_depth                 11630\n",
       "city_development_index     79202\n",
       "var_1                         94\n",
       "product_category               0\n",
       "Day                            0\n",
       "Hour                           0\n",
       "Minute                         0\n",
       "weekday                        0\n",
       "campaign_duration_hours        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((292638, 13),\n",
       " (73160, 13),\n",
       " (292638,),\n",
       " (73160,),\n",
       " (73160, 1),\n",
       " (365798, 14),\n",
       " (389163, 15))"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape, predictions.shape, cleaned_data.shape, raw_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19510, 15)"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find how many duplicated rows we have\n",
    "duplicates = raw_data[raw_data.duplicated()]\n",
    "duplicates.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Month\n",
      "Day\n",
      "Hour\n",
      "Minute\n",
      "weekday\n",
      "product\n",
      "campaign_id\n",
      "webpage_id\n",
      "gender\n",
      "age_level\n",
      "user_depth\n",
      "city_development_index\n",
      "var_1\n",
      "product_category\n",
      "Month\n",
      "Day\n",
      "Hour\n",
      "Minute\n",
      "weekday\n",
      "product\n",
      "campaign_id\n",
      "webpage_id\n",
      "gender\n",
      "age_level\n",
      "user_depth\n",
      "city_development_index\n",
      "var_1\n",
      "product_category\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def feature_generation(df):\n",
    "    \"\"\"Generate date/time features and fill missing values in a faster, \n",
    "       more scalable way without repeated group-based ffill/bfill.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # If not already a datetime, convert:\n",
    "    # df['DateTime'] = pd.to_datetime(df['DateTime'])\n",
    "    \n",
    "    # -- 1) Create date/time features --\n",
    "    df['Month'] = df['DateTime'].dt.month\n",
    "    df['Day'] = df['DateTime'].dt.day\n",
    "    df['Hour'] = df['DateTime'].dt.hour\n",
    "    df['Minute'] = df['DateTime'].dt.minute\n",
    "    df['weekday'] = df['DateTime'].dt.weekday\n",
    "    \n",
    "    # -- 2) Drop unnecessary columns --\n",
    "    df.drop(columns=['DateTime', 'session_id'], inplace=True, errors='ignore')\n",
    "    \n",
    "    # -- 3) Make user_id a consistent type --\n",
    "    # (Strings are often safer keys for merges.)\n",
    "    df['user_id'] = df['user_id'].astype(str)\n",
    "    \n",
    "    # -- 4) Identify columns to fill by median vs. mode --\n",
    "    #    (You can tune these lists as needed.)\n",
    "    columns_to_fill_median = ['Month', 'Day', 'Hour', 'Minute', 'weekday']\n",
    "    columns_to_fill_mode = [\n",
    "        'product', 'campaign_id', 'webpage_id', 'gender', \n",
    "        'age_level', 'user_depth', 'city_development_index', \n",
    "        'var_1', 'product_category'\n",
    "    ]\n",
    "    \n",
    "    # Keep only columns that actually exist in df\n",
    "    columns_to_fill_median = [c for c in columns_to_fill_median if c in df.columns]\n",
    "    columns_to_fill_mode = [c for c in columns_to_fill_mode if c in df.columns]\n",
    "    \n",
    "    # -- 5) Precompute the user-level medians/modes in one pass each --\n",
    "    if columns_to_fill_median:\n",
    "        median_df = (\n",
    "            df.groupby('user_id')[columns_to_fill_median]\n",
    "            .median()\n",
    "            .reset_index()\n",
    "        )\n",
    "    \n",
    "    # Mode can be tricky (pandas mode can return multiple values).\n",
    "    # We'll define a custom aggregator that picks the first mode if multiple modes exist.\n",
    "    def agg_mode(s):\n",
    "        m = s.mode(dropna=True)\n",
    "        return m.iloc[0] if len(m) > 0 else np.nan\n",
    "        \n",
    "    if columns_to_fill_mode:\n",
    "        mode_df = (\n",
    "            df.groupby('user_id')[columns_to_fill_mode]\n",
    "            .agg(agg_mode)\n",
    "            .reset_index()\n",
    "        )\n",
    "        \n",
    "    # -- 6) Merge those statistics back to df --\n",
    "    # This is usually much more performant than repeated group transforms:\n",
    "    if columns_to_fill_median:\n",
    "        df = df.merge(\n",
    "            median_df, \n",
    "            on='user_id', \n",
    "            suffixes=('', '_median')\n",
    "        )\n",
    "    if columns_to_fill_mode:\n",
    "        df = df.merge(\n",
    "            mode_df, \n",
    "            on='user_id', \n",
    "            suffixes=('', '_mode')\n",
    "        )\n",
    "        \n",
    "    # -- 7) Fill missing values in df using the merged median/mode --\n",
    "    if columns_to_fill_median:\n",
    "        for col in columns_to_fill_median:\n",
    "            df[col] = df[col].fillna(df[f'{col}_median'])\n",
    "            df.drop(columns=[f'{col}_median'], inplace=True, errors='ignore')\n",
    "            \n",
    "    if columns_to_fill_mode:\n",
    "        for col in columns_to_fill_mode:\n",
    "            df[col] = df[col].fillna(df[f'{col}_mode'])\n",
    "            df.drop(columns=[f'{col}_mode'], inplace=True, errors='ignore')\n",
    "    \n",
    "    for col in columns_to_fill_median:\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "\n",
    "    for col in columns_to_fill_mode:\n",
    "        df[col] = df[col].fillna(df[col].mode()[0])\n",
    "    \n",
    "    df.drop(columns=['user_id','user_group_id'], inplace=True, errors='ignore')\n",
    "            \n",
    "    return df\n",
    "\n",
    "# Example usage:\n",
    "X_train_u = feature_generation(X_train)\n",
    "X_test_u  = feature_generation(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_with_mode(df: pd.DataFrame, columns: list):\n",
    "    df = df.copy()\n",
    "    for column in columns:\n",
    "        if column in df.columns:\n",
    "            mode_value = df[column].mode()[0]  # Calculate the mode\n",
    "            df[column] = df[column].fillna(mode_value)  # Fill missing values with the mode\n",
    "    return df\n",
    "\n",
    "def fill_missing_with_median(df: pd.DataFrame, columns: list):\n",
    "    df = df.copy()\n",
    "    for column in columns:\n",
    "        if column in df.columns:\n",
    "            median_value = df[column].median()  # Calculate the median\n",
    "            df[column] = df[column].fillna(median_value)  # Fill missing values with the median\n",
    "    return df   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['session_id', 'DateTime', 'user_id', 'product', 'campaign_id',\n",
       "       'webpage_id', 'user_group_id', 'gender', 'age_level', 'user_depth',\n",
       "       'city_development_index', 'var_1', 'product_category'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_with_mode(df: pd.DataFrame, columns: list):\n",
    "    df = df.copy()\n",
    "    for column in columns:\n",
    "        if column in df.columns:\n",
    "            mode_value = df[column].mode()[0]  # Calculate the mode\n",
    "            df[column] = df[column].fillna(mode_value)  # Fill missing values with the mode\n",
    "    return df\n",
    "\n",
    "def fill_missing_with_median(df: pd.DataFrame, columns: list):\n",
    "    df = df.copy()\n",
    "    for column in columns:\n",
    "        if column in df.columns:\n",
    "            median_value = df[column].median()  # Calculate the median\n",
    "            df[column] = df[column].fillna(median_value)  # Fill missing values with the median\n",
    "    return df\n",
    "\n",
    "def determine_categorical_features(df: pd.DataFrame, cat_features: list = None):\n",
    "\n",
    "    if cat_features:\n",
    "        cat_features = [col for col in cat_features if col in df.columns]\n",
    "    else:\n",
    "        cat_features = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "    for col in cat_features:\n",
    "        if col in df.columns:\n",
    "            # Ensure column is treated as category\n",
    "            df[col] = df[col].astype(\"category\")\n",
    "\n",
    "            # Add \"missing\" only if it's not already a category\n",
    "            if \"missing\" not in df[col].cat.categories:\n",
    "                df[col] = df[col].cat.add_categories(\"missing\")\n",
    "\n",
    "            # Fill missing values with \"missing\"\n",
    "            df[col] = df[col].fillna(\"missing\")\n",
    "\n",
    "    return cat_features\n",
    "\n",
    "def feature_generation2(df, use_missing_with_mode=False, get_dumm=False, catb=True, cat_features=None):\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    # Generate time-based features\n",
    "    df['Month'] = df['DateTime'].dt.month\n",
    "    df['Day'] = df['DateTime'].dt.day\n",
    "    df['Hour'] = df['DateTime'].dt.hour\n",
    "    df['Minute'] = df['DateTime'].dt.minute\n",
    "    df['weekday'] = df['DateTime'].dt.weekday\n",
    "\n",
    "    # Handle categorical features if `catb` is True\n",
    "    if catb:\n",
    "        cat_features = determine_categorical_features(df, cat_features)\n",
    "\n",
    "    # Fill missing values\n",
    "    if use_missing_with_mode:\n",
    "        print(\"Filling missing values with mode\")\n",
    "        columns_to_fill_mode = [\"product\", \"campaign_id\", \"webpage_id\", \"user_group_id\", \"gender\", \"age_level\", \"user_depth\", \"city_development_index\", \"var_1\", \"product_category\",\n",
    "                                \"Month\", \"Day\", \"Hour\"]\n",
    "        df = fill_missing_with_mode(df, columns_to_fill_mode)\n",
    "\n",
    "    columns_to_fill_median = [\"Month\", \"Day\", \"Hour\", \"Minute\", \"weekday\", \"city_development_index\", \"age_level\", \"user_depth\"]\n",
    "    df['campaign_id'] = df['campaign_id'].fillna(df['campaign_id'].mode()[0]) #userid and sessionid have nas. What can we do else?\n",
    "    df['var_1'] = df['var_1'].fillna(df['var_1'].mode()[0])\n",
    "    df = fill_missing_with_median(df, columns_to_fill_median)\n",
    "\n",
    "    # Generate campaign-based features\n",
    "    df['start_date'] = df.groupby('campaign_id', observed=True)['DateTime'].transform('min')\n",
    "    df['campaign_duration'] = df['DateTime'] - df['start_date']\n",
    "    df['campaign_duration_days'] = df['campaign_duration'].dt.total_seconds() / (3600*24)\n",
    "    df['campaign_duration_days'] = df['campaign_duration_days'].fillna(\n",
    "        df.groupby('campaign_id', observed=True)['campaign_duration_days'].transform(lambda x: x.mode().iloc[0])).astype(int)\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    df.drop(columns=['DateTime', 'start_date', 'campaign_duration', 'session_id', 'user_id', 'user_group_id'], inplace=True)\n",
    "\n",
    "    # One-hot encoding if `get_dumm` is True\n",
    "    if get_dumm:\n",
    "        columns_to_d = [\"product\", \"campaign_id\", \"webpage_id\", \"product_category\", \"gender\"]\n",
    "        df = pd.get_dummies(df, columns=columns_to_d)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'DateTime'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\maorb\\anaconda3\\envs\\Yofi\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'DateTime'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_train2 \u001b[38;5;241m=\u001b[39m \u001b[43mfeature_generation2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m X_test2 \u001b[38;5;241m=\u001b[39m feature_generation2(X_test)\n\u001b[0;32m      3\u001b[0m cat_features \u001b[38;5;241m=\u001b[39m determine_categorical_features(X_train2)\n",
      "Cell \u001b[1;32mIn[25], line 43\u001b[0m, in \u001b[0;36mfeature_generation2\u001b[1;34m(df, use_missing_with_mode, get_dumm, catb, cat_features)\u001b[0m\n\u001b[0;32m     40\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Generate time-based features\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMonth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDateTime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mmonth\n\u001b[0;32m     44\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDay\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDateTime\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mday\n\u001b[0;32m     45\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHour\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDateTime\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mhour\n",
      "File \u001b[1;32mc:\\Users\\maorb\\anaconda3\\envs\\Yofi\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\maorb\\anaconda3\\envs\\Yofi\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'DateTime'"
     ]
    }
   ],
   "source": [
    "X_train2 = feature_generation2(X_train)\n",
    "X_test2 = feature_generation2(X_test)\n",
    "cat_features = determine_categorical_features(X_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_d = [\"product\", \"campaign_id\", \"webpage_id\", \"product_category\", \"gender\",\"user_group_id\"]\n",
    "X_train_d = pd.get_dummies(X_train2, columns=columns_to_d)\n",
    "X_test_d = pd.get_dummies(X_test2, columns=columns_to_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender\n",
       "Male       248397\n",
       "Female      32776\n",
       "missing     11465\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train2['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.040829346092503986"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42,class_weight='balanced')\n",
    "rf.fit(X_train_d, y_train)\n",
    "y_pred = rf.predict(X_test_d)\n",
    "\n",
    "f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.13929004519898577\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Compute sample weights\n",
    "sample_weights = compute_sample_weight(class_weight=\"balanced\", y=y_train)\n",
    "\n",
    "# Train AdaBoost with sample weights\n",
    "adamodel = AdaBoostClassifier(n_estimators=100, random_state=42, algorithm='SAMME')\n",
    "adamodel.fit(X_train_d, y_train, sample_weight=sample_weights)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = adamodel.predict(X_test_d)\n",
    "\n",
    "# Evaluate\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"F1 Score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Apply SMOTE to balance the training set\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train2, y_train)\n",
    "\n",
    "# Train Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred2 = rf.predict(X_test2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14371159806427056\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, classification_report\n",
    "#adjuct the balance of the classes\n",
    "model = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42, solver='liblinear',\n",
    "                           penalty='l2', C=1)\n",
    "model.fit(X_train_d, y_train)\n",
    "\n",
    "y_pred_LR = model.predict(X_test_d)\n",
    "print(f1_score(y_test, y_pred_LR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.14191397, 0.14630052, 0.14374937, 0.1396726 , 0.14359774])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "model = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42, solver='liblinear',\n",
    "                           penalty='l2', C=1)\n",
    "#run it on all\n",
    "scores = cross_val_score(model, X_train_d, y_train, cv=5, scoring='f1')\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14304684"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([0.14191397, 0.14630052, 0.14374937, 0.1396726 , 0.14359774])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complement Bayes:  [0.13291654 0.13741399 0.13816756 0.13567328 0.13666374]\n",
      "Gaussian Bayes:  [0.13584671 0.14390066 0.13671663 0.13889985 0.13384344]\n",
      "Multinomial Bayes:  [0.00100806 0.         0.         0.         0.        ]\n",
      "Bernoulli Bayes:  [0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "#import cross_val_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB, ComplementNB\n",
    "\n",
    "\n",
    "model1 = ComplementNB()\n",
    "model2 = GaussianNB()\n",
    "model3 = MultinomialNB()\n",
    "model4 = BernoulliNB()   \n",
    "print(\"Complement Bayes: \", cross_val_score(model1, X_train_d, y_train, cv=5, scoring='f1'))\n",
    "print(\"Gaussian Bayes: \", cross_val_score(model2, X_train_d, y_train, cv=5, scoring='f1'))\n",
    "print(\"Multinomial Bayes: \", cross_val_score(model3, X_train_d, y_train, cv=5, scoring='f1'))\n",
    "print(\"Bernoulli Bayes: \", cross_val_score(model4, X_train_d, y_train, cv=5, scoring='f1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complement Bayes: [0.13285236 0.13694722 0.13831141 0.13642458 0.13636068]\n",
      "Gaussian Bayes: [0.13413932 0.14055185 0.13428364 0.13605852 0.13060411]\n",
      "Multinomial Bayes: [0. 0. 0. 0. 0.]\n",
      "Bernoulli Bayes: [0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB, ComplementNB\n",
    "\n",
    "# Compute sample weights\n",
    "sample_weights = compute_sample_weight(class_weight=\"balanced\", y=y_train)\n",
    "\n",
    "# Define models without random_state\n",
    "model1 = ComplementNB()\n",
    "model2 = GaussianNB()\n",
    "model3 = MultinomialNB()\n",
    "model4 = BernoulliNB()\n",
    "\n",
    "# Fit models with sample weights\n",
    "model1.fit(X_train_d, y_train, sample_weight=sample_weights)\n",
    "model2.fit(X_train_d, y_train, sample_weight=sample_weights)\n",
    "model3.fit(X_train_d, y_train, sample_weight=sample_weights)\n",
    "model4.fit(X_train_d, y_train, sample_weight=sample_weights)\n",
    "\n",
    "# Cross-validation with sample weights\n",
    "print(\"Complement Bayes:\", cross_val_score(model1, X_train_d, y_train, cv=5, scoring='f1'))\n",
    "print(\"Gaussian Bayes:\", cross_val_score(model2, X_train_d, y_train, cv=5, scoring='f1'))\n",
    "print(\"Multinomial Bayes:\", cross_val_score(model3, X_train_d, y_train, cv=5, scoring='f1'))\n",
    "print(\"Bernoulli Bayes:\", cross_val_score(model4, X_train_d, y_train, cv=5, scoring='f1'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.14070554937834834\n"
     ]
    }
   ],
   "source": [
    "#import sgdclassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "model = SGDClassifier(random_state=42, loss='log_loss', class_weight='balanced')\n",
    "model.fit(X_train_d, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test_d)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f\"F1-score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score with RBF SGD: 0.12733747750277624\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.kernel_approximation import RBFSampler,Nystroem\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load CTR data (Assume df is the CTR dataset)\n",
    "\n",
    "\n",
    "# Define the full pipeline\n",
    "rbf_pipeline = Pipeline([\n",
    "    (\"rbf_feature_map\", Nystroem(gamma=1, n_components=300)),  # RBF feature map\n",
    "    (\"sgd\", SGDClassifier(random_state=42, loss='log_loss', class_weight='balanced'))  # SGD with log-loss\n",
    "])\n",
    "\n",
    "# Split the data\n",
    "\n",
    "\n",
    "# Train the model\n",
    "rbf_pipeline.fit(X_train_d, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_rbf = rbf_pipeline.predict(X_test_d)\n",
    "\n",
    "# Evaluate\n",
    "f1_rbf = f1_score(y_test, y_pred_rbf)\n",
    "print(f\"F1-score with RBF SGD: {f1_rbf}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Baseline? :()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9323260378678943"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data['is_click'].value_counts()[0]/cleaned_data['is_click'].value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1- cleaned_data['is_click'].value_counts()[0]/cleaned_data['is_click'].value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1 = X_train.drop(columns=['session_id', 'DateTime', 'user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Configure logger\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def objective(trial):\n",
    "    # Define hyperparameters to optimize\n",
    "    params = {\n",
    "        \"iterations\": 1000,\n",
    "        \"depth\": trial.suggest_int(\"depth\", 4, 8),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.1),\n",
    "        \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 1, 100),\n",
    "        \"grow_policy\": trial.suggest_categorical(\"grow_policy\", [\"SymmetricTree\", \"Depthwise\", \"Lossguide\"]),\n",
    "        \"bootstrap_type\": trial.suggest_categorical(\"bootstrap_type\", [\"Bayesian\", \"Bernoulli\"]),\n",
    "        \"class_weights\": [1, 1 / 0.06767396213210575],  # Fixed class weights\n",
    "        \"eval_metric\": \"F1\",\n",
    "        \"early_stopping_rounds\": 100,\n",
    "        \"random_seed\": 42,\n",
    "        \"verbose\": 0,\n",
    "    }\n",
    "\n",
    "    # Add bagging_temperature or subsample based on bootstrap_type\n",
    "    if params[\"bootstrap_type\"] == \"Bayesian\":\n",
    "        params[\"bagging_temperature\"] = trial.suggest_float(\"bagging_temperature\", 0.0, 1.0)\n",
    "    elif params[\"bootstrap_type\"] == \"Bernoulli\":\n",
    "        params[\"subsample\"] = trial.suggest_float(\"subsample\", 0.5, 1.0)\n",
    "\n",
    "    # Initialize the model\n",
    "    model = CatBoostClassifier(**params)\n",
    "\n",
    "    # Cross-validation\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scores = []\n",
    "\n",
    "    for fold_index, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train)):\n",
    "        # Create train-validation splits\n",
    "        X_train_cv, X_val_cv = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_train_cv, y_val_cv = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "        # Check if both classes are present in the training and validation sets\n",
    "        if len(np.unique(y_train_cv)) < 2 or len(np.unique(y_val_cv)) < 2:\n",
    "            logger.warning(f\"Fold {fold_index}: Skipping due to only one class in y_train_cv or y_val_cv\")\n",
    "            continue\n",
    "\n",
    "        # Train the model\n",
    "        model.fit(\n",
    "            X_train_cv,\n",
    "            y_train_cv,\n",
    "            cat_features=cat_features,\n",
    "            eval_set=(X_val_cv, y_val_cv),\n",
    "            early_stopping_rounds=50,\n",
    "            use_best_model=True\n",
    "        )\n",
    "\n",
    "        # Predict on the validation set\n",
    "        y_pred_val = model.predict(X_val_cv)\n",
    "\n",
    "        # Calculate F1 score\n",
    "        try:\n",
    "            score = f1_score(y_val_cv, y_pred_val)\n",
    "            scores.append(score)\n",
    "            logger.info(f\"Fold {fold_index}: F1 score = {score}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error calculating F1 score on fold {fold_index}: {e}\")\n",
    "            continue\n",
    "\n",
    "    # Return the average F1 score across folds\n",
    "    if scores:\n",
    "        return np.mean(scores)\n",
    "    else:\n",
    "        logger.warning(\"All folds were skipped. Returning 0.0.\")\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        \"iterations\": 1000,\n",
    "        \"depth\": trial.suggest_int(\"depth\", 3, 5),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.08, 0.15),\n",
    "        \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 15, 40),\n",
    "        \"random_strength\": trial.suggest_float(\"random_strength\", 0.1, 1.5),\n",
    "        #\"bagging_temperature\": trial.suggest_float(\"bagging_temperature\", 0.0, 1.0),\n",
    "        \"grow_policy\": trial.suggest_categorical(\"grow_policy\", [\"SymmetricTree\", \"Depthwise\"]),\n",
    "        \"bootstrap_type\": trial.suggest_categorical(\"bootstrap_type\", [\"Bayesian\", \"Bernoulli\", \"MVS\"]),\n",
    "        #\"class_weights\": [1, 1 / trial.suggest_float(\"class_weight_ratio\", 1.0, 10.0)],\n",
    "        \"eval_metric\": \"F1\",\n",
    "        \"class_weights\": [1, 1 / 0.06767396213210575],\n",
    "        \"early_stopping_rounds\": 100,\n",
    "        \"random_seed\": 42,\n",
    "        \"verbose\": 0,\n",
    "    }\n",
    "\n",
    "    if params[\"bootstrap_type\"] == \"Bayesian\":\n",
    "        params[\"bagging_temperature\"] = trial.suggest_float(\"bagging_temperature\", 0.1, 0.8)\n",
    "    if params['grow_policy'] == 'Depthwise':\n",
    "        params['min_data_in_leaf'] = trial.suggest_int(\"min_data_in_leaf\", 1, 10)\n",
    "    elif params[\"bootstrap_type\"] == \"Bernoulli\":\n",
    "        params[\"subsample\"] = trial.suggest_float(\"subsample\", 0.6, .9)\n",
    "\n",
    "    model = CatBoostClassifier(**params)\n",
    "\n",
    "    X_train_sub, X_val_sub, y_train_sub, y_val_sub = train_test_split(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=y_train\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train_sub,\n",
    "        y_train_sub,\n",
    "        cat_features=cat_features,\n",
    "        eval_set=(X_val_sub, y_val_sub),\n",
    "        early_stopping_rounds=50,\n",
    "        use_best_model=True\n",
    "    )\n",
    "\n",
    "    y_pred_val = model.predict(X_val_sub)\n",
    "    f1 = f1_score(y_val_sub, y_pred_val)\n",
    "    return f1\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-27 22:58:00,203] A new study created in memory with name: no-name-5758c482-6afb-4363-a73d-0de97e7ba98c\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d966c927af88443299cc94257bfe3aa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-01-27 22:58:12,512] Trial 0 finished with value: 0.1472231158424239 and parameters: {'depth': 3, 'learning_rate': 0.11179495588783098, 'l2_leaf_reg': 30.860280395620038, 'random_strength': 0.30182868854996703, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'MVS'}. Best is trial 0 with value: 0.1472231158424239.\n",
      "[I 2025-01-27 22:58:21,945] Trial 1 finished with value: 0.14491287240022485 and parameters: {'depth': 5, 'learning_rate': 0.13055535934283002, 'l2_leaf_reg': 21.524094448381117, 'random_strength': 1.015927175562968, 'grow_policy': 'Depthwise', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.1818611010446386, 'min_data_in_leaf': 7}. Best is trial 0 with value: 0.1472231158424239.\n",
      "[I 2025-01-27 22:58:31,078] Trial 2 finished with value: 0.14444444444444443 and parameters: {'depth': 4, 'learning_rate': 0.08194672112755871, 'l2_leaf_reg': 16.280719200709708, 'random_strength': 0.6647458591392498, 'grow_policy': 'Depthwise', 'bootstrap_type': 'MVS', 'min_data_in_leaf': 9}. Best is trial 0 with value: 0.1472231158424239.\n",
      "[I 2025-01-27 22:58:38,694] Trial 3 finished with value: 0.14359032846715328 and parameters: {'depth': 4, 'learning_rate': 0.11777725050650167, 'l2_leaf_reg': 27.57345230586553, 'random_strength': 0.20639375590497025, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'Bernoulli', 'subsample': 0.8686641033785144}. Best is trial 0 with value: 0.1472231158424239.\n",
      "[I 2025-01-27 22:58:47,077] Trial 4 finished with value: 0.14335189648962401 and parameters: {'depth': 5, 'learning_rate': 0.11767643869849281, 'l2_leaf_reg': 25.201191082784604, 'random_strength': 0.5710536146373626, 'grow_policy': 'Depthwise', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.6527600945638369, 'min_data_in_leaf': 4}. Best is trial 0 with value: 0.1472231158424239.\n",
      "[I 2025-01-27 22:58:58,943] Trial 5 finished with value: 0.14698455575782488 and parameters: {'depth': 4, 'learning_rate': 0.14354537700294157, 'l2_leaf_reg': 25.200609692790806, 'random_strength': 1.3793586901863284, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'MVS'}. Best is trial 0 with value: 0.1472231158424239.\n",
      "[I 2025-01-27 22:59:06,592] Trial 6 finished with value: 0.14534867444920355 and parameters: {'depth': 3, 'learning_rate': 0.12193470580462185, 'l2_leaf_reg': 35.701321013140976, 'random_strength': 0.15637135863533635, 'grow_policy': 'Depthwise', 'bootstrap_type': 'Bernoulli', 'min_data_in_leaf': 4}. Best is trial 0 with value: 0.1472231158424239.\n",
      "[I 2025-01-27 22:59:21,659] Trial 7 finished with value: 0.14663310258023915 and parameters: {'depth': 3, 'learning_rate': 0.14971050163640728, 'l2_leaf_reg': 26.936472761321735, 'random_strength': 1.192437145061087, 'grow_policy': 'Depthwise', 'bootstrap_type': 'MVS', 'min_data_in_leaf': 3}. Best is trial 0 with value: 0.1472231158424239.\n",
      "[I 2025-01-27 22:59:28,106] Trial 8 finished with value: 0.14434797860212226 and parameters: {'depth': 5, 'learning_rate': 0.13763575971506142, 'l2_leaf_reg': 26.0271113974352, 'random_strength': 1.1592131300992776, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'MVS'}. Best is trial 0 with value: 0.1472231158424239.\n",
      "[I 2025-01-27 22:59:36,777] Trial 9 finished with value: 0.14567619471735924 and parameters: {'depth': 5, 'learning_rate': 0.12247372175688659, 'l2_leaf_reg': 36.42549685367478, 'random_strength': 0.7109033109783542, 'grow_policy': 'Depthwise', 'bootstrap_type': 'MVS', 'min_data_in_leaf': 2}. Best is trial 0 with value: 0.1472231158424239.\n",
      "[I 2025-01-27 22:59:59,206] Trial 10 finished with value: 0.14683981652469172 and parameters: {'depth': 3, 'learning_rate': 0.09950753187486475, 'l2_leaf_reg': 32.530278798285536, 'random_strength': 0.42844970775585045, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.7841466129172147}. Best is trial 0 with value: 0.1472231158424239.\n",
      "[I 2025-01-27 23:00:20,206] Trial 11 finished with value: 0.14787705674075396 and parameters: {'depth': 4, 'learning_rate': 0.1024504424434467, 'l2_leaf_reg': 30.994066784973583, 'random_strength': 1.489607925058582, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'MVS'}. Best is trial 11 with value: 0.14787705674075396.\n",
      "[I 2025-01-27 23:00:38,904] Trial 12 finished with value: 0.14846048839678447 and parameters: {'depth': 3, 'learning_rate': 0.10064120011791873, 'l2_leaf_reg': 31.81460291957595, 'random_strength': 1.436388018074666, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'MVS'}. Best is trial 12 with value: 0.14846048839678447.\n",
      "[I 2025-01-27 23:00:48,555] Trial 13 finished with value: 0.1456371252859562 and parameters: {'depth': 4, 'learning_rate': 0.09825866978678253, 'l2_leaf_reg': 32.898034824425636, 'random_strength': 1.4996723499499514, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'MVS'}. Best is trial 12 with value: 0.14846048839678447.\n",
      "[I 2025-01-27 23:01:10,835] Trial 14 finished with value: 0.14826021180030258 and parameters: {'depth': 3, 'learning_rate': 0.10102284949490543, 'l2_leaf_reg': 37.92247227597721, 'random_strength': 0.950386473239303, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'MVS'}. Best is trial 12 with value: 0.14846048839678447.\n",
      "[I 2025-01-27 23:01:28,885] Trial 15 finished with value: 0.14776218300102403 and parameters: {'depth': 3, 'learning_rate': 0.0848092624528051, 'l2_leaf_reg': 39.83606587724646, 'random_strength': 0.9206797474506025, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'Bernoulli', 'subsample': 0.6010457610329025}. Best is trial 12 with value: 0.14846048839678447.\n",
      "[I 2025-01-27 23:01:42,634] Trial 16 finished with value: 0.14694656488549618 and parameters: {'depth': 3, 'learning_rate': 0.10741066059527016, 'l2_leaf_reg': 39.51052877581451, 'random_strength': 1.2195879738743327, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'MVS'}. Best is trial 12 with value: 0.14846048839678447.\n",
      "[I 2025-01-27 23:01:53,298] Trial 17 finished with value: 0.14715960324616773 and parameters: {'depth': 3, 'learning_rate': 0.09018736404500374, 'l2_leaf_reg': 35.06249021519381, 'random_strength': 0.9029863893983777, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'MVS'}. Best is trial 12 with value: 0.14846048839678447.\n",
      "[I 2025-01-27 23:02:08,032] Trial 18 finished with value: 0.14788837934238527 and parameters: {'depth': 3, 'learning_rate': 0.09421924716756346, 'l2_leaf_reg': 37.47886875787751, 'random_strength': 1.0083831343412224, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.10685662202986151}. Best is trial 12 with value: 0.14846048839678447.\n",
      "[I 2025-01-27 23:02:13,865] Trial 19 finished with value: 0.1374106433677522 and parameters: {'depth': 4, 'learning_rate': 0.10734864108703757, 'l2_leaf_reg': 30.134310651476543, 'random_strength': 1.3781511442588295, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'Bernoulli', 'subsample': 0.6867604357892539}. Best is trial 12 with value: 0.14846048839678447.\n",
      "[I 2025-01-27 23:02:25,631] Trial 20 finished with value: 0.1478836386024319 and parameters: {'depth': 3, 'learning_rate': 0.08750496655464224, 'l2_leaf_reg': 15.232055753010144, 'random_strength': 0.7882140642741557, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'MVS'}. Best is trial 12 with value: 0.14846048839678447.\n",
      "[I 2025-01-27 23:02:44,512] Trial 21 finished with value: 0.14732557095393456 and parameters: {'depth': 3, 'learning_rate': 0.09338199308794691, 'l2_leaf_reg': 37.03582136085168, 'random_strength': 1.0458297378762436, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.11653551199072619}. Best is trial 12 with value: 0.14846048839678447.\n",
      "[I 2025-01-27 23:02:54,899] Trial 22 finished with value: 0.14698241108489862 and parameters: {'depth': 3, 'learning_rate': 0.09478385899145075, 'l2_leaf_reg': 37.8424128561209, 'random_strength': 1.0534182296570425, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.3578841344065483}. Best is trial 12 with value: 0.14846048839678447.\n",
      "[I 2025-01-27 23:03:13,744] Trial 23 finished with value: 0.14882545793605437 and parameters: {'depth': 3, 'learning_rate': 0.10438854561048133, 'l2_leaf_reg': 34.61360183837556, 'random_strength': 0.8736512110939346, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.39850769342856124}. Best is trial 23 with value: 0.14882545793605437.\n",
      "[I 2025-01-27 23:03:23,727] Trial 24 finished with value: 0.1478302622891783 and parameters: {'depth': 3, 'learning_rate': 0.10664206562628417, 'l2_leaf_reg': 34.07453807093137, 'random_strength': 0.4948265287782614, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.4669934400496403}. Best is trial 23 with value: 0.14882545793605437.\n",
      "[I 2025-01-27 23:03:49,759] Trial 25 finished with value: 0.14749862082982493 and parameters: {'depth': 3, 'learning_rate': 0.11190469912885981, 'l2_leaf_reg': 28.970638902153272, 'random_strength': 0.84597213452494, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.4252699207545927}. Best is trial 23 with value: 0.14882545793605437.\n",
      "[I 2025-01-27 23:03:59,658] Trial 26 finished with value: 0.14722164038421257 and parameters: {'depth': 4, 'learning_rate': 0.10312169983420261, 'l2_leaf_reg': 33.13810498802256, 'random_strength': 1.3074390964406697, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'MVS'}. Best is trial 23 with value: 0.14882545793605437.\n",
      "[I 2025-01-27 23:04:09,642] Trial 27 finished with value: 0.14814814814814814 and parameters: {'depth': 3, 'learning_rate': 0.10068121137529955, 'l2_leaf_reg': 23.030707340396905, 'random_strength': 0.7152628095869544, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'Bernoulli', 'subsample': 0.87741097529445}. Best is trial 23 with value: 0.14882545793605437.\n",
      "[I 2025-01-27 23:04:21,791] Trial 28 finished with value: 0.14808647298462638 and parameters: {'depth': 3, 'learning_rate': 0.11369798852695209, 'l2_leaf_reg': 34.944272368274945, 'random_strength': 1.1026183031998982, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'MVS'}. Best is trial 23 with value: 0.14882545793605437.\n",
      "[I 2025-01-27 23:04:36,790] Trial 29 finished with value: 0.14940107145006923 and parameters: {'depth': 3, 'learning_rate': 0.10778652853992804, 'l2_leaf_reg': 31.32657566057153, 'random_strength': 0.37416766918399685, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.5633154883259968}. Best is trial 29 with value: 0.14940107145006923.\n",
      "[I 2025-01-27 23:04:45,638] Trial 30 finished with value: 0.14455507332709272 and parameters: {'depth': 4, 'learning_rate': 0.12734064109101534, 'l2_leaf_reg': 31.623236155900678, 'random_strength': 0.4330206842101041, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.56307934312951}. Best is trial 29 with value: 0.14940107145006923.\n",
      "[I 2025-01-27 23:05:18,905] Trial 31 finished with value: 0.14774699299862365 and parameters: {'depth': 3, 'learning_rate': 0.10716373493819438, 'l2_leaf_reg': 29.263985550777484, 'random_strength': 0.33351764710066856, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.29005749596444164}. Best is trial 29 with value: 0.14940107145006923.\n",
      "[I 2025-01-27 23:05:28,540] Trial 32 finished with value: 0.14662057456192634 and parameters: {'depth': 3, 'learning_rate': 0.10954062133366396, 'l2_leaf_reg': 38.31201737327671, 'random_strength': 0.6371197012240043, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.5639774271725879}. Best is trial 29 with value: 0.14940107145006923.\n",
      "[I 2025-01-27 23:05:46,486] Trial 33 finished with value: 0.14867051317275698 and parameters: {'depth': 3, 'learning_rate': 0.10348748328302199, 'l2_leaf_reg': 33.742980541546245, 'random_strength': 0.8155958102261162, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.527992003936651}. Best is trial 29 with value: 0.14940107145006923.\n",
      "[I 2025-01-27 23:05:56,268] Trial 34 finished with value: 0.14592782488661013 and parameters: {'depth': 3, 'learning_rate': 0.11605915787188298, 'l2_leaf_reg': 33.83249532574255, 'random_strength': 0.296023554594925, 'grow_policy': 'Depthwise', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.5395238008060632, 'min_data_in_leaf': 10}. Best is trial 29 with value: 0.14940107145006923.\n",
      "[I 2025-01-27 23:06:21,534] Trial 35 finished with value: 0.1486470234515935 and parameters: {'depth': 3, 'learning_rate': 0.09619601464507987, 'l2_leaf_reg': 19.538713577496743, 'random_strength': 0.7829073908570522, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.6619358016905671}. Best is trial 29 with value: 0.14940107145006923.\n",
      "[I 2025-01-27 23:06:35,884] Trial 36 finished with value: 0.1460279372696889 and parameters: {'depth': 3, 'learning_rate': 0.09585847005960091, 'l2_leaf_reg': 16.90616527531507, 'random_strength': 0.5527566923929081, 'grow_policy': 'Depthwise', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.678865695542537, 'min_data_in_leaf': 1}. Best is trial 29 with value: 0.14940107145006923.\n",
      "[I 2025-01-27 23:06:47,599] Trial 37 finished with value: 0.14778964764209407 and parameters: {'depth': 4, 'learning_rate': 0.09027564727961714, 'l2_leaf_reg': 19.137823242644668, 'random_strength': 0.8027691443965832, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.6609203495392882}. Best is trial 29 with value: 0.14940107145006923.\n",
      "[I 2025-01-27 23:06:57,252] Trial 38 finished with value: 0.1457844245427934 and parameters: {'depth': 3, 'learning_rate': 0.1204713040818752, 'l2_leaf_reg': 23.059818154400954, 'random_strength': 0.6064704411399551, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.5089090673902882}. Best is trial 29 with value: 0.14940107145006923.\n",
      "[I 2025-01-27 23:07:02,932] Trial 39 finished with value: 0.13957062819177946 and parameters: {'depth': 4, 'learning_rate': 0.1106993106814739, 'l2_leaf_reg': 28.204725203760127, 'random_strength': 0.11316039667201705, 'grow_policy': 'Depthwise', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.39867754918933296, 'min_data_in_leaf': 7}. Best is trial 29 with value: 0.14940107145006923.\n",
      "[I 2025-01-27 23:07:11,198] Trial 40 finished with value: 0.14484584507643694 and parameters: {'depth': 5, 'learning_rate': 0.08320835168185158, 'l2_leaf_reg': 20.27366995493959, 'random_strength': 0.7500402993473547, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.6297449272031895}. Best is trial 29 with value: 0.14940107145006923.\n",
      "[I 2025-01-27 23:07:29,747] Trial 41 finished with value: 0.14905972619226718 and parameters: {'depth': 3, 'learning_rate': 0.10543902899958894, 'l2_leaf_reg': 31.47807691070992, 'random_strength': 0.2484770910651779, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.7411442631586004}. Best is trial 29 with value: 0.14940107145006923.\n",
      "[I 2025-01-27 23:07:44,280] Trial 42 finished with value: 0.14742624257995923 and parameters: {'depth': 3, 'learning_rate': 0.10545962945020661, 'l2_leaf_reg': 30.718769815696277, 'random_strength': 0.2738120817421727, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.7651211962342831}. Best is trial 29 with value: 0.14940107145006923.\n",
      "[I 2025-01-27 23:08:08,548] Trial 43 finished with value: 0.1482780138472053 and parameters: {'depth': 3, 'learning_rate': 0.09791710159770488, 'l2_leaf_reg': 36.08501487797848, 'random_strength': 0.3858975125210717, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.7168278095766452}. Best is trial 29 with value: 0.14940107145006923.\n",
      "[I 2025-01-27 23:08:19,047] Trial 44 finished with value: 0.14580467675378267 and parameters: {'depth': 3, 'learning_rate': 0.10350107725443577, 'l2_leaf_reg': 29.965959962153313, 'random_strength': 0.20365553892956356, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.5994957305756883}. Best is trial 29 with value: 0.14940107145006923.\n",
      "[I 2025-01-27 23:08:34,608] Trial 45 finished with value: 0.14599468269564211 and parameters: {'depth': 3, 'learning_rate': 0.11471363868954348, 'l2_leaf_reg': 33.89414944891726, 'random_strength': 0.5220512407939266, 'grow_policy': 'Depthwise', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.4815126668845343, 'min_data_in_leaf': 6}. Best is trial 29 with value: 0.14940107145006923.\n",
      "[I 2025-01-27 23:08:52,911] Trial 46 finished with value: 0.1472924187725632 and parameters: {'depth': 3, 'learning_rate': 0.11951196340137253, 'l2_leaf_reg': 25.749658031087783, 'random_strength': 0.8574842482558265, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.7226027349208004}. Best is trial 29 with value: 0.14940107145006923.\n",
      "[I 2025-01-27 23:09:07,992] Trial 47 finished with value: 0.14714469228074273 and parameters: {'depth': 4, 'learning_rate': 0.10421432229397702, 'l2_leaf_reg': 27.49104945160048, 'random_strength': 0.2237709409496087, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.3308429251208881}. Best is trial 29 with value: 0.14940107145006923.\n",
      "[I 2025-01-27 23:09:16,708] Trial 48 finished with value: 0.14808346068677292 and parameters: {'depth': 3, 'learning_rate': 0.11082656468968562, 'l2_leaf_reg': 32.01032990135302, 'random_strength': 0.6994649359436516, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'Bernoulli', 'subsample': 0.7611236092319175}. Best is trial 29 with value: 0.14940107145006923.\n",
      "[I 2025-01-27 23:09:25,258] Trial 49 finished with value: 0.1470260767653091 and parameters: {'depth': 3, 'learning_rate': 0.12554334171251885, 'l2_leaf_reg': 35.48720262492658, 'random_strength': 0.3538629408744015, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.5881568204780482}. Best is trial 29 with value: 0.14940107145006923.\n",
      "[I 2025-01-27 23:09:42,722] Trial 50 finished with value: 0.14648993059506202 and parameters: {'depth': 3, 'learning_rate': 0.09671011325624859, 'l2_leaf_reg': 24.187497379675698, 'random_strength': 0.4568831484951784, 'grow_policy': 'Depthwise', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.7093642507354494, 'min_data_in_leaf': 8}. Best is trial 29 with value: 0.14940107145006923.\n",
      "[I 2025-01-27 23:10:08,471] Trial 51 finished with value: 0.14775128731732 and parameters: {'depth': 3, 'learning_rate': 0.10101507412563039, 'l2_leaf_reg': 31.801837045088867, 'random_strength': 1.2573405820383465, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.5209421273447327}. Best is trial 29 with value: 0.14940107145006923.\n",
      "[I 2025-01-27 23:10:26,199] Trial 52 finished with value: 0.14794030587074494 and parameters: {'depth': 3, 'learning_rate': 0.09023618307400523, 'l2_leaf_reg': 32.59383848235632, 'random_strength': 1.4068653353158078, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'MVS'}. Best is trial 29 with value: 0.14940107145006923.\n",
      "[I 2025-01-27 23:10:49,852] Trial 53 finished with value: 0.14822790489008525 and parameters: {'depth': 3, 'learning_rate': 0.08006902626536674, 'l2_leaf_reg': 34.647152924042466, 'random_strength': 0.9848418681829381, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'Bernoulli', 'subsample': 0.764382069569199}. Best is trial 29 with value: 0.14940107145006923.\n",
      "[I 2025-01-27 23:11:05,838] Trial 54 finished with value: 0.14673817991021978 and parameters: {'depth': 3, 'learning_rate': 0.09924531764924645, 'l2_leaf_reg': 30.95214400120568, 'random_strength': 0.10404854867870611, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.6220861761599975}. Best is trial 29 with value: 0.14940107145006923.\n",
      "[I 2025-01-27 23:11:24,020] Trial 55 finished with value: 0.1480618766051484 and parameters: {'depth': 3, 'learning_rate': 0.09238302751431882, 'l2_leaf_reg': 28.864665152650307, 'random_strength': 1.1599472578541798, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.26156606018529993}. Best is trial 29 with value: 0.14940107145006923.\n",
      "[I 2025-01-27 23:11:41,716] Trial 56 finished with value: 0.14825650823978984 and parameters: {'depth': 3, 'learning_rate': 0.10795588288512176, 'l2_leaf_reg': 33.08761956069046, 'random_strength': 0.23391671519286703, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'MVS'}. Best is trial 29 with value: 0.14940107145006923.\n",
      "[I 2025-01-27 23:12:04,897] Trial 57 finished with value: 0.1503281941688292 and parameters: {'depth': 5, 'learning_rate': 0.1390080342229852, 'l2_leaf_reg': 26.810014120981005, 'random_strength': 0.8809290164064231, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.4382338383640574}. Best is trial 57 with value: 0.1503281941688292.\n",
      "[I 2025-01-27 23:12:17,180] Trial 58 finished with value: 0.14750290360046459 and parameters: {'depth': 5, 'learning_rate': 0.11698422456108097, 'l2_leaf_reg': 26.58150742563306, 'random_strength': 0.9041294635366588, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.399368944881465}. Best is trial 57 with value: 0.1503281941688292.\n",
      "[I 2025-01-27 23:12:33,313] Trial 59 finished with value: 0.14918600729680842 and parameters: {'depth': 5, 'learning_rate': 0.1423751270815924, 'l2_leaf_reg': 17.962330322725663, 'random_strength': 0.8550643291715937, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.4386773583178675}. Best is trial 57 with value: 0.1503281941688292.\n",
      "[I 2025-01-27 23:12:43,915] Trial 60 finished with value: 0.14740545294635005 and parameters: {'depth': 5, 'learning_rate': 0.14313905830661117, 'l2_leaf_reg': 17.557453722724347, 'random_strength': 0.9483639246041868, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.4408129954911013}. Best is trial 57 with value: 0.1503281941688292.\n",
      "[I 2025-01-27 23:12:54,061] Trial 61 finished with value: 0.1480983031012288 and parameters: {'depth': 5, 'learning_rate': 0.13451566536247087, 'l2_leaf_reg': 19.338826050008073, 'random_strength': 0.8328805571482105, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.3793114769542386}. Best is trial 57 with value: 0.1503281941688292.\n",
      "[I 2025-01-27 23:13:01,831] Trial 62 finished with value: 0.1443962421352027 and parameters: {'depth': 5, 'learning_rate': 0.14264723085119213, 'l2_leaf_reg': 18.435585362803273, 'random_strength': 0.7693328517559029, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.4789125335438249}. Best is trial 57 with value: 0.1503281941688292.\n",
      "[I 2025-01-27 23:13:12,093] Trial 63 finished with value: 0.14773294203961848 and parameters: {'depth': 5, 'learning_rate': 0.13846432194809682, 'l2_leaf_reg': 21.195802776388824, 'random_strength': 0.8737697645382498, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.7662831542096609}. Best is trial 57 with value: 0.1503281941688292.\n",
      "[I 2025-01-27 23:13:18,944] Trial 64 finished with value: 0.14255765199161424 and parameters: {'depth': 5, 'learning_rate': 0.14933860923150785, 'l2_leaf_reg': 15.034192091190933, 'random_strength': 0.6642685065496547, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.4442268246145752}. Best is trial 57 with value: 0.1503281941688292.\n",
      "[I 2025-01-27 23:13:33,509] Trial 65 finished with value: 0.14695287147578076 and parameters: {'depth': 5, 'learning_rate': 0.14653212325653578, 'l2_leaf_reg': 21.97333007858356, 'random_strength': 1.0662020172274107, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.33676011883708395}. Best is trial 57 with value: 0.1503281941688292.\n",
      "[I 2025-01-27 23:14:01,408] Trial 66 finished with value: 0.15056678166584525 and parameters: {'depth': 4, 'learning_rate': 0.14003743954426082, 'l2_leaf_reg': 30.011362183686597, 'random_strength': 0.9655444575814124, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.49713793647222654}. Best is trial 66 with value: 0.15056678166584525.\n",
      "[I 2025-01-27 23:14:11,527] Trial 67 finished with value: 0.14832289870852614 and parameters: {'depth': 4, 'learning_rate': 0.13946990957960598, 'l2_leaf_reg': 30.078459646137887, 'random_strength': 0.9797833685874597, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'Bernoulli', 'subsample': 0.6041053458806841}. Best is trial 66 with value: 0.15056678166584525.\n",
      "[I 2025-01-27 23:14:21,239] Trial 68 finished with value: 0.1468145653057669 and parameters: {'depth': 5, 'learning_rate': 0.1351843806873276, 'l2_leaf_reg': 36.67930713854886, 'random_strength': 0.9359201213419316, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.47780685577795495}. Best is trial 66 with value: 0.15056678166584525.\n",
      "[I 2025-01-27 23:14:34,155] Trial 69 finished with value: 0.14663420709958672 and parameters: {'depth': 4, 'learning_rate': 0.13165801682978054, 'l2_leaf_reg': 27.842199835410074, 'random_strength': 1.1029468357480336, 'grow_policy': 'Depthwise', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.4175872108355466, 'min_data_in_leaf': 5}. Best is trial 66 with value: 0.15056678166584525.\n",
      "[I 2025-01-27 23:14:41,538] Trial 70 finished with value: 0.1462005717008099 and parameters: {'depth': 4, 'learning_rate': 0.14027318948142808, 'l2_leaf_reg': 33.49033052078891, 'random_strength': 0.8893371861389396, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.5153501256193105}. Best is trial 66 with value: 0.15056678166584525.\n",
      "[I 2025-01-27 23:14:49,870] Trial 71 finished with value: 0.14763621198129226 and parameters: {'depth': 5, 'learning_rate': 0.14597378224379692, 'l2_leaf_reg': 31.39617613429171, 'random_strength': 0.8236983848373013, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.55688414139903}. Best is trial 66 with value: 0.15056678166584525.\n",
      "[I 2025-01-27 23:14:55,508] Trial 72 finished with value: 0.13945951336258477 and parameters: {'depth': 4, 'learning_rate': 0.10547866958942395, 'l2_leaf_reg': 16.18857924282856, 'random_strength': 0.7304199227397693, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.45151571327360107}. Best is trial 66 with value: 0.15056678166584525.\n",
      "[I 2025-01-27 23:15:05,053] Trial 73 finished with value: 0.14737392213221845 and parameters: {'depth': 5, 'learning_rate': 0.13489581945518897, 'l2_leaf_reg': 29.29741739635527, 'random_strength': 0.802994658549006, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.49349952342023745}. Best is trial 66 with value: 0.15056678166584525.\n",
      "[I 2025-01-27 23:15:20,786] Trial 74 finished with value: 0.14795872855401268 and parameters: {'depth': 3, 'learning_rate': 0.1126011191899165, 'l2_leaf_reg': 32.448871909191126, 'random_strength': 1.0167526684677213, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.7938119667568213}. Best is trial 66 with value: 0.15056678166584525.\n",
      "[I 2025-01-27 23:15:29,869] Trial 75 finished with value: 0.14551547755533997 and parameters: {'depth': 3, 'learning_rate': 0.1026268134961226, 'l2_leaf_reg': 34.39286944653729, 'random_strength': 0.16404406349875883, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.5345595883158993}. Best is trial 66 with value: 0.15056678166584525.\n",
      "[I 2025-01-27 23:15:35,668] Trial 76 finished with value: 0.13945951336258477 and parameters: {'depth': 4, 'learning_rate': 0.10971374795379496, 'l2_leaf_reg': 30.566469591366623, 'random_strength': 0.592571026812938, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.688569807760451}. Best is trial 66 with value: 0.15056678166584525.\n",
      "[I 2025-01-27 23:15:53,917] Trial 77 finished with value: 0.14656124643916052 and parameters: {'depth': 3, 'learning_rate': 0.14158816436161667, 'l2_leaf_reg': 35.47486463429336, 'random_strength': 0.7734361709699039, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.36765599551005546}. Best is trial 66 with value: 0.15056678166584525.\n",
      "[I 2025-01-27 23:16:21,916] Trial 78 finished with value: 0.1479621972829297 and parameters: {'depth': 3, 'learning_rate': 0.0976243843773565, 'l2_leaf_reg': 17.93181518604224, 'random_strength': 0.6732808600175615, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.573182122945653}. Best is trial 66 with value: 0.15056678166584525.\n",
      "[I 2025-01-27 23:16:33,480] Trial 79 finished with value: 0.14659051574939425 and parameters: {'depth': 3, 'learning_rate': 0.14538274144202315, 'l2_leaf_reg': 20.52564369788237, 'random_strength': 0.913019365136237, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.6416453591850477}. Best is trial 66 with value: 0.15056678166584525.\n",
      "[I 2025-01-27 23:16:44,465] Trial 80 finished with value: 0.14691822476168925 and parameters: {'depth': 5, 'learning_rate': 0.10854062046789496, 'l2_leaf_reg': 24.005416689617903, 'random_strength': 0.9657095900199684, 'grow_policy': 'Depthwise', 'bootstrap_type': 'Bernoulli', 'min_data_in_leaf': 10}. Best is trial 66 with value: 0.15056678166584525.\n",
      "[I 2025-01-27 23:17:00,964] Trial 81 finished with value: 0.1461525018931671 and parameters: {'depth': 3, 'learning_rate': 0.10080313804639193, 'l2_leaf_reg': 31.996890219783246, 'random_strength': 1.3419027927869072, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'MVS'}. Best is trial 66 with value: 0.15056678166584525.\n",
      "[I 2025-01-27 23:17:29,682] Trial 82 finished with value: 0.1490637844420764 and parameters: {'depth': 3, 'learning_rate': 0.10523077892286771, 'l2_leaf_reg': 29.58698819787765, 'random_strength': 1.4457464215542433, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'MVS'}. Best is trial 66 with value: 0.15056678166584525.\n",
      "[I 2025-01-27 23:17:41,529] Trial 83 finished with value: 0.14703778757897246 and parameters: {'depth': 3, 'learning_rate': 0.10345505126306334, 'l2_leaf_reg': 29.820521482573238, 'random_strength': 0.8542101142695688, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'MVS'}. Best is trial 66 with value: 0.15056678166584525.\n",
      "[I 2025-01-27 23:17:53,710] Trial 84 finished with value: 0.14737031592211455 and parameters: {'depth': 3, 'learning_rate': 0.10634023155268663, 'l2_leaf_reg': 28.406655959026835, 'random_strength': 1.4549911775551787, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'MVS'}. Best is trial 66 with value: 0.15056678166584525.\n",
      "[I 2025-01-27 23:18:11,359] Trial 85 finished with value: 0.14840816824883246 and parameters: {'depth': 3, 'learning_rate': 0.10446646725460047, 'l2_leaf_reg': 27.209414167811047, 'random_strength': 1.2441440908990005, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.41949090876498074}. Best is trial 66 with value: 0.15056678166584525.\n",
      "[I 2025-01-27 23:18:21,360] Trial 86 finished with value: 0.14612083961498318 and parameters: {'depth': 3, 'learning_rate': 0.11376448525371383, 'l2_leaf_reg': 31.16257867102259, 'random_strength': 0.7438335292923723, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.6045660643284688}. Best is trial 66 with value: 0.15056678166584525.\n",
      "[I 2025-01-27 23:18:36,377] Trial 87 finished with value: 0.14840436731133635 and parameters: {'depth': 3, 'learning_rate': 0.12962565343191346, 'l2_leaf_reg': 16.665940435079854, 'random_strength': 0.3890091361465905, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'MVS'}. Best is trial 66 with value: 0.15056678166584525.\n",
      "[I 2025-01-27 23:18:54,973] Trial 88 finished with value: 0.1490348192369466 and parameters: {'depth': 4, 'learning_rate': 0.09884873370052057, 'l2_leaf_reg': 29.53215136529685, 'random_strength': 1.0876388717277934, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.45595381010633607}. Best is trial 66 with value: 0.15056678166584525.\n",
      "[I 2025-01-27 23:19:04,940] Trial 89 finished with value: 0.14613318252509544 and parameters: {'depth': 4, 'learning_rate': 0.10012325050734505, 'l2_leaf_reg': 29.435869386018734, 'random_strength': 1.0792999367667016, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.4552901988382301}. Best is trial 66 with value: 0.15056678166584525.\n",
      "[I 2025-01-27 23:19:17,391] Trial 90 finished with value: 0.14765913284132842 and parameters: {'depth': 4, 'learning_rate': 0.13686270269500617, 'l2_leaf_reg': 28.645794656609265, 'random_strength': 1.000111656737622, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.5027987013119387}. Best is trial 66 with value: 0.15056678166584525.\n",
      "[I 2025-01-27 23:19:39,154] Trial 91 finished with value: 0.1482774183842335 and parameters: {'depth': 4, 'learning_rate': 0.09523205617826096, 'l2_leaf_reg': 32.60257520732093, 'random_strength': 0.8128733560228469, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.7483987535408279}. Best is trial 66 with value: 0.15056678166584525.\n",
      "[I 2025-01-27 23:19:59,752] Trial 92 finished with value: 0.14756532066508313 and parameters: {'depth': 4, 'learning_rate': 0.09934871868097321, 'l2_leaf_reg': 26.261018577925714, 'random_strength': 1.0211634546680712, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.4008796448263655}. Best is trial 66 with value: 0.15056678166584525.\n",
      "[I 2025-01-27 23:20:31,552] Trial 93 finished with value: 0.14962097676152603 and parameters: {'depth': 4, 'learning_rate': 0.1052777389131375, 'l2_leaf_reg': 30.581063890725652, 'random_strength': 1.1674542397740433, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.5454926371462416}. Best is trial 66 with value: 0.15056678166584525.\n",
      "[I 2025-01-27 23:20:51,083] Trial 94 finished with value: 0.14765060600632873 and parameters: {'depth': 4, 'learning_rate': 0.10233811040179683, 'l2_leaf_reg': 30.483727463281173, 'random_strength': 0.9327933128683885, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.5463744189413566}. Best is trial 66 with value: 0.15056678166584525.\n",
      "[I 2025-01-27 23:21:08,797] Trial 95 finished with value: 0.14752893624839242 and parameters: {'depth': 4, 'learning_rate': 0.10621478492954825, 'l2_leaf_reg': 28.103836017824445, 'random_strength': 1.150337782308646, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.14631617621866277}. Best is trial 66 with value: 0.15056678166584525.\n",
      "[I 2025-01-27 23:21:24,331] Trial 96 finished with value: 0.14708353858190143 and parameters: {'depth': 4, 'learning_rate': 0.10897651333392802, 'l2_leaf_reg': 29.675012314574595, 'random_strength': 1.2989869919008823, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.4333689978412751}. Best is trial 66 with value: 0.15056678166584525.\n",
      "[I 2025-01-27 23:21:39,509] Trial 97 finished with value: 0.14741309740861405 and parameters: {'depth': 4, 'learning_rate': 0.10183149100252477, 'l2_leaf_reg': 30.319166533805753, 'random_strength': 1.1246329622937923, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'MVS'}. Best is trial 66 with value: 0.15056678166584525.\n",
      "[I 2025-01-27 23:21:55,299] Trial 98 finished with value: 0.1458848662019339 and parameters: {'depth': 4, 'learning_rate': 0.11087824418897904, 'l2_leaf_reg': 33.30953899833773, 'random_strength': 1.2012434916947534, 'grow_policy': 'Depthwise', 'bootstrap_type': 'Bayesian', 'bagging_temperature': 0.47028677342982456, 'min_data_in_leaf': 1}. Best is trial 66 with value: 0.15056678166584525.\n",
      "[I 2025-01-27 23:22:06,663] Trial 99 finished with value: 0.14661184711435968 and parameters: {'depth': 4, 'learning_rate': 0.10466337934952405, 'l2_leaf_reg': 31.291652257903895, 'random_strength': 0.892231879800608, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'Bernoulli', 'subsample': 0.8230318164136622}. Best is trial 66 with value: 0.15056678166584525.\n"
     ]
    }
   ],
   "source": [
    "# Create study that aims to maximize F1\n",
    "import optuna\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "\n",
    "# Optimize over 'objective' for a certain number of trials\n",
    "study.optimize(objective, n_trials=100, show_progress_bar=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "params2 = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'depth': 4,\n",
       " 'learning_rate': 0.12751986192358583,\n",
       " 'l2_leaf_reg': 28.56605893525792,\n",
       " 'random_strength': 1.4329403288787461,\n",
       " 'grow_policy': 'SymmetricTree',\n",
       " 'bootstrap_type': 'Bayesian',\n",
       " 'bagging_temperature': 0.31033906089109137}"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "params =  study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'depth': 4,\n",
       " 'learning_rate': 0.1264579533008154,\n",
       " 'l2_leaf_reg': 30.03825012048619,\n",
       " 'grow_policy': 'SymmetricTree',\n",
       " 'subsample': 0.7558041984536977}"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "completed_trials = [trial for trial in study.trials if trial.state == optuna.trial.TrialState.COMPLETE]\n",
    "\n",
    "# Sort the trials by the value (objective) in descending order (maximize performance)\n",
    "sorted_trials = sorted(completed_trials, key=lambda trial: trial.value, reverse=True)\n",
    "\n",
    "# Extract the top 5 parameter sets\n",
    "top_5_params = [trial.params for trial in sorted_trials[:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'depth': 4,\n",
       "  'learning_rate': 0.12751986192358583,\n",
       "  'l2_leaf_reg': 28.56605893525792,\n",
       "  'random_strength': 1.4329403288787461,\n",
       "  'grow_policy': 'SymmetricTree',\n",
       "  'bootstrap_type': 'Bayesian',\n",
       "  'bagging_temperature': 0.31033906089109137},\n",
       " {'depth': 4,\n",
       "  'learning_rate': 0.1248507739152174,\n",
       "  'l2_leaf_reg': 24.826390939702126,\n",
       "  'random_strength': 1.4094504738081457,\n",
       "  'grow_policy': 'SymmetricTree',\n",
       "  'bootstrap_type': 'Bayesian',\n",
       "  'bagging_temperature': 0.3773129429403069},\n",
       " {'depth': 4,\n",
       "  'learning_rate': 0.10889824051169908,\n",
       "  'l2_leaf_reg': 24.326419520439615,\n",
       "  'random_strength': 1.4322494067371123,\n",
       "  'grow_policy': 'SymmetricTree',\n",
       "  'bootstrap_type': 'Bayesian',\n",
       "  'bagging_temperature': 0.481893039827185},\n",
       " {'depth': 4,\n",
       "  'learning_rate': 0.1178823321005181,\n",
       "  'l2_leaf_reg': 22.111997922334616,\n",
       "  'random_strength': 1.428924662511862,\n",
       "  'grow_policy': 'SymmetricTree',\n",
       "  'bootstrap_type': 'Bayesian',\n",
       "  'bagging_temperature': 0.4705315566363708},\n",
       " {'depth': 4,\n",
       "  'learning_rate': 0.11005049955756034,\n",
       "  'l2_leaf_reg': 31.17690823161114,\n",
       "  'random_strength': 1.4254682793767415,\n",
       "  'grow_policy': 'SymmetricTree',\n",
       "  'bootstrap_type': 'Bayesian',\n",
       "  'bagging_temperature': 0.31345433019930435}]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_5_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Categorical features: ['product', 'campaign_id', 'webpage_id', 'gender', 'product_category']\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "# Define the ModelTrainer class\n",
    "class ModelTrainer:\n",
    "    def __init__(self, data_dir: False, model_name: str = \"catboost\", cat_features: list = None):\n",
    "        #self.data_dir = Path(data_dir)\n",
    "        self.model_name = model_name\n",
    "        self.cat_features = cat_features\n",
    "\n",
    "        logging.basicConfig(level=logging.INFO)\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "\n",
    "    def load_data(self):\n",
    "        self.logger.info(f\"Loading preprocessed data from {self.data_dir}...\")\n",
    "        X_train = pd.read_pickle(self.data_dir / \"X_train.pkl\")\n",
    "        y_train = pd.read_pickle(self.data_dir / \"y_train.pkl\").squeeze()\n",
    "        return X_train, y_train\n",
    "\n",
    "    def determine_categorical_features(self, X_train: pd.DataFrame):\n",
    "        if self.cat_features:\n",
    "            cat_features = [col for col in self.cat_features if col in X_train.columns]\n",
    "        else:\n",
    "            cat_features = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "        self.logger.info(f\"Categorical features: {cat_features}\")\n",
    "        return cat_features\n",
    "\n",
    "\n",
    "    def cross_validate_model(self, X_train: pd.DataFrame, y_train: pd.Series, cat_features: list, cv: int = 5):\n",
    "        if self.model_name == 'catboost':\n",
    "            model = CatBoostClassifier(\n",
    "                random_seed=42, verbose=0, eval_metric='F1',\n",
    "                cat_features=cat_features, class_weights=[1, 10]\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported model: {self.model_name}\")\n",
    "\n",
    "        self.logger.info(f\"Performing {cv}-fold cross-validation...\")\n",
    "        skf = StratifiedKFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "\n",
    "        fold_scores = []\n",
    "        for fold, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train)):\n",
    "            self.logger.info(f\"Processing fold {fold + 1}...\")\n",
    "\n",
    "            X_fold_train, X_fold_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "            y_fold_train, y_fold_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "            self.logger.info(f\"Validation set shape for fold {fold + 1}: {X_fold_val.shape}\")\n",
    "\n",
    "            model.fit(X_fold_train, y_fold_train, eval_set=(X_fold_val, y_fold_val), use_best_model=True)\n",
    "\n",
    "            fold_score = model.best_score_['validation']['F1']\n",
    "            fold_scores.append(fold_score)\n",
    "\n",
    "            self.logger.info(f\"Fold {fold + 1} F1 score: {fold_score}\")\n",
    "\n",
    "        mean_cv_score = sum(fold_scores) / len(fold_scores)\n",
    "        self.logger.info(f\"Mean cross-validation F1 score: {mean_cv_score}\")\n",
    "        return mean_cv_score\n",
    "\n",
    "    def train_model(self, X_train: pd.DataFrame, y_train: pd.Series, cat_features: list, val_size: float = 0.2):\n",
    "        if self.model_name == 'catboost':\n",
    "            model = CatBoostClassifier(\n",
    "            random_seed=42,\n",
    "            verbose=100,\n",
    "            eval_metric='F1',\n",
    "            loss_function='Logloss',\n",
    "            cat_features=cat_features,\n",
    "           #auto_class_weights='Balanced',\n",
    "            #bootstrap_type= \"Bernoulli\",\n",
    "            #grow_policy= \"SymmetricTree\",\n",
    "            class_weights=[1, 1 / a],\n",
    "            early_stopping_rounds=100,\n",
    "            **params2\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported model: {self.model_name}\")\n",
    "\n",
    "        self.logger.info(f\"Training {self.model_name} model...\")\n",
    "        X_train.drop(columns=['session_id', 'DateTime', 'user_id'], inplace=True, errors='ignore')\n",
    "\n",
    "        X_train_final, X_valid, y_train_final, y_valid = train_test_split(\n",
    "            X_train, y_train, test_size=val_size, random_state=42)\n",
    "        \n",
    "\n",
    "        self.logger.info(f\"Training {self.model_name} model with validation set...\")\n",
    "        model.fit(X_train_final, y_train_final, eval_set=(X_valid, y_valid), use_best_model=True)\n",
    "\n",
    "        return model\n",
    "\n",
    "# Interactive Workflow for Jupyter Notebook\n",
    "# Define the data directory\n",
    "DATA_DIR = \"path/to/data\"  # Replace with your actual path\n",
    "\n",
    "# Initialize ModelTrainer\n",
    "trainer = ModelTrainer(DATA_DIR,model_name=\"catboost\")\n",
    "cat_features = trainer.determine_categorical_features(X_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(293307, 15)"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Training catboost model...\n",
      "INFO:__main__:Training catboost model with validation set...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5313218\ttest: 0.5266059\tbest: 0.5266059 (0)\ttotal: 92.4ms\tremaining: 1m 32s\n",
      "100:\tlearn: 0.6000101\ttest: 0.5786546\tbest: 0.5806488 (93)\ttotal: 9.08s\tremaining: 1m 20s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.580648806\n",
      "bestIteration = 93\n",
      "\n",
      "Shrink model to first 94 iterations.\n"
     ]
    }
   ],
   "source": [
    "model = trainer.train_model(X_train, y_train, cat_features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9472    0.5222    0.6732     68404\n",
      "         1.0     0.0823    0.5954    0.1446      4923\n",
      "\n",
      "    accuracy                         0.5271     73327\n",
      "   macro avg     0.5147    0.5588    0.4089     73327\n",
      "weighted avg     0.8891    0.5271    0.6377     73327\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.5700000000000001\n",
      "Best F1 score: 0.15008745080891997\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# After training your CatBoost model:\n",
    "y_probs = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "best_threshold = 0.0\n",
    "best_f1 = 0.0\n",
    "\n",
    "# We can search thresholds from 0.0 to 1.0 in small steps\n",
    "for t in np.linspace(0, 1, 101):\n",
    "    y_pred = (y_probs >= t).astype(int)\n",
    "    score = f1_score(y_test, y_pred)\n",
    "    if score > best_f1:\n",
    "        best_f1 = score\n",
    "        best_threshold = t\n",
    "\n",
    "print(f\"Best threshold: {best_threshold}\")\n",
    "print(f\"Best F1 score: {best_f1}\")\n",
    "\n",
    "# When predicting on test data, use the best_threshold:\n",
    "y_probs_test = model.predict_proba(X_test)[:, 1]\n",
    "y_pred_test = (y_probs_test >= best_threshold).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive preprocessing (not my class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2= raw_data.drop(columns = ['session_id', 'DateTime', 'user_id','product_category_2'])\n",
    "data2.dropna(inplace = True) # Just close your eyes and drop the rows with missing values\n",
    "data2.drop_duplicates(inplace = True) # Drop duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11879, 11)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2 = data2.drop(columns = ['is_click'])\n",
    "y_2 = data2['is_click']\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_2, y_2, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_d2 = [\"product\", \"campaign_id\", \"webpage_id\", \"user_group_id\", \"gender\", \"product_category_1\"]\n",
    "\n",
    "X_train_2_d = pd.get_dummies(X_train_2, columns = columns_to_d2)\n",
    "X_test_2_d = pd.get_dummies(X_test_2, columns = columns_to_d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42,class_weight='balanced')\n",
    "rf.fit(X_train_2_d, y_train_2)\n",
    "y_pred_RF = rf.predict(X_test_2_d)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14298031865042174"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test_2, y_pred_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45353982300884954\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "model = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "model.fit(X_train_2_d, y_train_2)\n",
    "\n",
    "y_pred_LR = model.predict(X_test_2_d)\n",
    "print(f1_score(y_test_2, y_pred_LR))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Yofi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
